{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1539c25-698b-4213-a67c-dc9cf76d0442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c4667-cf99-47a7-8096-d0de0c7b2e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#\n",
    "#       aiplatform.CustomJob.from_local_script\n",
    "#\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa12b4-189d-470b-9def-3b3d1befc326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#\n",
    "# define the training script\n",
    "#\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d9ef4-5787-43e5-86d5-59116db92c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile training_script.py\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Sample Decision Tree Classifier\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "# parse args\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--bucket_name', dest='bucket_name', default=\"\", type=str, help='The GCS bucket to store model artifacts -> w/o gs://')\n",
    "parser.add_argument('--max_depth', dest='max_depth', default=10, type=int, help='The maximum depth of the tree')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# load the iris datasets\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "# fit a CART model to the data\n",
    "model = DecisionTreeClassifier(max_depth = args.max_depth)\n",
    "model.fit(dataset.data, dataset.target)\n",
    "print(model)\n",
    "\n",
    "# make predictions\n",
    "expected = dataset.target\n",
    "predicted = model.predict(dataset.data)\n",
    "\n",
    "# summarize the fit of the model\n",
    "classification_report = metrics.classification_report(expected, predicted)\n",
    "confusion_matrix = metrics.confusion_matrix(expected, predicted)\n",
    "\n",
    "# save the model to disk\n",
    "model_filename = \"model.pkl\"\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "# Upload the saved model file to GCS\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(args.bucket_name)\n",
    "model_directory = os.environ[\"AIP_MODEL_DIR\"]\n",
    "storage_path = os.path.join(model_directory, model_filename)\n",
    "blob = storage.blob.Blob.from_string(storage_path, client=storage_client)\n",
    "blob.upload_from_filename(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337cc1a-5363-4b80-b2fb-ef715678b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#\n",
    "# kick off the custom training job\n",
    "#\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c85eb3e-a729-4a04-b474-084cb0c97a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2e0c5e-379f-419b-b508-aee8601ac572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "P = ! gcloud config list --format 'value(core.project)'\n",
    "PROJECT_ID = P[0]\n",
    "REGION = \"us-central1\"\n",
    "BUCKET_NAME = f\"bkt-{PROJECT_ID}-vpipelines\"\n",
    "BUCKET_PATH = f\"gs://{BUCKET_NAME}\"\n",
    "PIPELINE_ROOT = f\"{BUCKET_PATH}/pipeline_root\"\n",
    "PIPELINE_DATA = f\"{BUCKET_PATH}/data\"\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1950bf-4671-45a9-9f9b-ab83dc65b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DEPTH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cecb078-ecae-4ea0-a2ab-03e5f1b1a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_PATH)\n",
    "\n",
    "job = aiplatform.CustomJob.from_local_script(\n",
    "    display_name = f\"vai_CustomJob_fromLocalScript_{TIMESTAMP}\"\n",
    "    , project = PROJECT_ID\n",
    "    , location = REGION\n",
    "    , script_path = \"training_script.py\"\n",
    "    , container_uri = \"us-docker.pkg.dev/vertex-ai/training/scikit-learn-cpu.0-23:latest\"\n",
    "    , requirements = [\"gcsfs\"]\n",
    "    , replica_count = 1\n",
    "    , machine_type = \"n1-standard-4\"\n",
    "    , accelerator_count = 0\n",
    "    , args = [f\"--bucket_name={BUCKET_NAME}\", f\"--max_depth={str(MAX_DEPTH)}\"]\n",
    "    , environment_variables = { 'MY_KEY': 'MY_VALUE' }\n",
    "    , labels={'my_key': 'my_value'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e48c199-10c7-48c2-ad4e-f423dfb5d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.run(service_account = f\"sa-vertex-pipelines@{PROJECT_ID}.iam.gserviceaccount.com\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "local-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
