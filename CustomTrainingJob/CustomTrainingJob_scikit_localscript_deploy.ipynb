{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b53f2b-f92f-4509-b40b-c2d865136503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8f6183-a471-42bc-9d90-3ea6d430a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#\n",
    "#       aiplatform.CustomTrainingJob -> script_path\n",
    "#\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa80aa31-3811-4595-85b2-5ed4600a5b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#\n",
    "# define the training script\n",
    "#\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62446b1a-a653-4fd6-bef4-6243b7e4bea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile training_script.py\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from google.cloud import storage\n",
    "\n",
    "# parse args\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_bucket_name', dest='data_bucket_name', default=\"\", type=str, help='my gcs bucket with all training data -> w/o gs://')\n",
    "parser.add_argument('--train_ds', dest='train_ds', default=\"\", type=str, help='CSV file name of the training data')\n",
    "args = parser.parse_args()\n",
    "\n",
    "## set params - data\n",
    "DATA_BUCKET_NAME = args.data_bucket_name\n",
    "DATA_BUCKET_ROOT = f\"/gcs/{DATA_BUCKET_NAME}\"\n",
    "DS_TRAIN_FILENAME = args.train_ds\n",
    "DS_TRAIN_PATH = f\"{DATA_BUCKET_ROOT}/{DS_TRAIN_FILENAME}\"\n",
    "\n",
    "## set params - model\n",
    "GCS_MODEL_SAVE_PATH = os.environ[\"AIP_MODEL_DIR\"]\n",
    "\n",
    "# clients\n",
    "storage_client = storage.Client()\n",
    "\n",
    "#####################################################################\n",
    "#\n",
    "#   BEGIN work\n",
    "#\n",
    "#####################################################################\n",
    "\n",
    "# load data from GCS using GCS fuse\n",
    "df = pd.read_csv(DS_TRAIN_PATH)\n",
    "labels = df.pop(\"label\").tolist()\n",
    "data = df.values.tolist()\n",
    "\n",
    "# fit the model\n",
    "skmodel = GradientBoostingClassifier(n_estimators = 100, max_depth = 10, min_samples_split = 100, min_samples_leaf = 100)\n",
    "skmodel.fit(data, labels)\n",
    "\n",
    "# save model to GCS\n",
    "model_filename = \"model.pkl\"\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    pickle.dump(skmodel, model_file)\n",
    "\n",
    "storage_path = os.path.join(GCS_MODEL_SAVE_PATH, model_filename)\n",
    "blob = storage.blob.Blob.from_string(storage_path, client=storage_client)\n",
    "blob.upload_from_filename(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e0d850-ca23-416d-b7e9-4d7935b6246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#\n",
    "# kick off the custom training job\n",
    "#\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede4ff71-4ead-4aef-a518-c3779593a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b7dc40-4503-46fa-b923-ec5952313512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "P = ! gcloud config list --format 'value(core.project)'\n",
    "PROJECT_ID = P[0]\n",
    "P = ! gcloud projects list --filter=\"$(gcloud config get-value project)\" --format=\"value(PROJECT_NUMBER)\"\n",
    "PROJECT_NUMBER = P[0]\n",
    "REGION = \"us-central1\"\n",
    "SERVICE_ACCOUNT = f\"sa-vertex-pipelines@{PROJECT_ID}.iam.gserviceaccount.com\"\n",
    "\n",
    "# exercise details\n",
    "USE_CASE = \"CustomTrainingJob\"\n",
    "ML_FRAMEWORK = \"scikit\"\n",
    "MODEL_TYPE = \"binclass\"\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "#-------------------\n",
    "# GCS\n",
    "#-------------------\n",
    "\n",
    "# training source data bucket\n",
    "GCS_DATA_SOURCE_BUCKET_NAME = f\"bkt-{REGION}-data\"\n",
    "GCS_DATA_SOURCE_BUCKET_PATH = f\"gs://{GCS_DATA_SOURCE_BUCKET_NAME}\"\n",
    "\n",
    "# training data table filename\n",
    "TRAIN_DS = \"tab_class_10inps_1krows_tes_3498.csv\"\n",
    "\n",
    "# use case staging bucket\n",
    "GCS_BUCKET_NAME = f\"bkt-{REGION}-{USE_CASE.lower()}\"\n",
    "GCS_BUCKET_PATH = f\"gs://{GCS_BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e1742-fb97-4416-9573-b7cb588e7f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create use case gcs bucket if needed\n",
    "! gsutil mb -p {PROJECT_ID} -c standard -l {REGION} {GCS_BUCKET_PATH}\n",
    "! gsutil ls -L -b {GCS_BUCKET_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af9a47-2244-4d36-81cf-db8fe3792931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------\n",
    "# JOB SPECIFIC DETAILS\n",
    "#-------------------------------------------------------\n",
    "\n",
    "# MODEL - training and serving containers\n",
    "TRAIN_VERSION  = \"scikit-learn-cpu.0-23\"\n",
    "DEPLOY_VERSION = \"sklearn-cpu.0-23\"\n",
    "\n",
    "TRAIN_IMAGE = \"us-docker.pkg.dev/vertex-ai/training/{}:latest\".format(TRAIN_VERSION)\n",
    "DEPLOY_IMAGE = \"us-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(DEPLOY_VERSION)\n",
    "\n",
    "# naming\n",
    "JOB_NAME = \"CustomTrainingJob\"\n",
    "MODEL_DISPLAY_NAME = f\"model_{MODEL_TYPE}_{ML_FRAMEWORK}\"\n",
    "\n",
    "# vars\n",
    "CMDARGS = [f\"--data_bucket_name={GCS_DATA_SOURCE_BUCKET_NAME}\", f\"--train_ds={TRAIN_DS}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c82786-c1c8-4c1f-8abd-a214615035a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "job = aiplatform.CustomTrainingJob(\n",
    "    display_name = JOB_NAME\n",
    "    , project = PROJECT_ID\n",
    "    , location = REGION\n",
    "    , staging_bucket = GCS_BUCKET_PATH\n",
    "    , script_path = \"training_script.py\"\n",
    "    , container_uri = TRAIN_IMAGE\n",
    "    , requirements = [\"gcsfs\"]\n",
    "    , model_serving_container_image_uri = DEPLOY_IMAGE\n",
    "    , model_description = \"My scikit model description\"\n",
    ")\n",
    "\n",
    "\n",
    "# Start the training\n",
    "model = job.run(\n",
    "    model_display_name = MODEL_DISPLAY_NAME\n",
    "    , args = CMDARGS\n",
    "    , environment_variables = { 'MY_KEY_run'.lower(): 'MY_VALUE_run' }\n",
    "    , replica_count = 1\n",
    "    , service_account = f\"sa-vertex-pipelines@{PROJECT_ID}.iam.gserviceaccount.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e12ce9-2fdf-4325-92fa-0052e64e2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(model)\n",
    "print(model.name)\n",
    "print(model.display_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d50b7-a90c-4703-b18d-887d2290a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#\n",
    "# deploy the model to an endpoint\n",
    "#\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacfd54c-615a-4cce-83ac-ff300e00a2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------\n",
    "# JOB SPECIFIC DETAILS\n",
    "#-------------------------------------------------------\n",
    "\n",
    "# exercise details\n",
    "USE_CASE = \"customTrained-prebuiltContainer-2\"\n",
    "\n",
    "# endpoint details\n",
    "resource_type = \"endpt\"\n",
    "resource_name = f\"{resource_type}-{USE_CASE}\"\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b1cd17-33ee-41aa-905f-c5c98cdf0912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an endpoint\n",
    "endpoint = aiplatform.Endpoint.create(\n",
    "    display_name = resource_name\n",
    "    , project = PROJECT_ID\n",
    "    , location = REGION\n",
    "    , labels = {\"env\" : \"prod\"}    \n",
    ")\n",
    "print(f\"Endpoint Created: {endpoint.resource_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb6436-dfb0-4d87-8f99-48eda84ed06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy a model\n",
    "endpoint.deploy(\n",
    "    model = model,\n",
    "    deployed_model_display_name = model.display_name,\n",
    "    traffic_percentage = 100,\n",
    "    machine_type = DEPLOY_COMPUTE,\n",
    "    min_replica_count = 1,\n",
    "    max_replica_count = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2585a5-0cef-414e-b5e8-99734a2ea908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#\n",
    "# test the prediction server\n",
    "#\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5adb8c6-a44c-4eca-818f-a8f443ec732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy data from GCS\n",
    "TP = os.path.join(GCS_DATA_SOURCE_BUCKET_PATH, TRAIN_DS)\n",
    "! gsutil cp {TP} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b312023c-5fee-461e-ac36-3381da59f0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "df = pd.read_csv(TP, nrows=10)\n",
    "labels = df.pop(\"label\").tolist()\n",
    "data = df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7578c11-6f50-4098-8405-d60458124ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prediction server\n",
    "# send to endpoint\n",
    "prediction = endpoint.predict(data)\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m102"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
