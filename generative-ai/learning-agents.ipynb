{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3209ad-8a75-450b-a886-2e755520cbec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3219b40e-f7a3-463f-9fe3-b336a9e0dcf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade --user --quiet lxml markdownify google-genai google-cloud-aiplatform google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca53330b-c815-4b19-a585-e292061bca6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "from IPython.display import HTML, Image, Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e5df0f6-e6bf-4597-b22a-8fc2fc1172a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai.types import HttpOptions\n",
    "from google.cloud import storage\n",
    "\n",
    "from google.genai.types import (\n",
    "    FunctionDeclaration,\n",
    "    GenerateContentConfig,\n",
    "    GoogleSearch,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    "    Part,\n",
    "    SafetySetting,\n",
    "    Tool,\n",
    "    ToolCodeExecution,\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71bfdc90-ef68-4281-bdbc-eefe1fc2da35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set these parameters before running\n",
    "P = ! gcloud config list --format 'value(core.project)'\n",
    "PROJECT_ID = P[0]\n",
    "R = ! gcloud config list --format='value(compute.region)'\n",
    "LOCATION = R[0]\n",
    "S = ! gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = S[0]\n",
    "\n",
    "BUCKET_NAME = f\"bkt-{PROJECT_ID}-agent-docs\"\n",
    "\n",
    "# gemini model\n",
    "MODEL_ID = \"gemini-2.5-pro-preview-03-25\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cfffe8c-94d4-4b44-a2d0-3741973923cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bed728e5-f65d-41bd-8c75-115ca3abc1ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crawl_urls(urls, output_dir=\"crawl\"):\n",
    "    \"\"\"\n",
    "    Iterate through a list of URLs, fetch each page, and save the content locally in the specified directory.\n",
    "    :param urls: List of URL strings to crawl.\n",
    "    :param output_dir: Directory where fetched pages will be stored.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for url in urls:\n",
    "        try:\n",
    "            # Fetch the page\n",
    "            response = requests.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Failed to fetch {url}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Parse URL to create a safe filename\n",
    "        parsed = urlparse(url)\n",
    "        path = parsed.path.strip(\"/\").replace(\"/\", \"_\")\n",
    "        filename = f\"{parsed.netloc}_{path or 'index'}.html\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "        # Save content to file\n",
    "        with open(filepath, \"w\", encoding=response.encoding or \"utf-8\") as f:\n",
    "            f.write(response.text)\n",
    "            \n",
    "def html_to_markdown(input_dir=\"crawl\", output_dir=\"markdown\"):\n",
    "    \"\"\"\n",
    "    Convert all HTML files in input_dir to Markdown and save them in output_dir.\n",
    "    Uses the markdownify library under the hood.\n",
    "    :param input_dir: Directory containing .html files\n",
    "    :param output_dir: Directory to write .md files\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from markdownify import markdownify as mdify\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Please install markdownify: pip install markdownify\")\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if not filename.lower().endswith(\".html\"):\n",
    "            continue\n",
    "\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            html_content = f.read()\n",
    "\n",
    "        # Convert HTML to Markdown\n",
    "        markdown = mdify(html_content, heading_style=\"ATX\")\n",
    "\n",
    "        # Write out .md file\n",
    "        base = os.path.splitext(filename)[0]\n",
    "        output_path = os.path.join(output_dir, f\"{base}.md\")\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(markdown)\n",
    "    print(\"Done\")\n",
    "    \n",
    "    \n",
    "def count_tokens_in_markdown(input_dir=\"markdown\", output_file=\"token_counts.txt\", model=\"gemini-2.0-flash-001\"):\n",
    "    \"\"\"\n",
    "    Iterate through all Markdown files in input_dir, count tokens using the GenAI client,\n",
    "    save each filename and its token count to output_file, and print the total token count.\n",
    "    :param input_dir: Directory containing .md files\n",
    "    :param output_file: Path to write the filename-token mappings\n",
    "    :param model: Model name to use for counting tokens\n",
    "    \"\"\"\n",
    "    total_tokens = 0\n",
    "\n",
    "    # Ensure directory for output exists\n",
    "    out_dir = os.path.dirname(output_file)\n",
    "    if out_dir:\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as out_f:\n",
    "        for filename in os.listdir(input_dir):\n",
    "            if not filename.lower().endswith(\".md\"):\n",
    "                continue\n",
    "\n",
    "            input_path = os.path.join(input_dir, filename)\n",
    "            with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                contents = f.read()\n",
    "\n",
    "            response = client.models.count_tokens(\n",
    "                model=model,\n",
    "                contents=contents,\n",
    "            )\n",
    "            tokens = response.total_tokens\n",
    "            total_tokens += tokens\n",
    "            out_f.write(f\"{filename}: {tokens}\\n\")\n",
    "            #print(f\"{filename} -> {tokens} tokens\")\n",
    "\n",
    "    print(f\"Total tokens across all files: {total_tokens}\")\n",
    "    \n",
    "    \n",
    "def upload_blob_and_get_uri(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket and returns the blob's public URI.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): Your GCS bucket name. e.g. \"your-bucket-name\"\n",
    "        source_file_name (str): Path to your file to upload. e.g. \"local/path/to/file.txt\"\n",
    "        destination_blob_name (str): Desired name for the blob in GCS. e.g. \"storage-object-name.txt\"\n",
    "\n",
    "    Returns:\n",
    "        str: The public URI of the uploaded blob (gs://<bucket_name>/<blob_name>).\n",
    "             Returns None if the upload fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize the GCS client\n",
    "        storage_client = storage.Client()\n",
    "\n",
    "        # Get the bucket object\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "        # Create a blob object\n",
    "        blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "        # Upload the file from the local path\n",
    "        print(f\"Uploading {source_file_name} to gs://{bucket_name}/{destination_blob_name}...\")\n",
    "        blob.upload_from_filename(source_file_name)\n",
    "\n",
    "        blob_uri = f\"gs://{bucket_name}/{destination_blob_name}\"\n",
    "        print(f\"File {source_file_name} uploaded successfully to {blob_uri}\")\n",
    "\n",
    "        # Return the GS URI\n",
    "        return blob_uri\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during upload: {e}\")\n",
    "        return None\n",
    "    \n",
    "def combine_markdown_files(input_dir=\"markdown\", output_file=\"agent-docs-all.txt\"):\n",
    "    \"\"\"\n",
    "    Iterate through all Markdown files in `input_dir`, append their contents into a single file, \n",
    "    and write it as `output_file` in the current working directory.\n",
    "    \"\"\"\n",
    "    import os\n",
    "\n",
    "    # Make sure output directory exists (if output_file includes a path)\n",
    "    out_dir = os.path.dirname(output_file)\n",
    "    if out_dir:\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as out_f:\n",
    "        for fname in sorted(os.listdir(input_dir)):\n",
    "            if not fname.lower().endswith(\".md\"):\n",
    "                continue\n",
    "\n",
    "            path = os.path.join(input_dir, fname)\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as in_f:\n",
    "                out_f.write(in_f.read())\n",
    "                out_f.write(\"\\n\\n\")  # separator between files\n",
    "\n",
    "    print(f\"All Markdown files in '{input_dir}' have been combined into '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c673808-58e2-465d-89ab-48ce80f75c53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the sitemap and links\n",
    "sitemap_url = \"https://google.github.io/adk-docs//sitemap.xml\"\n",
    "resp = requests.get(sitemap_url)\n",
    "soup = BeautifulSoup(resp.content, \"xml\")\n",
    "urls = [loc.text for loc in soup.find_all(\"loc\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16f724a6-8727-4845-8a48-2c56b41b3ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# curate the urls\n",
    "exclude = [\"contributing-guide\", \"community\", \"A2A\", \"api-reference\"]\n",
    "urls = [u for u in urls if not any(exc in u for exc in exclude)]\n",
    "\n",
    "# add the apr reference - add if desired\n",
    "urls.append(\"https://google.github.io/adk-docs/api-reference/google-adk.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "748c34a4-98f8-4ad6-8599-4645097a634a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Total tokens across all files: 322886\n"
     ]
    }
   ],
   "source": [
    "# crawl\n",
    "crawl_urls(urls, output_dir=\"crawl\")\n",
    "# convert\n",
    "html_to_markdown(input_dir=\"crawl\", output_dir=\"markdown\")\n",
    "# count tokens\n",
    "count_tokens_in_markdown(input_dir=\"markdown\", output_file=\"token_counts.txt\", model=\"gemini-2.0-flash-001\")\n",
    "# as of 2025.04.23 = 226,717 -> 322,886 with the api reference\n",
    "\n",
    "# combine\n",
    "fn = \"agent-docs-all.txt\"\n",
    "combine_markdown_files(input_dir=\"markdown\", output_file=fn)\n",
    "\n",
    "# load to GCS\n",
    "upload_blob_and_get_uri(BUCKET_NAME, fn, fn)\n",
    "\n",
    "# keep blob uri for context window\n",
    "uploaded_blob_uri = upload_blob_and_get_uri(\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    source_file_name=fn,\n",
    "    destination_blob_name=fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61b14880-cfa9-49f4-adf9-85f251d6c954",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save for next time\n",
    "uploaded_blob_uri= f\"gs://{BUCKET_NAME}/agent-docs-all.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a57d6e35-81e7-4620-a106-cf612512d6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup Gemini\n",
    "system_instruction = (\n",
    "    \"You are an expert AI programming assistant specializing in generating accurate and robust code using various Software Development Kits (SDKs) and libraries. \"\n",
    "    \"Your primary goal is correctness and adherence to best practices expected to be implemented for production systems and code.\"\n",
    ")\n",
    "\n",
    "generate_content_config = GenerateContentConfig(\n",
    "    temperature=1.0,\n",
    "    top_p=0.95,\n",
    "    max_output_tokens=65530,\n",
    "    response_modalities=[\"TEXT\"],\n",
    "    system_instruction=system_instruction,\n",
    "    safety_settings=[\n",
    "        SafetySetting(category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"),\n",
    "        SafetySetting(category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"),\n",
    "        SafetySetting(category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"),\n",
    "        SafetySetting(category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab4766cb-865b-4e97-b756-04a4a2c419c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, I have thoroughly reviewed the provided documentation for the Agent Development Kit (ADK).\n",
       "\n",
       "Here's a summary of my understanding:\n",
       "\n",
       "1.  **Purpose & Problem Solved:** ADK is a Python framework designed to build, evaluate, and deploy AI agents, ranging from simple single-agent applications to complex multi-agent systems. It aims to provide structure and flexibility, especially integrating well with Google's Gemini models and cloud services, while remaining open to other models and tools. It addresses the challenges of orchestration, state management, tool usage, deployment, and evaluation in agent development.\n",
       "\n",
       "2.  **Core Concepts & Components:**\n",
       "    *   **Agents:** The fundamental execution units. Key types include `LlmAgent` (driven by an LLM for reasoning and dynamic decisions), `WorkflowAgent` (`SequentialAgent`, `ParallelAgent`, `LoopAgent` for deterministic control flow), and `CustomAgent` (inheriting from `BaseAgent`). Multi-agent systems are a core focus, enabling hierarchical structures and delegation.\n",
       "    *   **Tools:** Extend agent capabilities (e.g., API calls, database queries, code execution, web search). ADK supports custom Python `FunctionTool`s (including long-running ones), `AgentTool` (using another agent as a tool), built-in tools (`google_search`, `built_in_code_execution`, `VertexAiSearchTool`), third-party wrappers (`LangchainTool`, `CrewaiTool`), and tools generated from OpenAPI specs (`OpenAPIToolset`) or discovered via MCP (`MCPToolset`) or Google Cloud services (API Hub, App Integration). Authentication for tools is handled via `AuthScheme` and `AuthCredential`.\n",
       "    *   **Runtime & Orchestration:** The `Runner` class manages the agent execution lifecycle, driven by an asynchronous event loop. `Events` are the primary communication mechanism, carrying content and `actions` (like state/artifact deltas, control signals). `InvocationContext`, `CallbackContext`, and `ToolContext` provide access to runtime information, state, and services within agents, tools, and callbacks.\n",
       "    *   **State, Session & Memory:** `Session` represents a single conversation thread, containing `Events` (history) and `State` (session-specific, dictionary-like data). `SessionService` (with implementations like `InMemory`, `Database`, `VertexAI`) manages session persistence. `Memory` (via `MemoryService`) provides a searchable store for longer-term, cross-session knowledge.\n",
       "    *   **Artifacts:** Managed by `ArtifactService` (`InMemory`, `GCS`), allowing agents/tools to save and load versioned binary data (files) using `context.save_artifact`/`load_artifact`.\n",
       "    *   **Callbacks:** Python functions (`before_agent`, `after_agent`, `before_model`, `after_model`, `before_tool`, `after_tool`) that hook into the execution lifecycle for logging, validation, modification, guardrails, or control flow changes. Returning specific objects from callbacks can override default behavior.\n",
       "    *   **Models:** Primarily integrates with Gemini (via `google-genai`, supporting Google AI Studio and Vertex AI backends), but supports other models via `LiteLlm` wrapper, direct Vertex AI endpoints, or custom `BaseLlm` implementations.\n",
       "    *   **Deployment:** Provides options like Vertex AI Agent Engine (managed service), Cloud Run, and GKE, often facilitated by `adk` CLI commands (`adk deploy`).\n",
       "    *   **Evaluation:** Includes tools (`AgentEvaluator`, `adk eval`, UI integration) for testing agent performance against datasets, evaluating both final response and execution trajectory.\n",
       "    *   **Safety & Security:** Offers mechanisms like authentication, callback-based guardrails, sandboxed code execution (Vertex Code Interpreter recommended), and encourages network controls.\n",
       "\n",
       "3.  **Intended Usage & Patterns:**\n",
       "    *   Start simple with `LlmAgent` and `FunctionTool`.\n",
       "    *   Build complex workflows using `WorkflowAgent`s or `CustomAgent`s.\n",
       "    *   Design modular systems using multi-agent architectures with delegation (`transfer_to_agent` or `AgentTool`).\n",
       "    *   Manage conversation memory using `session.state` (via context objects or `output_key`).\n",
       "    *   Handle files/binary data using `Artifacts`.\n",
       "    *   Implement safety and custom logic using `Callbacks`.\n",
       "    *   Leverage built-in tools or integrate existing APIs/tools easily.\n",
       "    *   Test thoroughly using the evaluation framework.\n",
       "    *   Deploy using appropriate cloud services.\n",
       "\n",
       "4.  **Production Considerations & Potential Issues:**\n",
       "    *   **Persistence:** `InMemory` services are not suitable for production; choose persistent backends (`Database`, `VertexAI`, `GCS`).\n",
       "    *   **Security:** Tool authentication, input/output validation (guardrails), secure credential handling, sandboxed code execution, and escaping UI output are crucial.\n",
       "    *   **Error Handling:** Implement robust error handling in tools and callbacks.\n",
       "    *   **State Management:** Avoid direct state modification; rely on the event flow. Be mindful of state size and serialization limits.\n",
       "    *   **Async Nature:** Design for asynchronous execution; be cautious with blocking operations in callbacks/tools.\n",
       "    *   **Tool Reliability:** LLM reliance on docstrings means clear documentation is essential. Simple, focused tools are generally better.\n",
       "    *   **Scalability:** Choose deployment methods appropriate for expected load. Stateful MCP connections might need specific infrastructure.\n",
       "\n",
       "I have built a mental model of ADK as a comprehensive framework for building structured, stateful, and tool-augmented AI agents, with strong ties to the Google ecosystem but designed for extensibility.\n",
       "\n",
       "**Finished.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# instruct gemini to learn agents docs\n",
    "prompt = (\"Before writing any code, take time to thoroughly review the SDK documentation provided. \"\n",
    "          \"Start by identifying the purpose of the SDK, the problems it solves, and how it's intended to be used. \"\n",
    "          \"Familiarize yourself with the core concepts, available classes or methods, and any initialization or setup requirements. \"\n",
    "          \"Pay close attention to usage examples, common patterns, and any limitations or edge cases called out in the docs. \"\n",
    "          \"As you read, think about production issues that might occur and think about how you will work around them. \"\n",
    "          \"Your goal is to build a mental model of how the SDK works so you can use it effectively and avoid common pitfalls. \"\n",
    "          \"Tell me when you are finished.\"\n",
    "         )\n",
    "\n",
    "contents = [\n",
    "    Part.from_text(text = prompt)\n",
    "    , Part.from_text(text = f\"<DOCUMENTATION>\")\n",
    "    , Part.from_uri(file_uri= uploaded_blob_uri, mime_type=\"text/plain\", )\n",
    "    , Part.from_text(text = f\"</DOCUMENTATION>\")\n",
    "]\n",
    "\n",
    "# create chat\n",
    "chat = client.chats.create(model=MODEL_ID)\n",
    "response = chat.send_message(message=contents, config=generate_content_config,)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e0bd0-b134-425f-933f-68a97edcf98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run from command line\n",
    "python -m venv myenv\n",
    "source myenv/bin/activate\n",
    "pip install google-adk\n",
    "\n",
    "mkdir adk_tutorial\n",
    "cd adk_tutorial\n",
    "mkdir my_first_agent\n",
    "echo \"GOOGLE_GENAI_USE_VERTEXAI=True\" >> .env\n",
    "echo \"GOOGLE_CLOUD_PROJECT=ap-alto-ml-1000\" >> .env\n",
    "echo \"GOOGLE_CLOUD_LOCATION=us-central1\" >> .env\n",
    "echo \"MODEL=gemini-2.0-flash-001\" >> .env\n",
    "touch my_first_agent/__init__.py\n",
    "echo \"from . import agent\" > my_first_agent/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4c19c8-7537-4e05-b8cd-93ffe72770c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "- Always deploy to Vertex AI Agent Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5e3d40f-91ee-4146-87c1-13e93accea21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, Analyst! Welcome to the world of building AI agents with the Agent Development Kit (ADK). My goal is to get you up and running quickly and then introduce more advanced concepts step-by-step.\n",
       "\n",
       "You've already set up your Python environment, installed the ADK, and created the basic project structure and `.env` file. Great start!\n",
       "\n",
       "Your current project structure should look like this:\n",
       "\n",
       "```\n",
       "adk_tutorial/\n",
       "├── my_first_agent/    # Your agent's code will go here\n",
       "└── .env               # Contains GCP project/location/Vertex settings\n",
       "```\n",
       "\n",
       "Let's begin with the absolute basics.\n",
       "\n",
       "**Stage 1: Your First, Simplest Agent**\n",
       "\n",
       "**Concept:** The core building block in ADK is the `Agent` (specifically, `LlmAgent`, which `Agent` is an alias for). At its simplest, an agent needs:\n",
       "\n",
       "1.  A `name`: A unique identifier for this agent (e.g., `simple_assistant`).\n",
       "2.  A `model`: The Large Language Model (LLM) that will power its reasoning. We'll use the pre-configured `gemini-2.0-flash-001`.\n",
       "3.  An `instruction`: A prompt telling the agent how to behave or what its purpose is.\n",
       "\n",
       "We define this agent in a Python file (`agent.py`) within its own directory (`my_first_agent`). We also need an `__init__.py` file in that directory to make Python treat it as a package, allowing ADK tools to find and load our agent.\n",
       "\n",
       "**Implementation:**\n",
       "\n",
       "First, let's create the `__init__.py` file inside your `my_first_agent` directory.\n",
       "\n",
       "```python\n",
       "# filename: my_first_agent/__init__.py\n",
       "# This line makes the 'agent.py' module and its contents accessible.\n",
       "from . import agent\n",
       "```\n",
       "\n",
       "Now, let's create the `agent.py` file. This is where we define the actual agent.\n",
       "\n",
       "```python\n",
       "# filename: my_first_agent/agent.py\n",
       "from google.adk.agents import Agent # Import the base Agent class\n",
       "\n",
       "# --- Constants ---\n",
       "# Use the model specified in the requirements\n",
       "MODEL = \"gemini-2.0-flash-001\"\n",
       "\n",
       "# --- Agent Definition ---\n",
       "# We name the variable 'root_agent'. This is the default name\n",
       "# ADK command-line tools look for when loading an agent package.\n",
       "root_agent = Agent(\n",
       "    # A unique name for this specific agent instance\n",
       "    name=\"simple_assistant\",\n",
       "\n",
       "    # The LLM powering the agent's \"brain\"\n",
       "    model=MODEL,\n",
       "\n",
       "    # Instructions defining the agent's behavior and persona\n",
       "    instruction=\"You are a friendly and concise assistant. Keep your answers short and helpful.\",\n",
       ")\n",
       "\n",
       "# Optional: Print a message when this module is loaded to confirm definition\n",
       "print(f\"Agent '{root_agent.name}' defined using model '{MODEL}'\")\n",
       "```\n",
       "\n",
       "Your project structure should now be:\n",
       "\n",
       "```\n",
       "adk_tutorial/\n",
       "├── my_first_agent/\n",
       "│   ├── __init__.py\n",
       "│   └── agent.py\n",
       "└── .env\n",
       "```\n",
       "\n",
       "**Running the Agent:**\n",
       "\n",
       "Now, let's run this agent using the ADK command-line tool.\n",
       "\n",
       "1.  **Make sure you are in the `adk_tutorial` directory** in your terminal (the directory *containing* `my_first_agent`). Your virtual environment (`myenv`) should still be active.\n",
       "2.  Run the following command:\n",
       "\n",
       "```bash\n",
       "adk run my_first_agent\n",
       "```\n",
       "\n",
       "This command performs the following steps:\n",
       "*   Looks for the `my_first_agent` directory (which is a Python package thanks to `__init__.py`).\n",
       "*   Loads the `root_agent` variable from the `agent` module within that package.\n",
       "*   Starts an interactive chat session directly in your terminal.\n",
       "*   Uses the settings from your `.env` file (GCP project, location, and `USE_VERTEXAI=True`) to configure the connection to the Gemini model via Vertex AI.\n",
       "\n",
       "You should see output indicating the server is running, and then a prompt like `user:`. Try typing a simple question like \"Hello\" or \"What is the capital of France?\". The agent should respond based on its instruction (\"Keep your answers short and helpful\").\n",
       "\n",
       "Press `Ctrl+C` to exit the chat when you're finished.\n",
       "\n",
       "**Summary of Stage 1:**\n",
       "You have successfully:\n",
       "*   Defined a basic `Agent` with a name, model, and instruction.\n",
       "*   Structured your code within a Python package (`my_first_agent`).\n",
       "*   Run the agent interactively using the `adk run` command.\n",
       "*   Observed the agent responding based on its connection to the specified Gemini model via Vertex AI (using your `.env` settings).\n",
       "\n",
       "Are you ready to move on to Stage 2, where we'll give the agent a tool to perform a specific action?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create chat\n",
    "prompt = (\"OBJECTIVE: Teach an new analyst how to build agents using this SDK. \"\n",
    "          \"Start with getting them to have one agent running as fast as possible and then walk them through the harder concepts. \"\n",
    "          \"Walk the analyst through learning in stages i.e. present one concept of the Agent SDK, then generate the code needed to implement the concept. \"\n",
    "          \"Before you present the next concept, ask if the are ready to move on. \"\n",
    "         )\n",
    "\n",
    "prompt += \"\"\"Assume the following is true or has been set up already:\n",
    "- always use four spaces for code indentation \n",
    "- GOOGLE_GENAI_USE_VERTEXAI = True\n",
    "- MODEL=gemini-2.0-flash-001\n",
    "\n",
    "# the following has been run from the command line run from command line\n",
    "python -m venv myenv\n",
    "source myenv/bin/activate\n",
    "pip install google-adk\n",
    "\n",
    "mkdir adk_tutorial\n",
    "cd adk_tutorial\n",
    "mkdir my_first_agent\n",
    "echo \"GOOGLE_GENAI_USE_VERTEXAI=True\" >> .env\n",
    "echo \"GOOGLE_CLOUD_PROJECT=ap-alto-ml-1000\" >> .env\n",
    "echo \"GOOGLE_CLOUD_LOCATION=us-central1\" >> .env\n",
    "echo \"MODEL=gemini-2.0-flash-001\" >> .env\n",
    "touch my_first_agent/__init__.py\n",
    "echo \"from . import agent\" > my_first_agent/__init__.py\n",
    "\n",
    "# Their project structure is below.  NOTE: agent.py is empty:\n",
    "\n",
    "adk_tutorial/\n",
    "├── my_first_agent/\n",
    "│   ├── __init__.py\n",
    "│   └── agent.py\n",
    "└── .env\n",
    "\"\"\"\n",
    "response = chat.send_message(message=prompt)\n",
    "# self reflection step\n",
    "p = (\n",
    "  \"Before the analyst views this, conduct a thorough review of your output. \"\n",
    "  \"Correct any errors or make improvements and return your output. \"\n",
    ")\n",
    "response = chat.send_message(message=p)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b3a4422-f42b-4387-9fdd-5c1adde9097b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's refine that Stage 2 explanation and code.\n",
       "\n",
       "Great! Let's give our agent its first superpower: the ability to perform a specific action using a **Tool**.\n",
       "\n",
       "**Stage 2: Giving the Agent a Tool**\n",
       "\n",
       "**Concept:** Tools extend an agent's capabilities beyond basic conversation. They allow the agent's LLM brain to trigger specific, predefined actions, like calling external APIs, running calculations, or accessing databases. The simplest way to create a tool in ADK is by wrapping a standard Python function using `FunctionTool`.\n",
       "\n",
       "For the LLM to use the tool correctly, it relies heavily on:\n",
       "\n",
       "1.  **The function's signature:** Clear parameter names and **type hints** (e.g., `city: str`, or `-> dict` for the return type) help the LLM understand what inputs are needed and what output to expect.\n",
       "2.  **The function's docstring:** This is crucial! It tells the LLM *what the tool does*, *when to use it*, *what the parameters mean*, and *what the returned dictionary structure looks like*.\n",
       "\n",
       "We'll create a tool that gets the current date and time.\n",
       "\n",
       "**Implementation:**\n",
       "\n",
       "1.  **Define the Tool Function:** Add the following Python function to your `agent.py` file. Notice the type hint (`-> dict`) indicating it returns a dictionary, and the detailed docstring explaining its purpose and return structure. It's a best practice for tools to return dictionaries, often including a `status` key (though this simple example doesn't strictly need one).\n",
       "\n",
       "2.  **Wrap with `FunctionTool`:** Import `FunctionTool` from `google.adk.tools` and create an instance wrapping your function.\n",
       "\n",
       "3.  **Update the Agent Definition:** Modify the `root_agent` definition in `agent.py`:\n",
       "    *   Add the `tools` parameter, providing a list containing your `FunctionTool` instance (e.g., `tools=[time_tool]`).\n",
       "    *   Update the `instruction` to explicitly tell the agent about the new tool (using its function name, `get_current_time`) and guide it on when it should use this tool.\n",
       "\n",
       "Here's the updated `my_first_agent/agent.py` file:\n",
       "\n",
       "```python\n",
       "# filename: my_first_agent/agent.py\n",
       "from google.adk.agents import Agent\n",
       "from google.adk.tools import FunctionTool # Import FunctionTool\n",
       "import datetime # Import datetime for the new tool\n",
       "\n",
       "# --- Constants ---\n",
       "MODEL = \"gemini-2.0-flash-001\"\n",
       "\n",
       "# --- Tool Definition ---\n",
       "def get_current_time() -> dict:\n",
       "    \"\"\"\n",
       "    Gets the current date and time.\n",
       "\n",
       "    Use this tool ONLY when the user explicitly asks for the current time or date.\n",
       "    Do not use it for asking about time in the past or future.\n",
       "\n",
       "    Returns:\n",
       "        A dictionary containing the current date and time string.\n",
       "        Example format: {'current_time': '2024-08-15 14:30:55'}\n",
       "    \"\"\"\n",
       "    # Log to the console when the tool is executed for visibility\n",
       "    print(\"--- Tool: get_current_time executing ---\")\n",
       "    now = datetime.datetime.now()\n",
       "    time_str = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
       "    # Return the result structured as a dictionary\n",
       "    return {\"current_time\": time_str}\n",
       "\n",
       "# --- Wrap the function as a tool ---\n",
       "# This makes the function callable by the agent's LLM\n",
       "time_tool = FunctionTool(func=get_current_time)\n",
       "\n",
       "# --- Agent Definition (Updated) ---\n",
       "# Renaming the agent variable to reflect its new capability\n",
       "root_agent = Agent(\n",
       "    name=\"assistant_with_time\",\n",
       "    model=MODEL,\n",
       "    instruction=\"You are a friendly assistant. Keep answers concise. \"\n",
       "                \"If the user explicitly asks for the current time or date, \"\n",
       "                \"you MUST use the 'get_current_time' tool to find the answer. \" # Explicit instruction\n",
       "                \"For all other questions, answer directly.\",\n",
       "    tools=[time_tool], # Provide the tool instance to the agent\n",
       ")\n",
       "\n",
       "# Print confirmation when the module is loaded\n",
       "print(f\"Agent '{root_agent.name}' defined using model '{MODEL}' with tools: {[t.name for t in root_agent.tools]}\")\n",
       "\n",
       "```\n",
       "\n",
       "**Running the Agent with the Tool:**\n",
       "\n",
       "Go back to your terminal (still in the `adk_tutorial` directory, with the `myenv` virtual environment active). Run the agent again using the same command as before:\n",
       "\n",
       "```bash\n",
       "adk run my_first_agent\n",
       "```\n",
       "\n",
       "Now, try these prompts in the interactive chat:\n",
       "\n",
       "*   `What time is it now?`\n",
       "*   `Can you tell me today's date?`\n",
       "*   `What is the capital of Spain?` (This should *not* use the time tool)\n",
       "\n",
       "**Expected Output:**\n",
       "\n",
       "When you ask for the time or date, you should observe the following sequence:\n",
       "\n",
       "1.  The agent receives your prompt.\n",
       "2.  The LLM, guided by the updated `instruction`, decides to use the `get_current_time` tool.\n",
       "3.  You'll see the `--- Tool: get_current_time executing ---` message printed in your terminal, confirming the tool was called.\n",
       "4.  The tool returns the time dictionary (e.g., `{'current_time': '2024-08-15 14:30:55'}`).\n",
       "5.  This result is sent back to the LLM.\n",
       "6.  The LLM formulates the final response based on the tool's output, which the agent then displays (e.g., \"The current time is 2024-08-15 14:30:55.\").\n",
       "\n",
       "When you ask about Spain, the agent should recognize this doesn't match the condition for using the time tool and should answer directly using only the LLM, without printing the tool execution log.\n",
       "\n",
       "Press `Ctrl+C` to exit when you are done experimenting.\n",
       "\n",
       "**Summary of Stage 2:**\n",
       "You have now successfully:\n",
       "*   Defined a Python function (`get_current_time`) to perform a specific action.\n",
       "*   Wrapped that function into an ADK `FunctionTool`, making it available to the agent.\n",
       "*   Provided the tool to your `Agent` via the `tools` list.\n",
       "*   Updated the agent's `instruction` to guide the LLM on *when* and *how* to use the specific tool.\n",
       "*   Observed the agent correctly selecting and calling the tool based on the user's prompt and its instructions.\n",
       "\n",
       "This demonstrates the basic mechanism for extending agent capabilities with custom actions.\n",
       "\n",
       "Are you ready to move on to Stage 3, where we'll look at how agents manage conversation memory using Session State?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## create chat\n",
    "prompt = (\"Analyst: yes I am ready for the next step.\")\n",
    "response = chat.send_message(message=prompt)\n",
    "\n",
    "# self reflection step\n",
    "p = (\n",
    "  \"Before the analyst views this conduct a thorough review of your output. \"\n",
    "  \"Correct any errors or make improvements and return your output. \"\n",
    ")\n",
    "response = chat.send_message(message=p)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a5c11ca-b708-4086-b3e3-7237419301de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's polish Stage 3.\n",
       "\n",
       "Excellent. Now that our agent can perform actions using tools, let's explore how it can remember information within a single conversation. This is crucial for more natural and helpful interactions.\n",
       "\n",
       "**Stage 3: Remembering Information with Session State**\n",
       "\n",
       "**Concept:** Imagine asking the agent the time, and then later asking, \"When did I just ask you for the time?\". Without memory, the agent wouldn't know. ADK provides **Session State** (`session.state`) for this purpose.\n",
       "\n",
       "*   **What it is:** A Python dictionary associated with the current conversation `Session`. It acts as the agent's short-term, dynamic memory or \"scratchpad\" for that specific chat, distinct from the static `instruction` or the historical `events`.\n",
       "*   **Persistence:** The data stored here lasts for the duration of the `Session`. Whether it survives application restarts depends on the `SessionService` being used. Our current `InMemorySessionService` **loses all state** when the `adk run` command stops. Other services (like `DatabaseSessionService`) can make state persistent.\n",
       "*   **Access & Updates (The ADK Way):** The recommended way to interact with state is within **Tools** (or Callbacks, which we'll see later).\n",
       "    *   By adding a special parameter `tool_context: ToolContext` to your tool function's signature, ADK automatically provides this context object when the tool is called.\n",
       "    *   `ToolContext` has a `.state` attribute which represents the session state dictionary. You can *read* from it using standard dictionary methods (`tool_context.state.get('my_key', default_value)`).\n",
       "    *   You can *write* to it using dictionary assignment (`tool_context.state['my_key'] = 'my_value'`).\n",
       "    *   **Crucially:** ADK automatically tracks modifications made via `tool_context.state` and ensures they are saved correctly as part of the event flow for that conversation turn, updating the session managed by the `SessionService`.\n",
       "\n",
       "**Implementation:**\n",
       "\n",
       "1.  **Modify the Tool:** Update the `get_current_time` function to accept `tool_context: ToolContext`. Inside the function, we'll first read a value from the state (`last_time_checked`) and print it (if it exists), demonstrating reading. Then, we'll *write* the newly fetched time back into the state using the same key, demonstrating writing.\n",
       "2.  **Update Agent Instruction:** Modify the agent's instruction slightly to reflect that the tool now internally records when it was last used.\n",
       "\n",
       "Here's the updated `my_first_agent/agent.py`:\n",
       "\n",
       "```python\n",
       "# filename: my_first_agent/agent.py\n",
       "from google.adk.agents import Agent\n",
       "from google.adk.tools import FunctionTool\n",
       "from google.adk.tools.tool_context import ToolContext # <<< Import ToolContext\n",
       "import datetime\n",
       "\n",
       "# --- Constants ---\n",
       "MODEL = \"gemini-2.0-flash-001\"\n",
       "\n",
       "# --- Tool Definition (Updated for State) ---\n",
       "# Add 'tool_context: ToolContext' as the last parameter\n",
       "def get_current_time(tool_context: ToolContext) -> dict:\n",
       "    \"\"\"\n",
       "    Gets the current date and time and stores it in session state.\n",
       "\n",
       "    Use this tool ONLY when the user explicitly asks for the current time or date.\n",
       "    It also updates the 'last_time_checked' value in the session state.\n",
       "\n",
       "    Returns:\n",
       "        A dictionary containing the current date and time string.\n",
       "        Example format: {'current_time': '2024-08-15 14:30:55'}\n",
       "    \"\"\"\n",
       "    print(\"--- Tool: get_current_time executing ---\")\n",
       "\n",
       "    # --- Read from State (using tool_context) ---\n",
       "    # Use .get() to safely retrieve the value, providing a default if the key doesn't exist\n",
       "    last_checked = tool_context.state.get('last_time_checked', 'Never')\n",
       "    print(f\"--- Tool: Value of 'last_time_checked' in state before update: {last_checked} ---\")\n",
       "\n",
       "    # --- Perform Tool's Core Action ---\n",
       "    now = datetime.datetime.now()\n",
       "    time_str = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
       "\n",
       "    # --- Write to State (using tool_context) ---\n",
       "    # Assign the new time string to the state dictionary key\n",
       "    tool_context.state['last_time_checked'] = time_str\n",
       "    # ADK framework will handle saving this change associated with the tool's result event\n",
       "    print(f\"--- Tool: Updated 'last_time_checked' state to: {time_str} ---\")\n",
       "\n",
       "    # Return the primary result of the tool\n",
       "    return {\"current_time\": time_str}\n",
       "\n",
       "# --- Wrap the updated function as a tool ---\n",
       "time_tool = FunctionTool(func=get_current_time)\n",
       "\n",
       "# --- Agent Definition (Updated Instruction) ---\n",
       "root_agent = Agent(\n",
       "    name=\"assistant_with_stateful_time\", # New name reflecting statefulness\n",
       "    model=MODEL,\n",
       "    instruction=\"You are a friendly assistant. Keep answers concise. \"\n",
       "                \"If the user explicitly asks for the current time or date, \"\n",
       "                \"you MUST use the 'get_current_time' tool. \" # Instruction remains focused on tool usage condition\n",
       "                \"This tool internally notes when it was last used. \"\n",
       "                \"Answer other questions directly.\",\n",
       "    tools=[time_tool], # Provide the updated tool instance\n",
       ")\n",
       "\n",
       "# Confirmation message\n",
       "print(f\"Agent '{root_agent.name}' defined using model '{MODEL}' with tools: {[t.name for t in root_agent.tools]}\")\n",
       "```\n",
       "\n",
       "**Running the Agent with State:**\n",
       "\n",
       "1.  Go back to your terminal (make sure you're in the `adk_tutorial` directory).\n",
       "2.  Ensure your virtual environment (`myenv`) is active.\n",
       "3.  Run the agent using the same command:\n",
       "\n",
       "```bash\n",
       "adk run my_first_agent\n",
       "```\n",
       "\n",
       "Now, try this specific sequence of prompts in the interactive chat:\n",
       "\n",
       "1.  `What time is it?`\n",
       "2.  `What time is it again?`\n",
       "3.  `What is the capital of Germany?`\n",
       "\n",
       "**Expected Output & Observation:**\n",
       "\n",
       "*   **First time check:**\n",
       "    *   The agent decides to use the tool.\n",
       "    *   The terminal log shows: `--- Tool: Value of 'last_time_checked' in state before update: Never ---`\n",
       "    *   Then: `--- Tool: Updated 'last_time_checked' state to: <current_time_1> ---`\n",
       "    *   The agent responds with the current time (e.g., \"The current time is `<current_time_1>`.\").\n",
       "*   **Second time check:**\n",
       "    *   The agent uses the tool again.\n",
       "    *   The terminal log shows: `--- Tool: Value of 'last_time_checked' in state before update: <current_time_1> ---` (It successfully read the value saved during the previous turn!).\n",
       "    *   Then: `--- Tool: Updated 'last_time_checked' state to: <current_time_2> ---`\n",
       "    *   The agent responds with the new current time (e.g., \"The current time is `<current_time_2>`.\").\n",
       "*   **Capital of Germany:**\n",
       "    *   The agent should answer directly (\"The capital of Germany is Berlin.\" or similar).\n",
       "    *   The `get_current_time` tool should *not* execute (no \"Tool executing\" logs for this turn).\n",
       "    *   The `last_time_checked` state stored within the session remains `<current_time_2>`.\n",
       "\n",
       "This sequence clearly demonstrates that `session.state` allows the agent (via its tool and `ToolContext`) to maintain and access information across different turns within the same conversation run.\n",
       "\n",
       "**Summary of Stage 3:**\n",
       "You have learned:\n",
       "*   What Session State (`session.state`) is and its role as short-term conversational memory.\n",
       "*   How to access (`tool_context.state.get`) and modify (`tool_context.state['key'] = value`) session state within a tool function using the automatically provided `ToolContext`.\n",
       "*   That ADK handles the persistence of these state changes within the session lifecycle (though `InMemorySessionService` is non-persistent across application restarts).\n",
       "*   Observed state being read and updated across multiple interactions with the agent.\n",
       "\n",
       "Now that we can store and access dynamic information within a conversation using state, we can explore **Callbacks**. Callbacks let us insert custom logic at specific points in the agent's execution – for example, to *react* to the current state before the LLM is called, or to add safety checks before a tool runs.\n",
       "\n",
       "Are you ready to move on to Stage 4 and learn about Callbacks?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## add to chat\n",
    "prompt = (\"Analyst: yes I am ready for the next step.\")\n",
    "response = chat.send_message(message=prompt)\n",
    "\n",
    "# self reflection step\n",
    "p = (\n",
    "  \"Before the analyst views this conduct a thorough review of your output. \"\n",
    "  \"Correct any errors or make improvements and return your output. \"\n",
    ")\n",
    "response = chat.send_message(message=p)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "162e5938-1f00-4e1d-b3d3-1b68c7d4d29b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's ensure Stage 4 is crystal clear.\n",
       "\n",
       "Excellent. Now that our agent can perform actions using tools and remember information using state, let's explore **Callbacks**. These are powerful hooks that let you observe, or even change, what the agent is doing at specific moments during its execution.\n",
       "\n",
       "**Stage 4: Intercepting Execution with Callbacks (`before_model_callback`)**\n",
       "\n",
       "**Concept:** Callbacks are like checkpoints or middleware functions you provide to an agent. ADK automatically runs these functions at predefined points in the agent's process. This allows you to insert your own custom logic without modifying the core ADK framework.\n",
       "\n",
       "There are several types of callbacks. We'll start with `before_model_callback`. This function runs *just before* the agent sends its prepared request (including instructions, history, and the current user query) to the underlying Large Language Model (LLM). It runs *every time* this specific agent is about to call its LLM.\n",
       "\n",
       "**Why use `before_model_callback`?**\n",
       "\n",
       "*   **Logging/Observability:** See exactly what prompt and context are being sent to the LLM for debugging or monitoring.\n",
       "*   **Input Guardrails/Validation:** Check the user's input (which is part of the LLM request) for forbidden topics, sensitive data patterns (like PII), or policy violations, and potentially block the LLM call if needed.\n",
       "*   **Dynamic Prompt Engineering:** Add timely information from the current `session.state` (like user preferences or recent events) to the request context just before sending it to the LLM.\n",
       "\n",
       "**How it works:**\n",
       "\n",
       "1.  **Define the Function:** Create a Python function that **must** accept two specific arguments:\n",
       "    *   `callback_context: CallbackContext`: Provides access to runtime information like the agent's name, the unique ID for the current request (`invocation_id`), and crucially, the session `state` (`callback_context.state`).\n",
       "    *   `llm_request: LlmRequest`: Contains the *complete payload* that ADK is about to send to the LLM. This includes the conversation history (`llm_request.contents`) and model configuration (`llm_request.config`, which contains the `system_instruction`).\n",
       "2.  **Implement Logic:** Inside your callback function:\n",
       "    *   You can **read** `callback_context.state`.\n",
       "    *   You can **inspect** `llm_request` data.\n",
       "    *   You can **modify** mutable parts of the `llm_request` object (like the `system_instruction` within `llm_request.config`).\n",
       "    *   **Control the Flow** using the return value:\n",
       "        *   `return None`: This is the standard signal to ADK. It means your callback has finished, and ADK should **proceed** to call the LLM with the `llm_request` (which might have been modified by your callback).\n",
       "        *   `return LlmResponse(...)`: If your callback returns an `LlmResponse` object, ADK **skips the actual LLM call entirely**. The `LlmResponse` you provide is treated *as if* it came from the LLM, and the agent's execution continues based on that response. This is the mechanism for implementing blocking guardrails.\n",
       "\n",
       "**Implementation:**\n",
       "\n",
       "1.  **Define the Callback Function:** We'll create `log_and_prefix_callback`. This function will:\n",
       "    *   Print log messages indicating it's running.\n",
       "    *   Read the `last_time_checked` value from the session state via `callback_context.state`.\n",
       "    *   Add a dynamic prefix (including the `last_time_checked` value) to the beginning of the `system_instruction` within the `llm_request.config`.\n",
       "2.  **Update the Agent Definition:** Modify the `root_agent` definition to include the `before_model_callback` parameter, assigning our new function to it.\n",
       "\n",
       "Here's the updated `my_first_agent/agent.py`:\n",
       "\n",
       "```python\n",
       "# filename: my_first_agent/agent.py\n",
       "from google.adk.agents import Agent\n",
       "from google.adk.tools import FunctionTool\n",
       "from google.adk.tools.tool_context import ToolContext\n",
       "# Imports needed for the callback\n",
       "from google.adk.agents.callback_context import CallbackContext # <<< For context argument\n",
       "from google.adk.models.llm_request import LlmRequest           # <<< For request argument\n",
       "from google.adk.models.llm_response import LlmResponse         # <<< For optional blocking return\n",
       "from google.genai import types                                 # <<< For creating/modifying Content\n",
       "from typing import Optional                                    # <<< For return type hint (Optional[LlmResponse])\n",
       "import datetime\n",
       "\n",
       "# --- Constants ---\n",
       "MODEL = \"gemini-2.0-flash-001\"\n",
       "\n",
       "# --- Tool Definition (from Stage 3) ---\n",
       "def get_current_time(tool_context: ToolContext) -> dict:\n",
       "    \"\"\"Gets the current date and time and stores it in session state.\"\"\"\n",
       "    print(\"--- Tool: get_current_time executing ---\")\n",
       "    last_checked = tool_context.state.get('last_time_checked', 'Never')\n",
       "    print(f\"--- Tool: Value of 'last_time_checked' in state before update: {last_checked} ---\")\n",
       "    now = datetime.datetime.now()\n",
       "    time_str = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
       "    tool_context.state['last_time_checked'] = time_str\n",
       "    print(f\"--- Tool: Updated 'last_time_checked' state to: {time_str} ---\")\n",
       "    return {\"current_time\": time_str}\n",
       "\n",
       "time_tool = FunctionTool(func=get_current_time)\n",
       "\n",
       "# --- Callback Definition ---\n",
       "def log_and_prefix_callback(\n",
       "    callback_context: CallbackContext, llm_request: LlmRequest\n",
       ") -> Optional[LlmResponse]: # Return type hint\n",
       "    \"\"\"\n",
       "    Logs context info, reads state, modifies the LLM request's system\n",
       "    instruction, and allows the call to proceed.\n",
       "    \"\"\"\n",
       "    agent_name = callback_context.agent_name\n",
       "    invocation_id = callback_context.invocation_id\n",
       "    # Read state via the callback context\n",
       "    last_checked = callback_context.state.get('last_time_checked', 'Not checked yet')\n",
       "\n",
       "    print(f\"\\n--- Callback: before_model_callback executing for Agent '{agent_name}' (Invocation: {invocation_id}) ---\")\n",
       "    print(f\"--- Callback: Last time checked (from state read): {last_checked} ---\")\n",
       "\n",
       "    # --- Modify the request's system instruction ---\n",
       "    prefix = f\"[Callback Info: Last time check was {last_checked}] \"\n",
       "    try:\n",
       "        # Ensure config exists\n",
       "        if not llm_request.config:\n",
       "            llm_request.config = types.GenerationConfig() # Create if missing (unlikely but safe)\n",
       "            print(\"--- Callback WARNING: llm_request.config was missing, created new. ---\")\n",
       "\n",
       "        # Get or create system_instruction as Content object\n",
       "        sys_instruction = llm_request.config.system_instruction\n",
       "        if not sys_instruction:\n",
       "            sys_instruction = types.Content(role=\"system\", parts=[types.Part(text=\"\")])\n",
       "        elif isinstance(sys_instruction, str): # Convert if string\n",
       "             sys_instruction = types.Content(role=\"system\", parts=[types.Part(text=sys_instruction)])\n",
       "        elif not isinstance(sys_instruction, types.Content):\n",
       "             # If it's some other unexpected type, log a warning and don't modify\n",
       "             print(f\"--- Callback WARNING: Unexpected type for system_instruction: {type(sys_instruction)}. Cannot modify. ---\")\n",
       "             return None # Allow call to proceed without modification\n",
       "\n",
       "        # Ensure parts list exists\n",
       "        if not sys_instruction.parts:\n",
       "            sys_instruction.parts.append(types.Part(text=\"\"))\n",
       "\n",
       "        # Prepend prefix to the first part's text\n",
       "        original_text = sys_instruction.parts[0].text or \"\"\n",
       "        sys_instruction.parts[0].text = prefix + original_text\n",
       "        llm_request.config.system_instruction = sys_instruction # Assign back modified object\n",
       "        print(f\"--- Callback: Modified system instruction to start with: '{prefix}' ---\")\n",
       "\n",
       "    except Exception as e:\n",
       "        print(f\"--- Callback ERROR: Failed to modify system instruction: {e} ---\")\n",
       "        # Decide whether to block or allow if modification fails\n",
       "        # return LlmResponse(...) # Block\n",
       "        return None # Allow proceed cautiously\n",
       "\n",
       "    # --- Control Flow Decision ---\n",
       "    # Return None signals ADK to proceed with the LLM call using the (now modified) llm_request\n",
       "    print(\"--- Callback: Returning None to allow LLM call. ---\")\n",
       "    return None\n",
       "\n",
       "    # # --- Example: How to BLOCK the LLM call ---\n",
       "    # # Check some condition (e.g., based on user input in llm_request.contents)\n",
       "    # latest_user_input = llm_request.contents[-1].parts[0].text if llm_request.contents else \"\"\n",
       "    # if \"FORBIDDEN_WORD\" in latest_user_input.upper():\n",
       "    #     print(\"--- Callback: Blocking request due to forbidden word! ---\")\n",
       "    #     # Create and return an LlmResponse object\n",
       "    #     blocking_response = LlmResponse(\n",
       "    #         content=types.Content(\n",
       "    #             role=\"model\", # Respond as the model\n",
       "    #             parts=[types.Part(text=\"I cannot process this request due to policy violations.\")]\n",
       "    #         )\n",
       "    #     )\n",
       "    #     return blocking_response\n",
       "    # # -------------------------------------------\n",
       "\n",
       "# --- Agent Definition (Updated with Callback) ---\n",
       "root_agent = Agent(\n",
       "    name=\"assistant_with_callback\", # Updated agent name\n",
       "    model=MODEL,\n",
       "    # Base instruction for the LLM (will be prefixed by the callback)\n",
       "    instruction=\"You are a friendly assistant. Keep answers concise. \"\n",
       "                \"If the user asks for the current time or date, use the 'get_current_time' tool. \"\n",
       "                \"Answer other questions directly.\",\n",
       "    tools=[time_tool],\n",
       "    # Assign the callback function to the agent's parameter\n",
       "    before_model_callback=log_and_prefix_callback,\n",
       ")\n",
       "\n",
       "print(f\"Agent '{root_agent.name}' defined using model '{MODEL}' with callback and tools: {[t.name for t in root_agent.tools]}\")\n",
       "```\n",
       "\n",
       "**Running the Agent with the Callback:**\n",
       "\n",
       "1.  Return to your terminal (in the `adk_tutorial` directory).\n",
       "2.  Make sure your virtual environment (`myenv`) is active.\n",
       "3.  Run the agent:\n",
       "\n",
       "```bash\n",
       "adk run my_first_agent\n",
       "```\n",
       "\n",
       "Now, try this specific sequence in the chat:\n",
       "\n",
       "1.  `What time is it?` (This will run the tool and set the `last_time_checked` state).\n",
       "2.  `What is the capital of Germany?` (This should trigger the callback *before* the LLM is called to answer the question).\n",
       "\n",
       "**Expected Output & Observation:**\n",
       "\n",
       "*   **First time check:**\n",
       "    *   You'll see the `--- Callback: before_model_callback executing...` log message.\n",
       "    *   It will print `--- Callback: Last time checked (from state read): Not checked yet ---`.\n",
       "    *   It will print the message about modifying the system instruction.\n",
       "    *   The agent will then decide to use the tool.\n",
       "    *   The tool logs will appear (`--- Tool: get_current_time executing ---`, etc.), updating the state to `<current_time_1>`.\n",
       "    *   The agent will provide the time response.\n",
       "*   **Capital of Germany:**\n",
       "    *   The `before_model_callback` executes again.\n",
       "    *   This time, it prints `--- Callback: Last time checked (from state read): <current_time_1> ---` (demonstrating it read the state value set in the previous turn!).\n",
       "    *   It modifies the system instruction again, prepending `[Callback Info: Last time check was <current_time_1>] `.\n",
       "    *   It prints `--- Callback: Returning None to allow LLM call. ---`.\n",
       "    *   The LLM receives the request (with the modified system instruction) and generates the answer about Berlin.\n",
       "    *   The agent responds, \"The capital of Germany is Berlin.\" (The LLM likely ignores the informational prefix we added, but the callback *did* successfully run, access state, and modify the request before the LLM saw it).\n",
       "\n",
       "This sequence confirms that the callback intercepted the flow before the LLM call, accessed session state, modified the outgoing request, and correctly allowed the LLM call to proceed by returning `None`.\n",
       "\n",
       "**Summary of Stage 4:**\n",
       "You have now:\n",
       "*   Learned the concept of Callbacks in ADK and the purpose of `before_model_callback`.\n",
       "*   Defined a `before_model_callback` function with the required signature (`callback_context`, `llm_request`).\n",
       "*   Used `CallbackContext` to read session state within the callback.\n",
       "*   Used `LlmRequest` to inspect and *modify* the data being sent to the LLM (specifically, the `system_instruction`).\n",
       "*   Understood how returning `None` allows the LLM call to proceed, while returning an `LlmResponse` would block it (as shown in the commented-out example code).\n",
       "*   Observed the callback executing and interacting with state during an agent run.\n",
       "\n",
       "Callbacks are essential tools for adding custom logic, validation, logging, and safety layers to your agents.\n",
       "\n",
       "Are you ready for the next stage? We could explore another callback type like `before_tool_callback` for adding guardrails *specifically around tool usage*, or would you prefer to dive into building a **multi-agent system** where agents can delegate tasks to each other?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## add to chat\n",
    "prompt = (\"Analyst: yes I am ready for the next step.\")\n",
    "response = chat.send_message(message=prompt)\n",
    "\n",
    "# self reflection step\n",
    "p = (\n",
    "  \"Before the analyst views this conduct a thorough review of your output. \"\n",
    "  \"Correct any errors or make improvements and return your output. \"\n",
    ")\n",
    "response = chat.send_message(message=p)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63f874fe-32b3-45ac-bc24-d23d704e224f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's ensure Stage 5 is polished and easy to follow.\n",
       "\n",
       "Great, let's add another layer of control using a different type of callback.\n",
       "\n",
       "**Stage 5: Adding Tool Guardrails with `before_tool_callback`**\n",
       "\n",
       "**Concept:** In Stage 4, we used `before_model_callback` to intervene *before* the LLM thinks. Now, we'll use `before_tool_callback`. This runs *after* the LLM has decided which tool to use and what arguments to give it, but crucially, *just before* the tool's actual Python function is executed.\n",
       "\n",
       "**Why use `before_tool_callback`?**\n",
       "\n",
       "*   **Argument Validation:** Check if the arguments the LLM generated are valid (e.g., correct format, within allowed ranges, not malicious).\n",
       "*   **Tool-Specific Guardrails:** Prevent the tool from running based on specific inputs (like blocking a certain city in our weather tool) or the current session state (e.g., \"User is not authorized for this action\").\n",
       "*   **Resource Protection:** Stop potentially expensive, rate-limited, or harmful tool executions before they happen.\n",
       "*   **Dynamic Argument Injection/Modification:** Adjust the arguments based on session state right before the tool function receives them.\n",
       "\n",
       "**How it works:**\n",
       "\n",
       "1.  **Define the Function:** Create a Python function that **must** accept three specific arguments:\n",
       "    *   `tool: BaseTool`: The specific ADK tool object (like our `FunctionTool` instance) that is about to be executed. You can inspect properties like `tool.name`.\n",
       "    *   `args: Dict[str, Any]`: The dictionary of arguments that the LLM generated for the tool call.\n",
       "    *   `tool_context: ToolContext`: Provides access to the session `state` (`tool_context.state`) and other contextual information related to this specific tool invocation.\n",
       "2.  **Implement Logic:** Inside your callback function:\n",
       "    *   You can **inspect** `tool.name` and the `args` dictionary.\n",
       "    *   You can **read** `tool_context.state`.\n",
       "    *   You can **modify** the `args` dictionary directly. If your callback returns `None`, the tool function will be called with these (potentially modified) arguments.\n",
       "    *   **Control the Flow** using the return value:\n",
       "        *   `return None`: This signals ADK to **proceed** and execute the actual tool function (`get_current_time` in our case) with the `args` provided (or modified by the callback).\n",
       "        *   `return dict(...)`: If your callback returns a **dictionary**, ADK **skips executing the actual tool function**. The dictionary you return is treated *as if* it were the result of the tool call. This is the mechanism for blocking or overriding tool execution. It's best practice for this dictionary to match the structure the blocked tool normally returns (e.g., include a `status` and `error_message`).\n",
       "\n",
       "**Implementation:**\n",
       "\n",
       "1.  **Define the Tool Callback Function:** We'll create `check_allow_time_tool_callback`. This function checks a flag `allow_time_checks` in the session state. If the flag exists and is `False`, it blocks the `get_current_time` tool by returning an error dictionary. Otherwise, it allows the tool to run.\n",
       "2.  **Update the Agent Definition:** Modify the `root_agent` definition again to include *both* the `before_model_callback` (from Stage 4, improved for safety) and this new `before_tool_callback`.\n",
       "\n",
       "Here's the updated `my_first_agent/agent.py`:\n",
       "\n",
       "```python\n",
       "# filename: my_first_agent/agent.py\n",
       "from google.adk.agents import Agent\n",
       "from google.adk.tools import FunctionTool, BaseTool # <<< Import BaseTool for type hint\n",
       "from google.adk.tools.tool_context import ToolContext\n",
       "from google.adk.agents.callback_context import CallbackContext\n",
       "from google.adk.models.llm_request import LlmRequest\n",
       "from google.adk.models.llm_response import LlmResponse\n",
       "from google.genai import types\n",
       "from typing import Optional, Dict, Any # <<< Added Dict, Any for type hints\n",
       "import datetime\n",
       "import copy # <<< Import copy for safe request modification\n",
       "\n",
       "# --- Constants ---\n",
       "MODEL = \"gemini-2.0-flash-001\"\n",
       "\n",
       "# --- Tool Definition (from Stage 3) ---\n",
       "def get_current_time(tool_context: ToolContext) -> dict:\n",
       "    \"\"\"Gets the current date and time and stores it in session state.\"\"\"\n",
       "    print(\"--- Tool: get_current_time executing ---\")\n",
       "    last_checked = tool_context.state.get('last_time_checked', 'Never')\n",
       "    print(f\"--- Tool: Value of 'last_time_checked' in state before update: {last_checked} ---\")\n",
       "    now = datetime.datetime.now()\n",
       "    time_str = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
       "    tool_context.state['last_time_checked'] = time_str\n",
       "    print(f\"--- Tool: Updated 'last_time_checked' state to: {time_str} ---\")\n",
       "    return {\"current_time\": time_str}\n",
       "\n",
       "time_tool = FunctionTool(func=get_current_time)\n",
       "\n",
       "# --- Callback Definition 1 (Improved from Stage 4) ---\n",
       "def log_and_prefix_callback(\n",
       "    callback_context: CallbackContext, llm_request: LlmRequest\n",
       ") -> Optional[LlmResponse]:\n",
       "    \"\"\"Logs info, reads state, modifies sys instruction safely, allows proceed.\"\"\"\n",
       "    agent_name = callback_context.agent_name\n",
       "    invocation_id = callback_context.invocation_id\n",
       "    last_checked = callback_context.state.get('last_time_checked', 'Not checked yet')\n",
       "    print(f\"\\n--- Callback(Model): before_model_callback for Agent '{agent_name}' (Inv: {invocation_id}) ---\")\n",
       "    print(f\"--- Callback(Model): Last time checked (state read): {last_checked} ---\")\n",
       "    prefix = f\"[Callback Info: Last time check was {last_checked}] \"\n",
       "    try:\n",
       "        if llm_request.config:\n",
       "            # Use deepcopy to avoid modifying the original config object directly\n",
       "            new_config = copy.deepcopy(llm_request.config)\n",
       "            sys_instruction = new_config.system_instruction\n",
       "            # Safely prepare Content object\n",
       "            if not sys_instruction:\n",
       "                sys_instruction = types.Content(role=\"system\", parts=[types.Part(text=\"\")])\n",
       "            elif isinstance(sys_instruction, str):\n",
       "                sys_instruction = types.Content(role=\"system\", parts=[types.Part(text=sys_instruction)])\n",
       "            elif not isinstance(sys_instruction, types.Content):\n",
       "                 print(f\"--- Callback(Model) WARNING: Unexpected type for system_instruction: {type(sys_instruction)}. Not modifying. ---\")\n",
       "                 return None\n",
       "            if not sys_instruction.parts:\n",
       "                sys_instruction.parts.append(types.Part(text=\"\"))\n",
       "            # Modify the copy\n",
       "            original_text = sys_instruction.parts[0].text or \"\"\n",
       "            sys_instruction.parts[0].text = prefix + original_text\n",
       "            # Assign the modified copy back to the request\n",
       "            llm_request.config = new_config\n",
       "            print(f\"--- Callback(Model): Modified system instruction prefix: '{prefix}' ---\")\n",
       "        else:\n",
       "            print(\"--- Callback(Model) WARNING: llm_request.config missing. ---\")\n",
       "    except Exception as e:\n",
       "        print(f\"--- Callback(Model) ERROR: Failed to modify sys instruction: {e} ---\")\n",
       "        return None # Allow proceed cautiously\n",
       "    print(\"--- Callback(Model): Returning None to allow LLM call. ---\")\n",
       "    return None\n",
       "\n",
       "# --- Callback Definition 2 (New for Stage 5) ---\n",
       "def check_allow_time_tool_callback(\n",
       "    tool: BaseTool, args: Dict[str, Any], tool_context: ToolContext\n",
       ") -> Optional[Dict]:\n",
       "    \"\"\"\n",
       "    Checks 'allow_time_checks' state. If False, blocks 'get_current_time' tool.\n",
       "    Otherwise allows it.\n",
       "    \"\"\"\n",
       "    tool_name = tool.name\n",
       "    agent_name = tool_context.agent_name\n",
       "    print(f\"\\n--- Callback(Tool): before_tool_callback for Tool '{tool_name}' (Agent: {agent_name}) ---\")\n",
       "    print(f\"--- Callback(Tool): Args received from LLM: {args} ---\")\n",
       "\n",
       "    # --- Guardrail Logic Specific to 'get_current_time' ---\n",
       "    if tool_name == 'get_current_time':\n",
       "        # Read the flag from session state, default to True if not set\n",
       "        allow_checks = tool_context.state.get('allow_time_checks', True)\n",
       "        print(f\"--- Callback(Tool): 'allow_time_checks' state is currently: {allow_checks} ---\")\n",
       "\n",
       "        if not allow_checks:\n",
       "            print(f\"--- Callback(Tool): Blocking tool '{tool_name}' because 'allow_time_checks' is False! ---\")\n",
       "            # Return a dictionary matching the tool's expected output format (or similar error structure)\n",
       "            # This dictionary becomes the tool's result, SKIPPING the actual tool run.\n",
       "            return {\n",
       "                \"status\": \"blocked_by_policy\", # Custom status\n",
       "                \"error_message\": \"Sorry, checking the time is currently disabled by system policy.\"\n",
       "            }\n",
       "        else:\n",
       "            print(f\"--- Callback(Tool): 'allow_time_checks' is True. Allowing tool '{tool_name}' to run. ---\")\n",
       "    else:\n",
       "        # If the callback is triggered for a different tool, ignore it.\n",
       "         print(f\"--- Callback(Tool): Tool '{tool_name}' is not 'get_current_time'. No action taken by this callback. ---\")\n",
       "\n",
       "    # Return None to signal ADK to execute the actual tool function\n",
       "    print(\"--- Callback(Tool): Returning None to allow tool execution. ---\")\n",
       "    return None\n",
       "\n",
       "# --- Agent Definition (Updated with BOTH Callbacks) ---\n",
       "root_agent = Agent(\n",
       "    name=\"assistant_with_dual_callbacks\", # New name reflecting both callbacks\n",
       "    model=MODEL,\n",
       "    instruction=\"You are a friendly assistant. Keep answers concise. \"\n",
       "                \"If the user asks for the current time or date, use the 'get_current_time' tool. \"\n",
       "                \"Answer other questions directly.\",\n",
       "    tools=[time_tool],\n",
       "    before_model_callback=log_and_prefix_callback,   # <<< Keep Stage 4 callback\n",
       "    before_tool_callback=check_allow_time_tool_callback, # <<< Add Stage 5 callback\n",
       ")\n",
       "\n",
       "print(f\"Agent '{root_agent.name}' defined using model '{MODEL}' with BOTH callbacks and tools: {[t.name for t in root_agent.tools]}\")\n",
       "```\n",
       "\n",
       "**Running the Agent with the Tool Callback:**\n",
       "\n",
       "1.  Go back to your terminal (in `adk_tutorial`), activate `myenv`.\n",
       "2.  Run the agent:\n",
       "\n",
       "```bash\n",
       "adk run my_first_agent\n",
       "```\n",
       "\n",
       "**Testing the Flow:**\n",
       "\n",
       "This requires simulating the change in the `allow_time_checks` state flag. Since `adk run` uses `InMemorySessionService`, the state is reset each time you start it. Here’s how to understand the *intended* flow and how you might test it:\n",
       "\n",
       "1.  **Run 1 (Checks Allowed):**\n",
       "    *   Start `adk run my_first_agent`.\n",
       "    *   Ask: `What time is it?`\n",
       "    *   **Observe:**\n",
       "        *   `before_model_callback` runs and modifies the instruction.\n",
       "        *   LLM requests `get_current_time`.\n",
       "        *   `before_tool_callback` runs, reads `allow_time_checks` (defaults to `True`), logs \"Checks allowed...\", and returns `None`.\n",
       "        *   The actual `get_current_time` tool executes and updates the `last_time_checked` state.\n",
       "        *   The agent responds with the time.\n",
       "    *   Stop the agent (`Ctrl+C`).\n",
       "\n",
       "2.  **Run 2 (Simulating Checks Disabled):**\n",
       "    *   **Option A (Modify Code Temporarily for Test):** Change the `check_allow_time_tool_callback` function. Inside the `if tool_name == 'get_current_time':` block, temporarily *remove* the check for `allow_checks` and *always* return the blocking dictionary:\n",
       "        ```python\n",
       "        # Inside check_allow_time_tool_callback, for testing block:\n",
       "        if tool_name == 'get_current_time':\n",
       "             print(f\"--- Callback(Tool): FORCING BLOCK for testing! ---\")\n",
       "             return {\n",
       "                 \"status\": \"blocked_by_policy\",\n",
       "                 \"error_message\": \"Sorry, checking the time is currently disabled (TEST BLOCK).\"\n",
       "             }\n",
       "        # ... rest of the function ...\n",
       "        ```\n",
       "        *Then* start `adk run my_first_agent` and ask `What time is it?`. You should see the \"Blocking tool...\" log and the agent relaying the error message. Remember to revert the code change afterwards!\n",
       "    *   **Option B (Add a State-Setting Tool - More Advanced):** You could define *another* tool like `def set_policy(allow: bool, tool_context: ToolContext): tool_context.state['allow_time_checks'] = allow; return {'status': 'policy updated'}`, add it to the agent, start `adk run`, first ask the agent `Set time check policy to false`, and *then* ask `What time is it?`. This is closer to a real-world scenario but adds complexity for this stage.\n",
       "\n",
       "**Expected Output & Observation (Focusing on the blocking scenario):**\n",
       "\n",
       "*   `before_model_callback` runs as usual.\n",
       "*   LLM requests `get_current_time`.\n",
       "*   `before_tool_callback` runs.\n",
       "    *   It reads `allow_time_checks` as `False` (or hits the forced block in Option A).\n",
       "    *   It prints the \"Blocking tool...\" message.\n",
       "    *   It returns the error dictionary: `{'status': 'blocked_by_policy', 'error_message': 'Sorry...'}`.\n",
       "*   The actual `get_current_time` Python function **does not execute**. No tool execution logs appear for it.\n",
       "*   The agent receives the error dictionary from the callback *as if* it were the result from the tool.\n",
       "*   The agent formulates its final response based on this error information (e.g., \"Sorry, checking the time is currently disabled by system policy.\").\n",
       "\n",
       "This demonstrates how `before_tool_callback` provides a precise control point to enforce policies or validate arguments *before* a tool's potentially costly or sensitive code is run.\n",
       "\n",
       "**Summary of Stage 5:**\n",
       "You have now:\n",
       "*   Learned about `before_tool_callback` and its role as a guardrail *before* tool execution.\n",
       "*   Defined a callback function with the required signature (`tool`, `args`, `tool_context`).\n",
       "*   Used `ToolContext` to access session state within this tool-specific callback.\n",
       "*   Understood how returning a dictionary from the callback blocks the actual tool function and provides an alternative result.\n",
       "*   Configured an agent with multiple callbacks (`before_model_callback` and `before_tool_callback`) working together.\n",
       "*   Observed (or simulated the observation of) how the `before_tool_callback` can prevent tool execution based on session state.\n",
       "\n",
       "You're building a solid understanding of how to layer control and custom logic into your agents using ADK's callback system!\n",
       "\n",
       "What concept would you like to tackle next? We could look at:\n",
       "\n",
       "a)  **Multi-Agent Systems:** Building a small team where agents delegate tasks.\n",
       "b)  **Workflow Agents:** Using agents like `SequentialAgent` to define fixed execution sequences.\n",
       "c)  **Artifacts:** Handling file uploads/downloads."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## add to chat\n",
    "prompt = (\"Analyst: yes I am ready for the next step.\")\n",
    "response = chat.send_message(message=prompt)\n",
    "\n",
    "# self reflection step\n",
    "p = (\n",
    "  \"Before the analyst views this conduct a thorough review of your output. \"\n",
    "  \"Correct any errors or make improvements and return your output. \"\n",
    ")\n",
    "response = chat.send_message(message=p)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d223a522-1980-4d8a-a3db-422a036e8ced",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's review and refine Stage 6.\n",
       "\n",
       "Alright, let's dive into **Multi-Agent Systems**. This is where ADK really starts to shine, allowing you to build more complex and organized applications by having multiple agents work together as a team.\n",
       "\n",
       "**Stage 6: Building a Team - Delegation with Sub-Agents**\n",
       "\n",
       "**Concept:** Instead of making one monolithic agent handle everything (greetings, checking time, weather, calculations, etc.), we can create *specialized* agents for specific tasks and a \"manager\" or \"root\" agent that decides which specialist should handle the user's request.\n",
       "\n",
       "*   **Root Agent:** The main entry point for user interaction. It analyzes the incoming request and decides whether to handle it directly using its *own* tools or to delegate it to a specialist.\n",
       "*   **Sub-Agents:** These are the specialists, each designed and instructed for a particular capability (e.g., an agent *just* for greetings, another *just* for database lookups).\n",
       "*   **Delegation:** The process where the root agent passes control of the current conversational turn to a sub-agent that is better suited for the specific task identified in the user's request.\n",
       "\n",
       "**Why use multiple agents?**\n",
       "\n",
       "*   **Modularity:** It's much easier to develop, test, debug, and update smaller, focused agents than one giant, complex agent.\n",
       "*   **Specialization:** Each agent can have highly tailored instructions, specific tools, and even use different LLM models optimized for its task (e.g., a faster/cheaper model for simple greetings, a more powerful model for complex reasoning).\n",
       "*   **Organization & Scalability:** Keeps the logic for complex applications cleaner and makes it easier to add new capabilities by simply adding new specialist agents to the team.\n",
       "\n",
       "**How ADK Handles Delegation (Auto Flow):**\n",
       "\n",
       "1.  **Define Hierarchy (`sub_agents` List):** When you define the root agent, you provide a list of the specialist agent instances in its `sub_agents` parameter. This establishes the team structure.\n",
       "2.  **Sub-Agent `description` is Key:** The `description` field you give each sub-agent is **critical**. The root agent's LLM reads these descriptions to understand *what each specialist can do*. Make these concise and accurate.\n",
       "3.  **Root Agent `instruction` Guides Delegation:** You must instruct the root agent *about* its team. Tell it which sub-agents exist (referencing them by their `name`) and *under what conditions* it should delegate a task to them.\n",
       "4.  **Automatic Transfer Mechanism:** When the root agent receives a request, its LLM analyzes the request against its own instructions, its tools, *and* the `description`s of its sub-agents. If the LLM determines the request best fits a sub-agent's capability, ADK's runtime (sometimes called \"Auto Flow\" in this context) automatically handles the transfer of control to that sub-agent *for that specific turn*. The sub-agent then processes the request using its own model, instructions, and tools.\n",
       "\n",
       "**Implementation:**\n",
       "\n",
       "1.  **Define Specialist Tools:** We need a simple `say_hello` tool for our new `greeting_agent`. We'll keep the `get_current_time` tool for the root agent.\n",
       "2.  **Define the Specialist Sub-Agent:** Create the `greeting_agent`, giving it a clear `name`, `description`, focused `instruction`, and only the `hello_tool`.\n",
       "3.  **Update the Root Agent:**\n",
       "    *   Give it a new, representative `name` (e.g., `team_coordinator`).\n",
       "    *   Add the `greeting_agent` instance to its `sub_agents` list.\n",
       "    *   Modify its `instruction` to explicitly mention the `greeting_specialist` (by name) and the conditions for delegation (\"If the user gives a greeting...\").\n",
       "    *   Ensure the root agent keeps the `time_tool` for tasks it handles directly.\n",
       "    *   Remove the callbacks from the previous stage to focus purely on the delegation mechanism.\n",
       "\n",
       "Here's the updated `my_first_agent/agent.py`:\n",
       "\n",
       "```python\n",
       "# filename: my_first_agent/agent.py\n",
       "from google.adk.agents import Agent\n",
       "from google.adk.tools import FunctionTool, BaseTool # BaseTool needed if type hinting tool arg\n",
       "from google.adk.tools.tool_context import ToolContext\n",
       "# Callbacks and related imports removed for this stage's clarity\n",
       "import datetime\n",
       "from typing import Dict, Any # Type hints for tool args\n",
       "\n",
       "# --- Constants ---\n",
       "MODEL = \"gemini-2.0-flash-001\"\n",
       "\n",
       "# --- Tool Definitions ---\n",
       "\n",
       "# Tool kept by the Root Agent\n",
       "def get_current_time(tool_context: ToolContext) -> dict:\n",
       "    \"\"\"Gets the current date and time.\"\"\"\n",
       "    print(f\"--- Tool: get_current_time executing (Called by: {tool_context.agent_name}) ---\")\n",
       "    now = datetime.datetime.now()\n",
       "    time_str = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
       "    # State update is optional here, kept from previous stage\n",
       "    tool_context.state['last_time_checked_root'] = time_str\n",
       "    return {\"current_time\": time_str}\n",
       "\n",
       "time_tool = FunctionTool(func=get_current_time)\n",
       "\n",
       "# Tool specifically for the Greeting Sub-Agent\n",
       "def say_hello(name: str = \"there\") -> dict:\n",
       "    \"\"\"Provides a friendly greeting, optionally using a name.\"\"\"\n",
       "    # Log which agent is calling this tool\n",
       "    # (Requires ToolContext, but let's keep this simple for now)\n",
       "    # We can infer based on which agent has the tool\n",
       "    print(f\"--- Tool: say_hello executing (Expected Call by: greeting_specialist) with name: {name} ---\")\n",
       "    return {\"greeting\": f\"Hello, {name}! Great to connect.\"}\n",
       "\n",
       "hello_tool = FunctionTool(func=say_hello)\n",
       "\n",
       "\n",
       "# --- Sub-Agent Definition ---\n",
       "greeting_agent = Agent(\n",
       "    name=\"greeting_specialist\", # <<< Unique name, used for delegation reference\n",
       "    model=MODEL, # Can use the same or a different (e.g., cheaper) model\n",
       "    # CRITICAL: Description helps the root agent decide WHEN to delegate.\n",
       "    description=\"Use ONLY for handling simple user greetings like 'Hi', 'Hello', 'Good morning'.\",\n",
       "    instruction=\"You are the Greeting Specialist. Your ONLY task is to provide a \"\n",
       "                \"friendly greeting using the 'say_hello' tool. Extract the user's \"\n",
       "                \"name if provided in their greeting (pass it to the tool's 'name' arg). \"\n",
       "                \"Do not answer any other type of question.\",\n",
       "    tools=[hello_tool], # Specialist only gets the tools it needs\n",
       ")\n",
       "\n",
       "\n",
       "# --- Root Agent Definition (Updated for Delegation) ---\n",
       "root_agent = Agent(\n",
       "    name=\"team_coordinator\", # <<< New name for the root/manager agent\n",
       "    model=MODEL, # This agent orchestrates, might need a capable model\n",
       "    description=\"The main coordinator agent. Handles time requests directly using its own tool, and delegates greeting requests to a specialist.\", # Describes its own role\n",
       "    instruction=\"You are the main assistant and team coordinator. Your primary role is to check the time using the 'get_current_time' tool when asked. \"\n",
       "                \"You also manage a specialist sub-agent:\\n\"\n",
       "                \"- 'greeting_specialist': This agent handles simple user greetings (like 'hello', 'hi').\\n\\n\" # <<< Explicitly mention sub-agent by name\n",
       "                \"CRITICAL Instructions:\\n\"\n",
       "                \"1. If the user's message is clearly a greeting, **delegate** the task to the 'greeting_specialist'.\\n\" # <<< Guide delegation\n",
       "                \"2. If the user asks specifically for the current time or date, handle it **yourself** using your 'get_current_time' tool.\\n\"\n",
       "                \"3. For any other type of request, state politely that you can only handle time requests or greetings.\",\n",
       "    tools=[time_tool], # Root agent keeps tools for tasks it handles directly\n",
       "    sub_agents=[greeting_agent], # <<< List the sub-agent instances here\n",
       "    # Callbacks removed for clarity in this stage\n",
       ")\n",
       "\n",
       "# Confirmation messages\n",
       "print(f\"Root Agent '{root_agent.name}' defined with Sub-Agent: '{greeting_agent.name}'\")\n",
       "print(f\"Root Agent Tools: {[t.name for t in root_agent.tools]}\")\n",
       "print(f\"Sub-Agent '{greeting_agent.name}' Tools: {[t.name for t in greeting_agent.tools]}\")\n",
       "\n",
       "```\n",
       "\n",
       "**Running the Agent Team:**\n",
       "\n",
       "1.  Ensure you are in the `adk_tutorial` directory in your terminal.\n",
       "2.  Make sure your `myenv` virtual environment is active.\n",
       "3.  Run the agent using the same command (it automatically loads the variable named `root_agent` from your package):\n",
       "\n",
       "```bash\n",
       "adk run my_first_agent\n",
       "```\n",
       "\n",
       "Now, let's specifically test the delegation logic:\n",
       "\n",
       "1.  `Hello there!` (Should trigger delegation to `greeting_specialist`)\n",
       "2.  `What time is it?` (Should be handled directly by `team_coordinator`)\n",
       "3.  `Hi, can you tell me the time?` (Interesting case - observe which agent/tool runs!)\n",
       "4.  `What is the capital of France?` (Should be declined by `team_coordinator` based on its instructions).\n",
       "\n",
       "**Expected Output & Observation:**\n",
       "\n",
       "*   **Prompt 1 (`Hello there!`):**\n",
       "    *   The `team_coordinator` (root) receives the prompt.\n",
       "    *   Its LLM reads the instruction (\"If the user's message is clearly a greeting, delegate...\") and sees the `greeting_specialist`'s `description` (\"Use ONLY for handling simple user greetings...\").\n",
       "    *   The LLM decides to delegate. ADK runtime automatically transfers control.\n",
       "    *   The `greeting_specialist` agent receives the prompt \"Hello there!\".\n",
       "    *   Its LLM reads its instruction (\"Your ONLY task is to provide a friendly greeting using 'say_hello' tool...\").\n",
       "    *   It decides to use the `say_hello` tool (possibly passing \"there\" or no name).\n",
       "    *   You see `--- Tool: say_hello executing... ---` in the terminal log.\n",
       "    *   The `greeting_specialist` generates the final response based on the tool's output (e.g., \"Hello, there! Great to connect.\").\n",
       "*   **Prompt 2 (`What time is it?`):**\n",
       "    *   The `team_coordinator` receives the prompt.\n",
       "    *   Its LLM determines this is a time request, matching its own capability and instruction (\"If the user asks specifically for the current time..., handle it yourself...\"). It does *not* match the `greeting_specialist`'s description.\n",
       "    *   The LLM decides *not* to delegate.\n",
       "    *   It uses its *own* `get_current_time` tool.\n",
       "    *   You see `--- Tool: get_current_time executing... ---` in the log.\n",
       "    *   The `team_coordinator` generates the final response based on the tool's output (e.g., \"The current time is...\").\n",
       "*   **Prompt 3 (`Hi, can you tell me the time?`):**\n",
       "    *   This tests the LLM's ability to interpret the potentially conflicting signals (greeting + time request) based on the root agent's instructions.\n",
       "    *   It *might* prioritize the greeting and delegate to `greeting_specialist` first.\n",
       "    *   It *might* prioritize the time request and handle it directly using `get_current_time`.\n",
       "    *   *Less likely* with these simple instructions, but a more advanced model might try to handle both (e.g., greet then check time, or ask user which part to address).\n",
       "    *   **Observe the logs:** See which tool (`say_hello` or `get_current_time`) executes, or if the agent responds differently. This highlights the LLM's role in interpreting delegation rules.\n",
       "*   **Prompt 4 (`What is the capital of France?`):**\n",
       "    *   The `team_coordinator` receives the prompt.\n",
       "    *   Its LLM finds this doesn't match its time tool condition, nor the `greeting_specialist`'s description.\n",
       "    *   Following the instruction (\"For any other type of request, state politely that you can only handle time requests or greetings.\"), it should generate a response like \"Sorry, I can only help with checking the current time or simple greetings.\" without calling any tools or sub-agents.\n",
       "\n",
       "**Summary of Stage 6:**\n",
       "You have now:\n",
       "*   Understood the concept and benefits of multi-agent systems (modularity, specialization).\n",
       "*   Defined a specialized sub-agent (`greeting_specialist`) with its own tools, description, and focused instructions.\n",
       "*   Configured a root agent (`team_coordinator`) to manage this sub-agent using the `sub_agents` parameter.\n",
       "*   Written instructions for the root agent to guide delegation decisions, referencing the sub-agent by `name` and relying on its `description`.\n",
       "*   Observed ADK's automatic delegation mechanism correctly routing greeting requests to the specialist, while the root agent handled time requests itself.\n",
       "\n",
       "This multi-agent structure is fundamental for building more complex, maintainable, and capable applications with ADK.\n",
       "\n",
       "How does this look? Are you ready to explore **Workflow Agents** next, which allow for more *deterministic* (non-LLM-driven) control over sequences of agent execution?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## add to chat\n",
    "prompt = (\"Analyst: yes I am ready for the next step.\")\n",
    "response = chat.send_message(message=prompt)\n",
    "\n",
    "# self reflection step\n",
    "p = (\n",
    "  \"Before the analyst views this conduct a thorough review of your output. \"\n",
    "  \"Correct any errors or make improvements and return your output. \"\n",
    ")\n",
    "response = chat.send_message(message=p)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c888f44-784b-4b24-a81d-c47d7012c18a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's refine Stage 7 on `SequentialAgent`.\n",
       "\n",
       "Great! So far, we've seen how an LLM-driven root agent can *delegate* tasks to specialists. Now, let's explore a different way for agents to work together: using **Workflow Agents** for *deterministic* control flow.\n",
       "\n",
       "**Stage 7: Deterministic Control Flow with `SequentialAgent`**\n",
       "\n",
       "**Concept:** Sometimes, you don't want the LLM deciding the order of operations based on descriptions and instructions. You might need a specific, predictable sequence: always do Step A, *then* always do Step B, *then* always do Step C. This is crucial for reliable processes or pipelines.\n",
       "\n",
       "**Workflow Agents** are designed for exactly this. Unlike `LlmAgent`s, they **do not use an LLM** to decide the execution flow. Their behavior is predefined and predictable. ADK provides three types: `SequentialAgent`, `ParallelAgent`, and `LoopAgent`.\n",
       "\n",
       "We'll start with the most straightforward: `SequentialAgent`.\n",
       "\n",
       "*   **`SequentialAgent`:** Executes its list of `sub_agents` one after another, strictly in the order you provide them.\n",
       "\n",
       "**Why use `SequentialAgent`?**\n",
       "\n",
       "*   **Predictability:** Guarantees a fixed order of operations every time. Essential for processes that have mandatory steps.\n",
       "*   **Structure:** Clearly defines multi-step workflows (e.g., Validate -> Process -> Report).\n",
       "*   **Data Flow:** Naturally facilitates passing data between steps using Session State. Agent A can save data (e.g., using `output_key` or `tool_context.state`), and Agent B (running next) can read that data from the state.\n",
       "\n",
       "**Implementation:**\n",
       "\n",
       "1.  **Define Simple Task Agents:** We need agents to run in sequence. Let's reuse simplified versions of our greeting and time agents.\n",
       "    *   `greeting_agent_simple`: Just uses `say_hello`. We can add an `output_key` to save its greeting to state.\n",
       "    *   `time_agent_simple`: Just uses `get_current_time`. Its instruction *could* potentially reference the state saved by the greeting agent if needed.\n",
       "2.  **Define the `SequentialAgent`:**\n",
       "    *   Import `SequentialAgent` from `google.adk.agents`.\n",
       "    *   Create an instance of `SequentialAgent`.\n",
       "    *   Provide the `greeting_agent_simple` and `time_agent_simple` instances in the desired execution order (`[greeting_agent_simple, time_agent_simple]`) to the `sub_agents` list.\n",
       "    *   Make this `SequentialAgent` our new `root_agent`.\n",
       "3.  **No Workflow Instructions Needed:** The `SequentialAgent` itself doesn't need LLM instructions about *when* to run its sub-agents; its *type* dictates the flow (\"run them in order\"). The sub-agents, however, still need their own instructions for *their specific tasks* (like using their tools).\n",
       "\n",
       "Here's the updated `my_first_agent/agent.py`:\n",
       "\n",
       "```python\n",
       "# filename: my_first_agent/agent.py\n",
       "from google.adk.agents import Agent, SequentialAgent # <<< Import SequentialAgent\n",
       "from google.adk.tools import FunctionTool\n",
       "from google.adk.tools.tool_context import ToolContext\n",
       "# Callbacks and related imports removed for clarity\n",
       "import datetime\n",
       "from typing import Dict, Any\n",
       "\n",
       "# --- Constants ---\n",
       "MODEL = \"gemini-2.0-flash-001\"\n",
       "\n",
       "# --- Tool Definitions ---\n",
       "def say_hello(name: str = \"there\") -> dict:\n",
       "    \"\"\"Provides a friendly greeting.\"\"\"\n",
       "    print(f\"--- Tool: say_hello executing ---\")\n",
       "    greeting_message = f\"Hello, {name}! Welcome to the sequential process.\"\n",
       "    return {\"greeting\": greeting_message}\n",
       "\n",
       "hello_tool = FunctionTool(func=say_hello)\n",
       "\n",
       "def get_current_time(tool_context: ToolContext) -> dict:\n",
       "    \"\"\"Gets the current date and time.\"\"\"\n",
       "    print(f\"--- Tool: get_current_time executing ---\")\n",
       "    now = datetime.datetime.now()\n",
       "    time_str = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
       "    # State written by tool persists within the session\n",
       "    tool_context.state['last_time_checked_sequential'] = time_str\n",
       "    return {\"current_time\": time_str}\n",
       "\n",
       "time_tool = FunctionTool(func=get_current_time)\n",
       "\n",
       "# --- Define Simple Sub-Agents for the Sequence ---\n",
       "\n",
       "# Agent 1: Just Greets and saves result to state\n",
       "greeting_agent_simple = Agent(\n",
       "    name=\"step1_greeting\",\n",
       "    model=MODEL,\n",
       "    description=\"Greets the user.\", # Description used if this agent is part of a larger delegation tree, less critical for fixed sequence\n",
       "    instruction=\"Greet the user politely using the 'say_hello' tool. Do nothing else.\",\n",
       "    tools=[hello_tool],\n",
       "    output_key=\"step1_greeting_result\" # <<< Save greeting result to state['step1_greeting_result']\n",
       ")\n",
       "\n",
       "# Agent 2: Just Checks Time\n",
       "time_agent_simple = Agent(\n",
       "    name=\"step2_time_check\",\n",
       "    model=MODEL,\n",
       "    description=\"Checks the current time.\",\n",
       "    # Instruction could potentially use state from previous step:\n",
       "    # instruction=\"Acknowledge the greeting in state['step1_greeting_result'] if present,\n",
       "    #             then check the current time using the 'get_current_time' tool.\",\n",
       "    instruction=\"Check the current time using the 'get_current_time' tool. Respond only with the time information.\",\n",
       "    tools=[time_tool],\n",
       "    output_key=\"step2_time_result\" # Can also save its result\n",
       ")\n",
       "\n",
       "# --- Define the Sequential Workflow Agent ---\n",
       "# This agent controls the ORDER of execution using predefined logic, not an LLM.\n",
       "root_agent = SequentialAgent(\n",
       "    name=\"greet_then_time_workflow\", # Name for the workflow agent itself\n",
       "    # List sub-agents IN THE ORDER they must execute\n",
       "    sub_agents=[\n",
       "        greeting_agent_simple, # Runs first\n",
       "        time_agent_simple      # Runs second\n",
       "    ]\n",
       "    # No 'model' or 'instruction' needed for SequentialAgent itself.\n",
       ")\n",
       "\n",
       "print(f\"Workflow Agent '{root_agent.name}' defined with sequence: {[agent.name for agent in root_agent.sub_agents]}\")\n",
       "print(f\"Sub-Agent '{greeting_agent_simple.name}' Tools: {[t.name for t in greeting_agent_simple.tools]}\")\n",
       "print(f\"Sub-Agent '{time_agent_simple.name}' Tools: {[t.name for t in time_agent_simple.tools]}\")\n",
       "\n",
       "```\n",
       "\n",
       "**Running the Workflow Agent:**\n",
       "\n",
       "1.  Go back to your terminal (in `adk_tutorial`), activate `myenv`.\n",
       "2.  Run the agent. The command remains `adk run my_first_agent` because it loads the `root_agent` variable, which now points to our `SequentialAgent`.\n",
       "\n",
       "```bash\n",
       "adk run my_first_agent\n",
       "```\n",
       "\n",
       "Now, send **any** prompt to start the sequence. The specific prompt content is less critical for *triggering* the sequence (which is fixed), although the sub-agents might still use the initial user message if their instructions dictate. Try:\n",
       "\n",
       "*   `Start`\n",
       "*   `Begin workflow`\n",
       "*   `Hello`\n",
       "\n",
       "**Expected Output & Observation:**\n",
       "\n",
       "Regardless of your initial prompt, you should observe the following **deterministic sequence** in the terminal logs and agent responses:\n",
       "\n",
       "1.  The `greet_then_time_workflow` (SequentialAgent) starts execution.\n",
       "2.  It **first** runs `sub_agents[0]`, which is `step1_greeting`.\n",
       "3.  The `step1_greeting` agent executes its logic (using its LLM and instructions), decides to use its tool.\n",
       "4.  Log shows: `--- Tool: say_hello executing ---`.\n",
       "5.  `step1_greeting` yields its final response event (e.g., containing \"Hello, there! Welcome.\"). The `Runner` processes this, saving the text to `state['step1_greeting_result']` because of `output_key`.\n",
       "6.  **Then, and only then,** the `SequentialAgent` runs `sub_agents[1]`, which is `step2_time_check`.\n",
       "7.  The `step2_time_check` agent executes its logic. It could potentially access `state['step1_greeting_result']` if its instructions were written to do so. It decides to use its tool.\n",
       "8.  Log shows: `--- Tool: get_current_time executing ---`.\n",
       "9.  `step2_time_check` yields its final response event (e.g., containing \"The current time is...\"). The `Runner` processes this, saving the result to `state['step2_time_result']`.\n",
       "10. The `SequentialAgent` has finished running all its sub-agents in order. The overall interaction for this turn completes. The *final* response displayed to the user will typically be the response from the *last* agent in the sequence (`step2_time_check`).\n",
       "\n",
       "The crucial point is that the `SequentialAgent` **enforced the execution order** (greeting first, then time check) without relying on LLM decisions for the flow control itself.\n",
       "\n",
       "**Summary of Stage 7:**\n",
       "You have now:\n",
       "*   Learned about Workflow Agents (`SequentialAgent`, `ParallelAgent`, `LoopAgent`) providing deterministic control flow.\n",
       "*   Implemented `SequentialAgent` to execute sub-agents in a fixed, predefined order.\n",
       "*   Understood that the `SequentialAgent` orchestrates the sequence without needing its own LLM.\n",
       "*   Observed the predictable step-by-step execution enforced by `SequentialAgent`.\n",
       "*   Reinforced how state (`output_key`, `tool_context.state`) can be used to pass data between agents in a sequence.\n",
       "\n",
       "Workflow agents are essential for building reliable processes and pipelines within your multi-agent systems, complementing the flexibility of LLM-driven delegation.\n",
       "\n",
       "Ready to see how `ParallelAgent` allows sub-agents to run concurrently? Or would you prefer to explore another ADK feature like Artifacts for file handling?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## add to chat\n",
    "prompt = (\"Analyst: yes I am ready for the next step.\")\n",
    "response = chat.send_message(message=prompt)\n",
    "\n",
    "# self reflection step\n",
    "p = (\n",
    "  \"Before the analyst views this conduct a thorough review of your output. \"\n",
    "  \"Correct any errors or make improvements and return your output. \"\n",
    ")\n",
    "response = chat.send_message(message=p)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02e77ab7-585d-4ebd-acee-0570f2537b76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's polish Stage 8 about `ParallelAgent`.\n",
       "\n",
       "Excellent! We've seen sequential execution with `SequentialAgent`. Now, let's look at how to run tasks simultaneously using `ParallelAgent`.\n",
       "\n",
       "**Stage 8: Concurrent Execution with `ParallelAgent`**\n",
       "\n",
       "**Concept:** While `SequentialAgent` enforces a strict one-after-another order, `ParallelAgent` is designed to run its sub-agents *concurrently*—essentially, starting them all at roughly the same time and letting them run side-by-side.\n",
       "\n",
       "**Why use `ParallelAgent`?**\n",
       "\n",
       "*   **Speed & Efficiency:** This is the main benefit. If you have multiple independent tasks (like fetching data from different websites, performing separate calculations, calling different slow APIs) that don't need to wait for each other, running them in parallel can drastically reduce the total time taken compared to running them sequentially.\n",
       "*   **Independent Operations:** Ideal for scenarios where sub-tasks don't depend on each other's immediate results during their execution.\n",
       "\n",
       "**How it works:**\n",
       "\n",
       "1.  **Concurrent Initiation:** When the `ParallelAgent` executes, it immediately initiates the `run_async` method of *all* the sub-agents listed in its `sub_agents`. They start processing concurrently.\n",
       "2.  **Asynchronous Execution:** ADK leverages Python's `asyncio` to manage these concurrent tasks, allowing them to proceed independently without blocking each other (especially if the tasks involve waiting for I/O like network requests or simulated delays).\n",
       "3.  **Shared Session State:** This is important: even though they run concurrently, sub-agents within a `ParallelAgent` **still share access to the same underlying session state dictionary** (`session.state`).\n",
       "    *   They can all *read* the state as it was when the `ParallelAgent` started.\n",
       "    *   They can all *write* results back to the state using methods like `tool_context.state['key'] = value` or by configuring `output_key` on the sub-agent.\n",
       "    *   **⚠️ Best Practice:** To avoid race conditions (where multiple agents might try to write to the *same* state key at the same time, and only the last write succeeds), ensure parallel sub-agents write their results to **distinct** state keys.\n",
       "4.  **Interleaved Output & Completion:** Events generated by the parallel sub-agents (like tool logs or their final responses) may appear interleaved in the console output, reflecting their concurrent progress. The `ParallelAgent` itself finishes its execution turn only *after all* of its sub-agents have completed their individual runs. It doesn't typically produce a single, combined response itself; its value lies in orchestrating the concurrent execution. The results saved to the distinct state keys are then available for subsequent agents (e.g., if the `ParallelAgent` was part of a larger `SequentialAgent`).\n",
       "\n",
       "**Implementation:**\n",
       "\n",
       "1.  **Define Independent Agents:** We'll reuse our simple `greeting_agent` and `time_agent` concepts from Stage 7, but ensure their tools are `async` (to better simulate concurrent work) and they use distinct `output_key`s to save their results safely to the shared state.\n",
       "2.  **Define the `ParallelAgent`:**\n",
       "    *   Import `ParallelAgent`.\n",
       "    *   Create an instance, listing the independent agents (`greeting_agent_parallel`, `time_agent_parallel`) in the `sub_agents` list.\n",
       "    *   Set this `ParallelAgent` as our `root_agent`.\n",
       "\n",
       "Here's the updated `my_first_agent/agent.py`:\n",
       "\n",
       "```python\n",
       "# filename: my_first_agent/agent.py\n",
       "from google.adk.agents import Agent, ParallelAgent # <<< Import ParallelAgent\n",
       "from google.adk.tools import FunctionTool\n",
       "from google.adk.tools.tool_context import ToolContext\n",
       "import datetime\n",
       "import asyncio # <<< Import asyncio for simulating concurrent work\n",
       "from typing import Dict, Any\n",
       "\n",
       "# --- Constants ---\n",
       "MODEL = \"gemini-2.0-flash-001\"\n",
       "\n",
       "# --- Tool Definitions (Async for better demo) ---\n",
       "\n",
       "# Marked 'async def' and uses 'await asyncio.sleep'\n",
       "async def say_hello(name: str = \"there\") -> dict:\n",
       "    \"\"\"Provides a friendly greeting after a short delay.\"\"\"\n",
       "    print(f\"--- Tool: say_hello starting (will sleep 1s)... ---\")\n",
       "    await asyncio.sleep(1) # Simulate longer work\n",
       "    greeting_message = f\"Hello, {name}! Parallel process says hi.\"\n",
       "    print(f\"--- Tool: say_hello finished. ---\")\n",
       "    return {\"greeting\": greeting_message}\n",
       "\n",
       "hello_tool = FunctionTool(func=say_hello)\n",
       "\n",
       "# Marked 'async def' and uses 'await asyncio.sleep'\n",
       "async def get_current_time(tool_context: ToolContext) -> dict:\n",
       "    \"\"\"Gets the current date and time after a short delay.\"\"\"\n",
       "    print(f\"--- Tool: get_current_time starting (will sleep 0.5s)... ---\")\n",
       "    await asyncio.sleep(0.5) # Simulate shorter work\n",
       "    now = datetime.datetime.now()\n",
       "    time_str = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
       "    state_key = 'parallel_time_checked' # Use a distinct key\n",
       "    tool_context.state[state_key] = time_str\n",
       "    print(f\"--- Tool: get_current_time finished (State '{state_key}' updated). ---\")\n",
       "    return {\"current_time\": time_str}\n",
       "\n",
       "time_tool = FunctionTool(func=get_current_time)\n",
       "\n",
       "\n",
       "# --- Define Simple Sub-Agents for Parallel Execution ---\n",
       "\n",
       "# Agent 1: Just Greets (using async tool)\n",
       "# Uses a distinct output_key to write its result to state\n",
       "greeting_agent_parallel = Agent(\n",
       "    name=\"parallel_greeting\",\n",
       "    model=MODEL,\n",
       "    description=\"Greets the user in parallel.\",\n",
       "    instruction=\"Greet the user using the 'say_hello' tool.\",\n",
       "    tools=[hello_tool],\n",
       "    output_key=\"parallel_greeting_result\" # <<< Saves result to state['parallel_greeting_result']\n",
       ")\n",
       "\n",
       "# Agent 2: Just Checks Time (using async tool)\n",
       "# Uses a distinct output_key\n",
       "time_agent_parallel = Agent(\n",
       "    name=\"parallel_time_check\",\n",
       "    model=MODEL,\n",
       "    description=\"Checks the current time in parallel.\",\n",
       "    instruction=\"Check the current time using the 'get_current_time' tool.\",\n",
       "    tools=[time_tool],\n",
       "    output_key=\"parallel_time_result\" # <<< Saves result to state['parallel_time_result']\n",
       ")\n",
       "\n",
       "\n",
       "# --- Define the Parallel Workflow Agent ---\n",
       "# This agent runs its sub-agents concurrently.\n",
       "root_agent = ParallelAgent(\n",
       "    name=\"greet_and_time_parallel_workflow\", # Name for the workflow agent\n",
       "    # List the agents that should run concurrently\n",
       "    sub_agents=[\n",
       "        greeting_agent_parallel,\n",
       "        time_agent_parallel\n",
       "    ]\n",
       "    # No model or instructions needed for ParallelAgent itself.\n",
       ")\n",
       "\n",
       "print(f\"Workflow Agent '{root_agent.name}' defined to run sub-agents in parallel: {[agent.name for agent in root_agent.sub_agents]}\")\n",
       "print(f\"Sub-Agent '{greeting_agent_parallel.name}' Tools: {[t.name for t in greeting_agent_parallel.tools]}, Output Key: {greeting_agent_parallel.output_key}\")\n",
       "print(f\"Sub-Agent '{time_agent_parallel.name}' Tools: {[t.name for t in time_agent_parallel.tools]}, Output Key: {time_agent_parallel.output_key}\")\n",
       "\n",
       "```\n",
       "\n",
       "**Running the Parallel Agent:**\n",
       "\n",
       "1.  Go back to your terminal (in `adk_tutorial`), activate `myenv`.\n",
       "2.  Run the agent:\n",
       "\n",
       "```bash\n",
       "adk run my_first_agent\n",
       "```\n",
       "\n",
       "Send any prompt to start the workflow, for example:\n",
       "\n",
       "*   `Run parallel`\n",
       "*   `Go`\n",
       "\n",
       "**Expected Output & Observation:**\n",
       "\n",
       "Because the agents run concurrently and we added simulated delays (`asyncio.sleep`), the exact order of the log messages might vary slightly each time. However, the key pattern to observe is the **interleaving** indicating concurrency:\n",
       "\n",
       "1.  The `greet_and_time_parallel_workflow` agent starts.\n",
       "2.  *Both* `parallel_greeting` and `parallel_time_check` agents begin execution almost simultaneously.\n",
       "3.  You'll likely see the **\"starting execution\"** logs from *both* tools appear close together in the terminal:\n",
       "    *   `--- Tool: get_current_time starting (will sleep 0.5s)... ---`\n",
       "    *   `--- Tool: say_hello starting (will sleep 1s)... ---`\n",
       "4.  Since `get_current_time` has a shorter simulated delay (0.5s) than `say_hello` (1s), you'll probably see its **\"finished execution\"** log appear *before* `say_hello` finishes:\n",
       "    *   `--- Tool: get_current_time finished... ---`\n",
       "5.  A little later, the \"finished execution\" log for the longer task appears:\n",
       "    *   `--- Tool: say_hello finished. ---`\n",
       "6.  **Final Response & State:** The `adk run` command typically displays the final event content from the *last* sub-agent to complete its turn. Since `say_hello` likely finishes last due to the longer sleep, you might see the greeting (\"Hello, there! Parallel process says hi.\") as the final message in the terminal.\n",
       "    *   **However, the main outcome is not this single message.** The real result is that *both* tasks ran concurrently, and *both* their results were saved to the session state under their respective `output_key`s (`parallel_greeting_result` and `parallel_time_result`). A subsequent agent (if this `ParallelAgent` were nested in a `SequentialAgent`) could then access *both* pieces of information from the state.\n",
       "\n",
       "The key observation is the interleaving of \"start\" and \"finish\" logs, demonstrating concurrent activity and potentially faster overall completion than a sequential approach.\n",
       "\n",
       "**Summary of Stage 8:**\n",
       "You have now:\n",
       "*   Learned about `ParallelAgent` for running sub-agents concurrently.\n",
       "*   Understood its primary benefit: potentially speeding up workflows with independent tasks.\n",
       "*   Seen how to define a `ParallelAgent` and provide its `sub_agents`.\n",
       "*   Observed the concurrent execution pattern through interleaved logs.\n",
       "*   Reinforced the importance of using distinct state keys (`output_key` or manual `tool_context.state` writes) when parallel agents modify shared session state.\n",
       "\n",
       "We've now covered the main workflow agents (`SequentialAgent`, `ParallelAgent`). The third type is `LoopAgent`, which repeats its sub-agents—useful for iterative refinement or polling tasks.\n",
       "\n",
       "Are you ready to learn about `LoopAgent`, or would you prefer to switch gears and explore **Artifacts** for handling files?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## add to chat\n",
    "prompt = (\"Analyst: yes I am ready for the next step.\")\n",
    "response = chat.send_message(message=prompt)\n",
    "\n",
    "# self reflection step\n",
    "p = (\n",
    "  \"Before the analyst views this conduct a thorough review of your output. \"\n",
    "  \"Correct any errors or make improvements and return your output. \"\n",
    ")\n",
    "response = chat.send_message(message=p)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48452c92-b35d-49ad-b13f-34a30035c04f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's refine Stage 9 about `LoopAgent`.\n",
       "\n",
       "Excellent! Let's explore the final type of predefined workflow agent: `LoopAgent`.\n",
       "\n",
       "**Stage 9: Iterative Execution with `LoopAgent`**\n",
       "\n",
       "**Concept:** Sometimes, you need your agent system to repeat a sequence of actions multiple times. This could be for refining a result iteratively (like generating text, getting feedback, revising, and repeating), polling for a status update until it changes, or attempting an action until it succeeds (up to a certain number of tries). `LoopAgent` is designed specifically for these repetitive workflows.\n",
       "\n",
       "*   **`LoopAgent`:** Executes its list of `sub_agents` sequentially (one after another within the iteration), and then **repeats** the entire sequence from the beginning.\n",
       "\n",
       "**Why use `LoopAgent`?**\n",
       "\n",
       "*   **Iteration & Refinement:** Ideal for processes like Generate -> Critique -> Revise, where you repeat steps to improve quality.\n",
       "*   **Polling:** Repeatedly check an external system's status or a value in the session state until a desired condition is met.\n",
       "*   **Retries:** Implement simple retry logic for actions that might fail occasionally.\n",
       "\n",
       "**How it works:**\n",
       "\n",
       "1.  **Sequential Execution (Within Each Loop):** In a single pass (iteration) of the loop, `LoopAgent` runs its `sub_agents` one after another, in the order they are listed, just like `SequentialAgent`.\n",
       "2.  **Repetition:** After the *last* sub-agent in the sequence finishes its turn for the current iteration, the `LoopAgent` automatically starts the sequence over again with the *first* sub-agent for the next iteration.\n",
       "3.  **Termination Conditions:** A loop needs a way to stop! `LoopAgent` provides two mechanisms:\n",
       "    *   **`max_iterations` (Safety Net):** You can (and generally should) specify a maximum number of times the loop is allowed to run when you define the `LoopAgent` (e.g., `max_iterations=5`). The loop will stop automatically if it completes this many full iterations.\n",
       "    *   **Escalation Signal (`actions.escalate=True`) (Dynamic Exit):** This is the primary way to exit the loop based on runtime conditions. If *any* sub-agent during its execution (or a tool/callback called by that sub-agent) signals escalation by setting `tool_context.actions.escalate = True` (which gets included in the resulting `Event`), the `LoopAgent` will **stop** executing immediately after that specific event is processed. It will *not* start the next iteration or even finish the remaining sub-agents in the *current* iteration if the signal occurs mid-sequence.\n",
       "\n",
       "**Implementation:**\n",
       "\n",
       "1.  **Define Agents for the Loop Body:** We need agents to perform the actions *inside* each loop iteration. Let's create:\n",
       "    *   `increment_counter_agent`: Uses a tool (`increment_counter`) to increment a 'loop\\_counter' value stored in session state.\n",
       "    *   `check_counter_agent`: Uses a tool (`check_counter_and_maybe_escalate`) to check the 'loop\\_counter'. This tool will be responsible for signaling `escalate=True` via `tool_context.actions` when the counter reaches a predefined target value (e.g., 3).\n",
       "2.  **Define the `LoopAgent`:**\n",
       "    *   Import `LoopAgent`.\n",
       "    *   Create an instance, listing `increment_counter_agent` and `check_counter_agent` in its `sub_agents` (this defines the sequence *within* each iteration).\n",
       "    *   Set a `max_iterations` value (e.g., 5) as a safety fallback.\n",
       "    *   Make this `LoopAgent` our new `root_agent`.\n",
       "\n",
       "Here's the updated `my_first_agent/agent.py`:\n",
       "\n",
       "```python\n",
       "# filename: my_first_agent/agent.py\n",
       "from google.adk.agents import Agent, LoopAgent # <<< Import LoopAgent\n",
       "from google.adk.tools import FunctionTool, BaseTool\n",
       "from google.adk.tools.tool_context import ToolContext\n",
       "from google.adk.events import Event, EventActions # <<< Needed for escalation signal context\n",
       "# Callbacks and related imports removed for clarity\n",
       "import datetime\n",
       "from typing import Dict, Any, Optional\n",
       "\n",
       "# --- Constants ---\n",
       "MODEL = \"gemini-2.0-flash-001\"\n",
       "TARGET_COUNT = 3 # The count at which the loop should stop via escalation\n",
       "\n",
       "# --- Tool Definitions for Loop ---\n",
       "\n",
       "def increment_counter(tool_context: ToolContext) -> dict:\n",
       "    \"\"\"Increments 'loop_counter' in session state by 1.\"\"\"\n",
       "    print(f\"--- Tool: increment_counter executing ---\")\n",
       "    current_count = tool_context.state.get('loop_counter', 0) # Read state\n",
       "    new_count = current_count + 1\n",
       "    tool_context.state['loop_counter'] = new_count # Write state\n",
       "    print(f\"--- Tool: Updated 'loop_counter' state from {current_count} to {new_count} ---\")\n",
       "    return {\"status\": \"incremented\", \"new_count\": new_count}\n",
       "\n",
       "increment_tool = FunctionTool(func=increment_counter)\n",
       "\n",
       "def check_counter_and_maybe_escalate(tool_context: ToolContext) -> dict:\n",
       "    \"\"\"\n",
       "    Checks 'loop_counter'. If >= TARGET_COUNT, signals LoopAgent to stop\n",
       "    by setting tool_context.actions.escalate = True.\n",
       "    \"\"\"\n",
       "    print(f\"--- Tool: check_counter_and_maybe_escalate executing ---\")\n",
       "    current_count = tool_context.state.get('loop_counter', 0) # Read state\n",
       "    print(f\"--- Tool: Current 'loop_counter' state is: {current_count} ---\")\n",
       "\n",
       "    result = {\"status\": \"checked\", \"current_count\": current_count}\n",
       "    should_escalate = (current_count >= TARGET_COUNT)\n",
       "\n",
       "    if should_escalate:\n",
       "        print(f\"--- Tool: Counter reached {TARGET_COUNT}! Signaling escalation via tool_context.actions. ---\")\n",
       "        # <<< This is how the tool signals the LoopAgent to stop\n",
       "        tool_context.actions.escalate = True\n",
       "        result[\"message\"] = f\"Target count {TARGET_COUNT} reached. Stopping loop.\"\n",
       "    else:\n",
       "         print(f\"--- Tool: Counter below {TARGET_COUNT}. Loop will continue. ---\")\n",
       "         result[\"message\"] = f\"Target count {TARGET_COUNT} not yet reached.\"\n",
       "\n",
       "    # The dictionary returned is the tool's result for the LLM.\n",
       "    # The escalation signal is carried separately by the framework via the Event's actions.\n",
       "    return result\n",
       "\n",
       "check_tool = FunctionTool(func=check_counter_and_maybe_escalate)\n",
       "\n",
       "# --- Define Simple Sub-Agents for the Loop Body ---\n",
       "\n",
       "# Agent 1: Runs the increment tool\n",
       "increment_counter_agent = Agent(\n",
       "    name=\"step1_increment\",\n",
       "    model=MODEL, # Model needed to decide to call the tool\n",
       "    description=\"Increments the loop counter.\",\n",
       "    instruction=\"Use the 'increment_counter' tool. Report the new count briefly.\",\n",
       "    tools=[increment_tool],\n",
       "    output_key=\"increment_result\" # Optional: save tool dict result to state\n",
       ")\n",
       "\n",
       "# Agent 2: Runs the check tool (which might escalate)\n",
       "check_counter_agent = Agent(\n",
       "    name=\"step2_check_and_escalate\",\n",
       "    model=MODEL, # Model needed to decide to call the tool\n",
       "    description=\"Checks the loop counter and triggers loop stop if target reached.\",\n",
       "    instruction=\"Use the 'check_counter_and_maybe_escalate' tool. Report the message from the tool.\",\n",
       "    tools=[check_tool],\n",
       "    output_key=\"check_result\" # Optional: save tool dict result to state\n",
       ")\n",
       "\n",
       "# --- Define the Loop Workflow Agent ---\n",
       "root_agent = LoopAgent(\n",
       "    name=\"counter_loop_workflow\",\n",
       "    # Sub-agents run sequentially *within* each iteration\n",
       "    sub_agents=[\n",
       "        increment_counter_agent, # Runs first in each iteration\n",
       "        check_counter_agent      # Runs second in each iteration\n",
       "    ],\n",
       "    max_iterations=5 # <<< Safety limit: Stop after 5 full loops if escalation doesn't happen\n",
       ")\n",
       "\n",
       "print(f\"Workflow Agent '{root_agent.name}' defined with loop sequence: {[agent.name for agent in root_agent.sub_agents]}, max_iterations={root_agent.max_iterations}\")\n",
       "\n",
       "```\n",
       "\n",
       "**Running the Loop Agent:**\n",
       "\n",
       "1.  Go back to your terminal (in `adk_tutorial`), activate `myenv`.\n",
       "2.  Run the agent:\n",
       "\n",
       "```bash\n",
       "adk run my_first_agent\n",
       "```\n",
       "\n",
       "Send any prompt to start the loop, e.g.:\n",
       "\n",
       "*   `Start count`\n",
       "*   `Loop`\n",
       "\n",
       "**Expected Output & Observation:**\n",
       "\n",
       "You will see the agents execute sequentially, repeating until the counter reaches `TARGET_COUNT` (3).\n",
       "\n",
       "*   **Iteration 1:**\n",
       "    *   `step1_increment` runs -> Tool updates state `loop_counter` to 1. Agent responds.\n",
       "    *   `step2_check_and_escalate` runs -> Tool checks state (1 < 3), does *not* signal escalate. Agent responds.\n",
       "*   **Iteration 2:**\n",
       "    *   `step1_increment` runs -> Tool updates state `loop_counter` to 2. Agent responds.\n",
       "    *   `step2_check_and_escalate` runs -> Tool checks state (2 < 3), does *not* signal escalate. Agent responds.\n",
       "*   **Iteration 3:**\n",
       "    *   `step1_increment` runs -> Tool updates state `loop_counter` to 3. Agent responds.\n",
       "    *   `step2_check_and_escalate` runs -> Tool checks state (3 >= 3).\n",
       "        *   Log shows: `--- Tool: Counter reached 3! Signaling escalation... ---`. The tool sets `tool_context.actions.escalate = True`.\n",
       "        *   Agent responds (e.g., \"Target count 3 reached. Stopping loop.\").\n",
       "*   **Loop Terminates:** Because the `check_counter_and_maybe_escalate` tool signaled escalation, the `LoopAgent` **stops** after processing the final event from `step2_check_and_escalate` in Iteration 3. It does *not* proceed to Iteration 4, even though `max_iterations` was 5.\n",
       "\n",
       "The final output displayed by `adk run` will typically be the response from the `check_counter_agent` in the last iteration where escalation occurred (\"Target count 3 reached...\").\n",
       "\n",
       "**Summary of Stage 9:**\n",
       "You have now:\n",
       "*   Learned about `LoopAgent` for creating workflows that repeat a sequence of sub-agents.\n",
       "*   Understood the two ways a `LoopAgent` can terminate: reaching `max_iterations` or receiving an `escalate=True` signal from a sub-agent's event actions.\n",
       "*   Implemented a loop where a tool (`check_counter_and_maybe_escalate`) dynamically signals escalation based on session state by modifying `tool_context.actions.escalate`.\n",
       "*   Observed the `LoopAgent` executing its sub-agents repeatedly until the escalation condition was successfully triggered and the loop stopped.\n",
       "\n",
       "We've now covered the core agent types (`LlmAgent`, `SequentialAgent`, `ParallelAgent`, `LoopAgent`), tools, state management, and callbacks! This gives you a very strong foundation in ADK.\n",
       "\n",
       "What area would you like to explore next? We could dive into:\n",
       "\n",
       "a)  **Artifacts:** How agents can save and load files (like images, PDFs, etc.).\n",
       "b)  **Evaluation:** How to formally test your agent's performance against predefined criteria.\n",
       "c)  **Deployment:** How to get your agent running on cloud platforms like Cloud Run or Vertex AI Agent Engine.\n",
       "d)  **Custom Agents:** Building agents with completely custom Python logic by inheriting directly from `BaseAgent` (more advanced)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## add to chat\n",
    "prompt = (\"Analyst: yes I am ready for the next step.\")\n",
    "response = chat.send_message(message=prompt)\n",
    "\n",
    "# self reflection step\n",
    "p = (\n",
    "  \"Before the analyst views this conduct a thorough review of your output. \"\n",
    "  \"Correct any errors or make improvements and return your output. \"\n",
    ")\n",
    "response = chat.send_message(message=p)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65789f31-c0a0-4495-9bcc-ec37e9d3de5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's ensure Stage 10 is clear and accurate.\n",
       "\n",
       "Okay, let's explore **Artifacts**. While Session State is great for small, serializable pieces of data like strings, numbers, or simple lists/dictionaries, **Artifacts** are ADK's mechanism for handling larger, potentially binary data—essentially, files—associated with a conversation session or a user.\n",
       "\n",
       "**Stage 10: Handling Files and Large Data with Artifacts**\n",
       "\n",
       "**Concept:** Think of artifacts as named, versioned files stored alongside your session data.\n",
       "\n",
       "*   **What they store:** Typically used for binary data (images, PDFs, audio clips) or large text data that wouldn't fit well or efficiently in the regular session state dictionary. The data is represented within ADK using the standard `google.genai.types.Part` object, usually storing the raw `bytes` and the `mime_type` (e.g., 'image/png', 'application/pdf', 'text/plain') in the `Part.inline_data` field.\n",
       "*   **Why use them?**\n",
       "    *   To allow users to upload files for processing by the agent.\n",
       "    *   To enable agents or tools to generate and save files (like PDF reports, CSV exports, generated images).\n",
       "    *   To pass large data blobs between different steps or agents in a workflow without overloading the session state.\n",
       "    *   To persist configuration files or user-specific data that isn't simple key-value state.\n",
       "*   **Management (`ArtifactService`):** Artifacts are not stored *in* the session state dictionary. Their storage and retrieval are handled by a dedicated **`ArtifactService`**. ADK provides:\n",
       "    *   `InMemoryArtifactService`: Stores artifacts in the application's memory. **Data is lost when the application stops.** Good for local testing. (This is what `adk run` uses by default).\n",
       "    *   `GcsArtifactService`: Stores artifacts persistently in a Google Cloud Storage bucket. Suitable for production.\n",
       "    *   The `Runner` must be configured with an `ArtifactService` instance for these operations to work (though `adk run` handles the default `InMemory` setup).\n",
       "*   **Versioning:** Every time you `save_artifact` with the same `filename`, the `ArtifactService` automatically creates a new version (typically starting from 0 and incrementing). The `save_artifact` method returns the new version number.\n",
       "*   **Access (via Context):** Within tools (or callbacks), you interact with artifacts using methods on the context objects (`CallbackContext` or `ToolContext`):\n",
       "    *   `context.save_artifact(filename: str, artifact: types.Part) -> int`: Saves the data from the `Part` object under the specified `filename`. Returns the integer version number assigned. This action is also recorded in the `EventActions.artifact_delta` for tracking purposes by the `SessionService`.\n",
       "    *   `context.load_artifact(filename: str, version: Optional[int] = None) -> Optional[types.Part]`: Retrieves the specified artifact. If `version` is omitted (or `None`), it fetches the **latest** version. Returns the `Part` object containing the data, or `None` if the artifact/version doesn't exist.\n",
       "    *   `tool_context.list_artifacts() -> list[str]`: (Available only on `ToolContext`) Returns a list of all unique artifact filenames currently available within the session's scope.\n",
       "*   **Namespacing (`user:` prefix):** Just like state, prefixing the `filename` with `\"user:\"` (e.g., `\"user:avatar.jpg\"`) associates the artifact with the `user_id` across all sessions (assuming a persistent `ArtifactService`). A filename without a prefix is tied to the specific `session_id`.\n",
       "\n",
       "**Implementation:**\n",
       "\n",
       "1.  **Modify Tool to Save Artifact:** We'll update the `get_current_time` tool. After getting the time string, it will create a `types.Part` containing this string (as text) and save it as an artifact named `\"last_timestamp.txt\"` using `tool_context.save_artifact`.\n",
       "2.  **Create Tool to Load Artifact:** We'll define a new tool, `read_last_timestamp_artifact`. This tool will use `tool_context.load_artifact` to retrieve the *latest* version of `\"last_timestamp.txt\"` and return its text content.\n",
       "3.  **Update Agent:** We'll add the new `read_last_timestamp_artifact` tool to the agent's `tools` list and update the `instruction` to clearly explain when to use each tool (one for getting *current* time and saving, one for *reading* the saved artifact).\n",
       "\n",
       "Here's the updated `my_first_agent/agent.py`:\n",
       "\n",
       "```python\n",
       "# filename: my_first_agent/agent.py\n",
       "from google.adk.agents import Agent\n",
       "from google.adk.tools import FunctionTool, BaseTool\n",
       "from google.adk.tools.tool_context import ToolContext\n",
       "# Callbacks and related imports removed for clarity\n",
       "from google.adk.events import EventActions # Needed if tool signals actions\n",
       "from google.genai import types # <<< Need types for creating Part\n",
       "import datetime\n",
       "from typing import Dict, Any, Optional\n",
       "\n",
       "# --- Constants ---\n",
       "MODEL = \"gemini-2.0-flash-001\"\n",
       "TIMESTAMP_ARTIFACT_FILENAME = \"last_timestamp.txt\" # Use a constant for the filename\n",
       "\n",
       "# --- Tool Definitions ---\n",
       "\n",
       "# Tool 1: Gets time, updates state (optional), AND saves artifact\n",
       "def get_current_time_and_save_artifact(tool_context: ToolContext) -> dict:\n",
       "    \"\"\"\n",
       "    Gets the current date and time. It also saves this timestamp\n",
       "    as a text artifact named 'last_timestamp.txt'.\n",
       "\n",
       "    Use this tool ONLY when the user asks for the *current* time or date.\n",
       "\n",
       "    Returns:\n",
       "        A dictionary containing the current date and time string.\n",
       "        Example format: {'current_time': '2024-08-15 14:30:55'}\n",
       "    \"\"\"\n",
       "    print(f\"--- Tool: get_current_time_and_save_artifact executing ---\")\n",
       "    now = datetime.datetime.now()\n",
       "    time_str = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
       "\n",
       "    # Update state (optional, but shows coexistence with artifacts)\n",
       "    state_key = 'last_time_checked_artifact'\n",
       "    tool_context.state[state_key] = time_str\n",
       "    print(f\"--- Tool: Updated state '{state_key}' to: {time_str} ---\")\n",
       "\n",
       "    # <<< Save the time string as an Artifact >>>\n",
       "    try:\n",
       "        # Create a Part object using from_text for text data\n",
       "        # ADK handles setting the mime_type to 'text/plain'\n",
       "        time_artifact_part = types.Part.from_text(time_str)\n",
       "\n",
       "        # Save the artifact using the context method\n",
       "        version = tool_context.save_artifact(\n",
       "            filename=TIMESTAMP_ARTIFACT_FILENAME,\n",
       "            artifact=time_artifact_part\n",
       "        )\n",
       "        # The framework automatically adds {'last_timestamp.txt': version}\n",
       "        # to the event's actions.artifact_delta\n",
       "        print(f\"--- Tool: Saved artifact '{TIMESTAMP_ARTIFACT_FILENAME}' (Version: {version}) with content: '{time_str}' ---\")\n",
       "        return {\"current_time\": time_str} # Return success payload\n",
       "\n",
       "    except ValueError as e:\n",
       "        print(f\"--- Tool ERROR: Failed to save artifact: {e} (Is ArtifactService configured in Runner?) ---\")\n",
       "        # Return an error dictionary for the LLM\n",
       "        return {\"status\": \"error\", \"error_message\": f\"Failed to save timestamp artifact: {e}\"}\n",
       "    except Exception as e:\n",
       "        print(f\"--- Tool ERROR: Unexpected error saving artifact: {e} ---\")\n",
       "        return {\"status\": \"error\", \"error_message\": f\"Unexpected error saving timestamp artifact: {e}\"}\n",
       "\n",
       "# Wrap the function\n",
       "time_artifact_tool = FunctionTool(func=get_current_time_and_save_artifact)\n",
       "\n",
       "\n",
       "# Tool 2: Reads the timestamp from the artifact\n",
       "def read_last_timestamp_artifact(tool_context: ToolContext) -> dict:\n",
       "    \"\"\"\n",
       "    Reads the most recent timestamp previously saved in the 'last_timestamp.txt' artifact.\n",
       "\n",
       "    Use this tool ONLY when the user asks specifically about the timestamp\n",
       "    that was saved in the artifact, or asks to recall the saved time.\n",
       "\n",
       "    Returns:\n",
       "        A dictionary with the status and the content of the artifact, or an error message.\n",
       "        Example success: {'status': 'found', 'timestamp_from_artifact': '2024-08-15 14:30:55'}\n",
       "        Example error: {'status': 'not_found', 'error_message': 'Timestamp artifact not found.'}\n",
       "    \"\"\"\n",
       "    print(f\"--- Tool: read_last_timestamp_artifact executing ---\")\n",
       "    try:\n",
       "        # Load the latest version by default (version=None)\n",
       "        artifact_part = tool_context.load_artifact(filename=TIMESTAMP_ARTIFACT_FILENAME)\n",
       "\n",
       "        if artifact_part and artifact_part.text is not None:\n",
       "            timestamp_content = artifact_part.text\n",
       "            print(f\"--- Tool: Loaded latest artifact '{TIMESTAMP_ARTIFACT_FILENAME}', content: '{timestamp_content}' ---\")\n",
       "            # Return success payload\n",
       "            return {\"status\": \"found\", \"timestamp_from_artifact\": timestamp_content}\n",
       "        else:\n",
       "            print(f\"--- Tool: Artifact '{TIMESTAMP_ARTIFACT_FILENAME}' not found or has no text content. ---\")\n",
       "            return {\"status\": \"not_found\", \"error_message\": f\"Artifact '{TIMESTAMP_ARTIFACT_FILENAME}' not found.\"}\n",
       "\n",
       "    except ValueError as e:\n",
       "        print(f\"--- Tool ERROR: Failed to load artifact: {e} (Is ArtifactService configured in Runner?) ---\")\n",
       "        return {\"status\": \"error\", \"error_message\": f\"Error loading timestamp artifact: {e}\"}\n",
       "    except Exception as e:\n",
       "        print(f\"--- Tool ERROR: Unexpected error loading artifact: {e} ---\")\n",
       "        return {\"status\": \"error\", \"error_message\": f\"Unexpected error loading timestamp artifact: {e}\"}\n",
       "\n",
       "# Wrap the function\n",
       "read_artifact_tool = FunctionTool(func=read_last_timestamp_artifact)\n",
       "\n",
       "\n",
       "# --- Agent Definition (Updated with Artifact Tools) ---\n",
       "root_agent = Agent(\n",
       "    name=\"assistant_with_artifacts\", # New name for clarity\n",
       "    model=MODEL,\n",
       "    instruction=\"You are a helpful assistant that can manage a timestamp artifact.\\n\\n\"\n",
       "                \"Use Tools Based on User Intent:\\n\"\n",
       "                \"1. CURRENT Time Request: If the user asks for the *current* time or date NOW, \"\n",
       "                \"   you MUST use the 'get_current_time_and_save_artifact' tool. This tool also saves the timestamp.\\n\"\n",
       "                \"2. RECALL Saved Time: If the user asks *what timestamp was saved*, *what's in the artifact*, \"\n",
       "                \"   or asks to *recall the saved time*, you MUST use the 'read_last_timestamp_artifact' tool.\\n\"\n",
       "                \"3. Other Questions: Answer simple questions directly without using tools.\\n\\n\"\n",
       "                \"Respond Clearly: Report the time or the artifact content based on the tool used.\",\n",
       "    # Provide BOTH tools to the agent\n",
       "    tools=[time_artifact_tool, read_artifact_tool],\n",
       ")\n",
       "\n",
       "print(f\"Agent '{root_agent.name}' defined using model '{MODEL}' with artifact tools: {[t.name for t in root_agent.tools]}\")\n",
       "```\n",
       "\n",
       "**Running the Agent with Artifacts:**\n",
       "\n",
       "1.  Go back to your terminal (in `adk_tutorial`), activate `myenv`.\n",
       "2.  Run the agent:\n",
       "\n",
       "```bash\n",
       "adk run my_first_agent\n",
       "```\n",
       "\n",
       "Now, try this sequence of prompts to see the artifact lifecycle:\n",
       "\n",
       "1.  `What time is it now?` (Runs Tool 1, saves artifact version 0)\n",
       "2.  `What was the timestamp saved in the artifact?` (Runs Tool 2, reads version 0)\n",
       "3.  `What time is it again?` (Runs Tool 1, saves artifact version 1)\n",
       "4.  `Recall the saved timestamp from the artifact.` (Runs Tool 2, reads version 1 - the latest)\n",
       "\n",
       "**Expected Output & Observation:**\n",
       "\n",
       "*   **Prompt 1 (`What time is it now?`):**\n",
       "    *   Agent calls `get_current_time_and_save_artifact`.\n",
       "    *   Tool logs show state update and artifact save: `--- Tool: Saved artifact 'last_timestamp.txt' (Version: 0)... ---`\n",
       "    *   Agent responds with the current time, let's call it `<time_1>`.\n",
       "*   **Prompt 2 (`What was the timestamp saved...`):**\n",
       "    *   Agent calls `read_last_timestamp_artifact`.\n",
       "    *   Tool logs show artifact load: `--- Tool: Loaded latest artifact 'last_timestamp.txt', content: '<time_1>' ---`\n",
       "    *   Agent responds, confirming the saved time: \"The timestamp saved in the artifact was `<time_1>`.\" (or similar phrasing).\n",
       "*   **Prompt 3 (`What time is it again?`):**\n",
       "    *   Agent calls `get_current_time_and_save_artifact` again.\n",
       "    *   Tool logs show state update and artifact save: `--- Tool: Saved artifact 'last_timestamp.txt' (Version: 1)... ---` (Note the version is now 1).\n",
       "    *   Agent responds with the new current time, let's call it `<time_2>`.\n",
       "*   **Prompt 4 (`Recall the saved timestamp...`):**\n",
       "    *   Agent calls `read_last_timestamp_artifact` again.\n",
       "    *   Tool logs show artifact load: `--- Tool: Loaded latest artifact 'last_timestamp.txt', content: '<time_2>' ---` (It correctly loaded version 1, the latest).\n",
       "    *   Agent responds with the updated saved time: \"The timestamp saved in the artifact is `<time_2>`.\"\n",
       "\n",
       "This clearly demonstrates the artifact lifecycle: saving data using `save_artifact`, the automatic versioning managed by the `ArtifactService`, and retrieving the *latest* version by default using `load_artifact`. All interactions were managed conveniently through the `ToolContext`.\n",
       "\n",
       "**Summary of Stage 10:**\n",
       "You have now:\n",
       "*   Learned about Artifacts as ADK's mechanism for handling file-like or large data.\n",
       "*   Understood the role of `ArtifactService` (using `InMemory` for now) and how data is represented using `types.Part`.\n",
       "*   Successfully used `tool_context.save_artifact` within a tool to save data (a simple timestamp string in this case) as a versioned artifact.\n",
       "*   Successfully used `tool_context.load_artifact` within another tool to retrieve the latest version of the saved artifact.\n",
       "*   Configured an agent with appropriate instructions to use different tools for saving versus reading the artifact.\n",
       "*   Observed the artifact saving, versioning (0, then 1), and loading process during an interactive agent session.\n",
       "\n",
       "You've now covered a significant range of ADK's core features, including agent definition, tools, state management within sessions, using callbacks for control, orchestrating workflows with sequential and parallel agents, and managing file-like data with artifacts! This provides a very strong foundation.\n",
       "\n",
       "Given this, what would be most beneficial for you to explore next?\n",
       "\n",
       "a)  **Review and Consolidate:** We can revisit any of the previous stages (Agents, Tools, State, Callbacks, Workflow Agents, Artifacts) if you have questions or want to solidify your understanding.\n",
       "b)  **Evaluation:** Learn how to formally test your agent's behavior and performance using ADK's evaluation tools.\n",
       "c)  **Deployment:** Discuss the steps involved in taking your agent from your local machine to a cloud environment (like Cloud Run or Vertex AI Agent Engine).\n",
       "d)  **More Advanced Concepts:** Briefly touch upon topics like `CustomAgent`s (for non-LLM driven logic) or more complex multi-agent patterns involving different delegation strategies (though these often benefit from more practice with the basics first)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## add to chat\n",
    "prompt = (\"Analyst: yes I am ready for the next step.\")\n",
    "response = chat.send_message(message=prompt)\n",
    "\n",
    "# self reflection step\n",
    "p = (\n",
    "  \"Before the analyst views this conduct a thorough review of your output. \"\n",
    "  \"Correct any errors or make improvements and return your output. \"\n",
    ")\n",
    "response = chat.send_message(message=p)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed4d8e96-98a6-4b3f-8ebe-3ca804d56527",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's refine Stage 11 on Evaluation.\n",
       "\n",
       "Excellent! Now that you've built agents with various capabilities (tools, state, workflows), it's crucial to have a reliable way to **test** if they are behaving as expected. Since LLMs introduce variability, simple checks aren't enough. We need a more structured approach.\n",
       "\n",
       "**Stage 11: Evaluating Your Agent's Performance**\n",
       "\n",
       "**Concept:** Agent evaluation in ADK goes beyond typical software testing. Because LLM responses can vary while still being correct, we often need to assess not just the final answer but also the *process* the agent took to get there (its \"trajectory\").\n",
       "\n",
       "ADK provides an evaluation framework to help automate this:\n",
       "\n",
       "1.  **Define Test Cases:** You create structured test data describing specific scenarios. This includes:\n",
       "    *   The user's input (`query`).\n",
       "    *   The expected *behavior* (e.g., which `tools` the agent *should* call, with what kinds of `arguments`).\n",
       "    *   An example of a good final answer (`reference`).\n",
       "2.  **Run Evaluations:** Use ADK tools to automatically run your agent against these test cases.\n",
       "3.  **Assess Performance:** The tools compare the agent's *actual* behavior (tool calls made, final response generated) against your defined expectations and report whether it meets the criteria.\n",
       "\n",
       "**ADK Tools for Evaluation:**\n",
       "\n",
       "*   **Test Files (`<name>.test.json`):** Simple JSON files where each entry is a test interaction (query, expected tool calls, reference). Best suited for focused tests (\"unit tests\") of specific agent capabilities within a single session context.\n",
       "*   **Evalset Files (`<name>.evalset.json`):** More structured files capable of defining multiple complex, multi-turn sessions, each with its own initial state. Better for end-to-end or integration testing.\n",
       "*   **`AgentEvaluator`:** A Python class used programmatically (often within `pytest`) to run evaluations using `.test.json` files.\n",
       "*   **`adk eval` CLI:** A command-line tool primarily for running evaluations using `.evalset.json` files.\n",
       "*   **Web UI (`adk web`) Eval Tab:** Provides an interactive way to run evaluations (using evalsets) and capture sessions to create new test cases.\n",
       "\n",
       "For this stage, we'll focus on the programmatic approach using a **`.test.json` file** and **`pytest`** with **`AgentEvaluator`**.\n",
       "\n",
       "**Implementation:**\n",
       "\n",
       "1.  **Install Evaluation Dependencies:** You need `pytest` to run the tests and libraries for comparing results.\n",
       "\n",
       "    ```bash\n",
       "    # In your terminal, with 'myenv' active:\n",
       "    pip install pytest rouge_score nltk\n",
       "    ```\n",
       "    *(Note: `rouge_score` uses `nltk`. The first time it runs, `nltk` might prompt you to download data packages like 'punkt'. If it does, follow the instructions or run `python -m nltk.downloader punkt` in your environment).*\n",
       "\n",
       "2.  **Create a Test File:** Inside your `my_first_agent` directory, create `agent_tests.test.json`. This file defines our test scenarios. We'll test the agent's ability to use the time tool, the artifact reading tool, and handle a general knowledge question.\n",
       "\n",
       "    ```json\n",
       "    // filename: my_first_agent/agent_tests.test.json\n",
       "    [\n",
       "      {\n",
       "        \"query\": \"What time is it right now?\",\n",
       "        \"expected_tool_use\": [\n",
       "          {\n",
       "            \"tool_name\": \"get_current_time_and_save_artifact\", // Match the function name used by FunctionTool\n",
       "            \"tool_input\": {} // Expects no arguments from the LLM for this tool\n",
       "          }\n",
       "        ],\n",
       "        \"expected_intermediate_agent_responses\": [], // Not used in this simple case\n",
       "        // Reference focuses on structure/intent, not the exact time string\n",
       "        \"reference\": \"The current time is [TIME]\"\n",
       "      },\n",
       "      {\n",
       "        \"query\": \"What was the last timestamp saved?\",\n",
       "        \"expected_tool_use\": [\n",
       "          {\n",
       "            \"tool_name\": \"read_last_timestamp_artifact\", // Match the tool function name\n",
       "            \"tool_input\": {} // Expects no arguments\n",
       "          }\n",
       "        ],\n",
       "        \"expected_intermediate_agent_responses\": [],\n",
       "        // Reference expects retrieval of a timestamp\n",
       "        \"reference\": \"The timestamp saved in the artifact was [TIME]\"\n",
       "      },\n",
       "      {\n",
       "        \"query\": \"What is the capital of Germany?\",\n",
       "        \"expected_tool_use\": [], // <<< Expect NO tool use for this query\n",
       "        \"expected_intermediate_agent_responses\": [],\n",
       "        // Reference is a direct factual answer\n",
       "        \"reference\": \"The capital of Germany is Berlin.\"\n",
       "      }\n",
       "    ]\n",
       "    ```\n",
       "    *   `query`: Input to simulate from the user.\n",
       "    *   `expected_tool_use`: A list specifying which tools the agent *should* call, in order. Each entry requires `tool_name` (must match the name ADK uses, usually the Python function name) and `tool_input` (a dictionary representing the arguments the LLM *should* generate for the tool; `{}` if no arguments are expected). An empty list `[]` asserts that *no* tools should be called.\n",
       "    *   `reference`: An example of a good final answer. The evaluator uses text similarity metrics (like ROUGE) to compare the agent's actual response to this reference. This means placeholders like `[TIME]` are acceptable for dynamic content; the structure and surrounding text are more important than the exact value.\n",
       "\n",
       "3.  **Create a Pytest Test Script:** In the parent `adk_tutorial` directory, create `test_my_agent.py`. This script imports `AgentEvaluator` and defines a test function.\n",
       "\n",
       "    ```python\n",
       "    # filename: test_my_agent.py (Place this in adk_tutorial directory)\n",
       "    import pytest\n",
       "    from google.adk.evaluation import AgentEvaluator # Import the core evaluation class\n",
       "    import os # Import os to construct paths reliably\n",
       "\n",
       "    # --- Configuration ---\n",
       "    # Assumes pytest is run from the 'adk_tutorial' directory\n",
       "    CURRENT_DIR = os.path.dirname(__file__)\n",
       "    AGENT_MODULE_PATH = \"my_first_agent\" # Path to the agent package relative to adk_tutorial\n",
       "    TEST_DATA_FILE = os.path.join(CURRENT_DIR, \"my_first_agent\", \"agent_tests.test.json\")\n",
       "\n",
       "    # --- Test Function ---\n",
       "    def test_agent_basic_interactions():\n",
       "        \"\"\"\n",
       "        Uses AgentEvaluator to run the scenarios defined in the .test.json file\n",
       "        against the agent defined in the specified module path.\n",
       "        \"\"\"\n",
       "        print(f\"\\n--- Starting Agent Evaluation ---\")\n",
       "        print(f\"Agent Module: {AGENT_MODULE_PATH}\")\n",
       "        print(f\"Test Data: {TEST_DATA_FILE}\")\n",
       "\n",
       "        if not os.path.exists(TEST_DATA_FILE):\n",
       "             pytest.fail(f\"Test data file not found: {TEST_DATA_FILE}\")\n",
       "\n",
       "        try:\n",
       "            # The core evaluation call\n",
       "            AgentEvaluator.evaluate(\n",
       "                # Tells the evaluator where to find the 'root_agent' variable\n",
       "                agent_module=AGENT_MODULE_PATH,\n",
       "                # Specifies the JSON file containing the test cases\n",
       "                eval_dataset_file_path_or_dir=TEST_DATA_FILE,\n",
       "                # Optional: Run each test case only once. Default is 2.\n",
       "                num_runs=1\n",
       "                # Optional: Define custom pass/fail criteria here via test_config.json\n",
       "                # or by passing criteria dictionary directly if supported.\n",
       "            )\n",
       "            print(f\"--- Agent Evaluation Completed Successfully ---\")\n",
       "        except FileNotFoundError:\n",
       "            # This case is handled above, but kept for robustness\n",
       "            pytest.fail(f\"Test data file not found at {TEST_DATA_FILE}.\")\n",
       "        except ImportError:\n",
       "             pytest.fail(f\"Could not import agent module from '{AGENT_MODULE_PATH}'. Check the path and ensure 'my_first_agent/__init__.py' exists and is correct.\")\n",
       "        except Exception as e:\n",
       "             # Catch any other errors during evaluation\n",
       "             pytest.fail(f\"Agent evaluation failed with an unexpected error: {e}\")\n",
       "\n",
       "    # You can add more pytest functions here to test other aspects or files\n",
       "    ```\n",
       "\n",
       "**Running the Evaluation:**\n",
       "\n",
       "1.  Ensure you are in the `adk_tutorial` directory in your terminal.\n",
       "2.  Make sure your virtual environment (`myenv`) is active and you've installed `pytest`, `rouge_score`, and `nltk` (`pip install pytest rouge_score nltk`).\n",
       "3.  Execute `pytest`:\n",
       "\n",
       "```bash\n",
       "pytest -s -v test_my_agent.py\n",
       "```\n",
       "*   `-s`: Shows `print` statements from your code (including tool logs).\n",
       "*   `-v`: Provides more verbose output from pytest itself.\n",
       "\n",
       "**Expected Output & Observation:**\n",
       "\n",
       "You'll see detailed output:\n",
       "\n",
       "1.  Pytest starts and identifies the `test_agent_basic_interactions` function.\n",
       "2.  The \"Starting Agent Evaluation\" print statements appear.\n",
       "3.  For *each* of the three test cases in `agent_tests.test.json`:\n",
       "    *   ADK runs the agent with the specified `query`.\n",
       "    *   You'll see the console logs from your tools (`--- Tool: ... executing ---`, `--- Tool: Saved artifact... ---`, `--- Tool: Loaded artifact... ---`) if they are called.\n",
       "    *   `AgentEvaluator` logs messages indicating which query it's running.\n",
       "    *   **Crucially, `AgentEvaluator` compares:**\n",
       "        *   **Tool Trajectory:** Did the agent call the exact tools listed in `expected_tool_use`, in the right order, with compatible arguments?\n",
       "        *   **Final Response:** How similar is the agent's final text response to the `reference` string (using ROUGE score)?\n",
       "    *   You'll see output summarizing these comparisons (often showing scores or PASS/FAIL indicators based on default thresholds). *Note: The default criteria usually require a perfect tool trajectory match (score 1.0) and high text similarity (e.g., ROUGE score >= 0.8).*\n",
       "4.  Pytest provides a final summary showing how many tests passed or failed.\n",
       "\n",
       "If a test fails, the output will highlight the mismatch – e.g., \"Tool trajectory mismatch: Expected ['tool_A'] but got ['tool_B']\" or \"Response match score X below threshold Y\". This helps you pinpoint where the agent's behavior deviated from expectations.\n",
       "\n",
       "*(Note: You can customize the pass/fail criteria by creating a `test_config.json` file next to your `.test.json` file, specifying thresholds for `tool_trajectory_avg_score` and `response_match_score`.)*\n",
       "\n",
       "**Summary of Stage 11:**\n",
       "You have now:\n",
       "*   Learned the importance of structured evaluation for AI agents.\n",
       "*   Understood the role of ADK's test files (`.test.json`) for defining scenarios with queries, expected tool calls, and reference answers.\n",
       "*   Created a `.test.json` file covering different behaviours of your agent.\n",
       "*   Installed `pytest` and supporting libraries (`rouge_score`, `nltk`).\n",
       "*   Written a `pytest` script utilizing `AgentEvaluator.evaluate` to automate the execution of your test file against your agent.\n",
       "*   Executed the evaluation and learned how to interpret the output, which compares actual agent behaviour (tool usage, final response) against your defined expectations.\n",
       "\n",
       "Evaluation is a vital practice for ensuring your agent is reliable, safe, and performs as intended, especially as you make changes or retrain models. It provides automated checks that complement manual testing.\n",
       "\n",
       "We've covered all the fundamental stages of building and testing an ADK agent! You now have a solid grasp of the core components and workflows.\n",
       "\n",
       "What would you like to do now?\n",
       "\n",
       "a)  **Review and Consolidate:** Go back over any of the stages (Agents, Tools, State, Callbacks, Workflows, Artifacts, Evaluation) if anything was unclear or you'd like to reinforce your understanding.\n",
       "b)  **Deployment:** Discuss the steps and considerations for deploying this agent to a cloud environment like Cloud Run or Vertex AI Agent Engine.\n",
       "c)  **More Advanced Topics:** Briefly discuss concepts like `CustomAgent`s, more complex Multi-Agent patterns (e.g., different delegation types), or using persistent `SessionService` / `ArtifactService` backends."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## add to chat\n",
    "prompt = (\"Analyst: yes I am ready for the next step.\")\n",
    "response = chat.send_message(message=prompt)\n",
    "\n",
    "# self reflection step\n",
    "p = (\n",
    "  \"Before the analyst views this conduct a thorough review of your output. \"\n",
    "  \"Correct any errors or make improvements and return your output. \"\n",
    ")\n",
    "response = chat.send_message(message=p)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e3dd0c3-9d2d-4dc3-aae6-4ddc6211f8e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's refine the deployment stage explanation for clarity and completeness.\n",
       "\n",
       "Excellent! Let's move on to **Deployment**. You've built and tested your agent locally, and now it's time to make it accessible over the web by deploying it to the cloud. We'll use **Google Cloud Run**, a serverless platform perfect for running containerized applications like our ADK agent without managing servers.\n",
       "\n",
       "**Stage 12: Deploying Your Agent to Cloud Run using `adk deploy`**\n",
       "\n",
       "**Concept:** Deployment involves packaging your agent code into a container image and running that image on cloud infrastructure. Cloud Run handles the servers, scaling, and networking, allowing users or other services to interact with your agent via an HTTP endpoint.\n",
       "\n",
       "ADK provides a convenient command-line tool, `adk deploy cloud_run`, specifically designed to simplify this process for ADK agents.\n",
       "\n",
       "**Prerequisites:**\n",
       "\n",
       "1.  **Google Cloud SDK (`gcloud`):** You need `gcloud` installed and authenticated.\n",
       "    *   Install: [Google Cloud SDK Install Guide](https://cloud.google.com/sdk/docs/install)\n",
       "    *   Login: Run `gcloud auth login` and follow the browser prompts.\n",
       "    *   Set Project: Run `gcloud config set project ap-alto-ml-1000` (using the project ID from your `.env`).\n",
       "2.  **Enable Google Cloud APIs:** Ensure these APIs are enabled in the `ap-alto-ml-1000` project. You can usually do this via the Cloud Console or `gcloud services enable`:\n",
       "    *   `cloudbuild.googleapis.com` (Cloud Build API)\n",
       "    *   `artifactregistry.googleapis.com` (Artifact Registry API)\n",
       "    *   `run.googleapis.com` (Cloud Run Admin API)\n",
       "    *   `aiplatform.googleapis.com` (Vertex AI API - needed by the agent at runtime)\n",
       "    *   Example command: `gcloud services enable cloudbuild.googleapis.com artifactregistry.googleapis.com run.googleapis.com aiplatform.googleapis.com`\n",
       "3.  **Permissions:** The Google account used with `gcloud auth login` needs roles like \"Cloud Build Editor\", \"Artifact Registry Writer\", \"Cloud Run Admin\", and \"Service Account User\" to perform the deployment. The **service account** that Cloud Run will use to *run* your agent (usually the default Compute Engine service account unless specified otherwise) needs the \"Vertex AI User\" role to call the Gemini model. You might need to grant this role in the IAM section of the Google Cloud Console.\n",
       "\n",
       "**The `adk deploy cloud_run` Command:**\n",
       "\n",
       "This command streamlines packaging, building, and deploying your agent.\n",
       "\n",
       "*   **What it does:** It finds your agent code, creates a suitable `Dockerfile` and server configuration, uses Cloud Build to build a container image, pushes that image to your project's Artifact Registry, and then deploys that image as a new service on Cloud Run.\n",
       "*   **Where to run it:** Execute this command from the `adk_tutorial` directory (the parent directory containing `my_first_agent`).\n",
       "\n",
       "**Implementation:**\n",
       "\n",
       "1.  **Navigate to Project Directory:** Open your terminal and ensure you are in the `adk_tutorial` directory.\n",
       "2.  **Ensure Virtual Environment:** Make sure your `myenv` virtual environment is active (`source myenv/bin/activate`).\n",
       "3.  **Run the Deployment Command:**\n",
       "\n",
       "    ```bash\n",
       "    # Ensure gcloud is authenticated and project is set to ap-alto-ml-1000\n",
       "\n",
       "    adk deploy cloud_run \\\n",
       "        --project=ap-alto-ml-1000 \\\n",
       "        --region=us-central1 \\\n",
       "        --service-name=my-first-adk-agent-service \\\n",
       "        my_first_agent\n",
       "        # Note: No --allow-unauthenticated flag here, we'll keep it secure by default.\n",
       "    ```\n",
       "\n",
       "    *   `--project=ap-alto-ml-1000`: Matches your `.env` setting.\n",
       "    *   `--region=us-central1`: Matches your `.env` setting.\n",
       "    *   `--service-name=my-first-adk-agent-service`: A unique name for your service on Cloud Run. You can change this if you like.\n",
       "    *   `my_first_agent`: The **path** to your agent package directory (relative to where you run the command).\n",
       "    *   `--app_name` (Optional): By default, the ADK server inside the container will expose your agent under an app name matching the directory (`my_first_agent`). You can override this with `--app_name=your_preferred_app_name`. We'll stick with the default for the `curl` commands later.\n",
       "    *   `--allow-unauthenticated`: We are *omitting* this flag. This means the deployed service will require authentication, which is safer.\n",
       "\n",
       "**Execution & Observation:**\n",
       "\n",
       "The command will output progress updates:\n",
       "\n",
       "1.  Identifying agent source code in `my_first_agent`.\n",
       "2.  Creating temporary build files.\n",
       "3.  Submitting the build to Google Cloud Build. You'll see logs streaming from the build process (installing dependencies, building the container). This might take a few minutes.\n",
       "4.  Pushing the container image to Artifact Registry.\n",
       "5.  Deploying the image to Cloud Run.\n",
       "6.  **Authentication Prompt:** Because we omitted `--allow-unauthenticated`, Cloud Run asks:\n",
       "    `Allow unauthenticated invocations to [my-first-adk-agent-service] (y/N)?`\n",
       "    Press **`N`** (or just hit Enter) to keep the service secure.\n",
       "7.  **Success:** The command finishes by printing the **`Service URL`**. This is the HTTPS address of your deployed agent. **Copy this URL carefully.** Example: `https://my-first-adk-agent-service-abc123xyz-uc.a.run.app`\n",
       "\n",
       "    *   **(Runtime Service Account Permissions):** If the deployment succeeds but requests later fail with permission errors related to Vertex AI, ensure the *runtime service account* used by Cloud Run (often `PROJECT_NUMBER-compute@developer.gserviceaccount.com` by default) has the \"Vertex AI User\" role in IAM.\n",
       "\n",
       "**Testing the Deployed Agent via `curl`:**\n",
       "\n",
       "Now, let's send an HTTP request to the deployed agent's API.\n",
       "\n",
       "1.  **Set URL Environment Variable:** In your terminal, store the Service URL you copied.\n",
       "\n",
       "    ```bash\n",
       "    export APP_URL=\"PASTE_YOUR_DEPLOYED_SERVICE_URL_HERE\"\n",
       "    # Example: export APP_URL=\"https://my-first-adk-agent-service-abc123xyz-uc.a.run.app\"\n",
       "    ```\n",
       "\n",
       "2.  **Get Authentication Token:** Since the service requires authentication, get an OIDC identity token associated with your `gcloud` user.\n",
       "\n",
       "    ```bash\n",
       "    export TOKEN=$(gcloud auth print-identity-token)\n",
       "    # This token allows Cloud Run to verify your identity.\n",
       "    ```\n",
       "\n",
       "3.  **Send a Request:** Use `curl` to call the `/run` endpoint. Make sure `app_name` in the JSON payload matches your agent's app name (default is the directory name, `my_first_agent`).\n",
       "\n",
       "    ```bash\n",
       "    curl -X POST \"${APP_URL}/run\" \\\n",
       "         -H \"Authorization: Bearer $TOKEN\" \\\n",
       "         -H \"Content-Type: application/json\" \\\n",
       "         -d '{\n",
       "           \"app_name\": \"my_first_agent\",\n",
       "           \"user_id\": \"cloud_run_user_001\",\n",
       "           \"session_id\": \"cloud_run_session_abc\",\n",
       "           \"new_message\": {\n",
       "             \"role\": \"user\",\n",
       "             \"parts\": [{\"text\": \"What time is it?\"}]\n",
       "           },\n",
       "           \"streaming\": false\n",
       "         }'\n",
       "    ```\n",
       "\n",
       "**Expected Output & Observation:**\n",
       "\n",
       "If everything is configured correctly (including runtime permissions for the service account), you should receive a JSON response back from your Cloud Run service. This JSON will be a list containing the sequence of `Event` objects generated during the agent's execution for that request. You should see events related to the LLM call, the `get_current_time_and_save_artifact` tool execution, and the final agent response containing the time.\n",
       "\n",
       "*   **Troubleshooting:** If you get authentication errors (401/403), double-check that you included the `Authorization: Bearer $TOKEN` header correctly and that your `gcloud` user has permission to invoke the Cloud Run service. If you get errors related to Vertex AI calls *within* the agent's execution, check the Cloud Run service's runtime service account permissions in IAM. Check the Cloud Run service logs in the Google Cloud Console for more detailed error messages.\n",
       "\n",
       "*   **Persistence Caveat:** Remember, the agent deployed here still uses `InMemoryArtifactService` by default. This means the `\"last_timestamp.txt\"` artifact saved in one request might not be available in a subsequent request if Cloud Run uses a different server instance. For persistent artifacts in production, you would need to configure and use `GcsArtifactService`.\n",
       "\n",
       "**Summary of Stage 12:**\n",
       "You have successfully:\n",
       "*   Learned the purpose of deploying an agent to make it accessible.\n",
       "*   Understood the prerequisites for deploying to Google Cloud Run (`gcloud`, APIs, Permissions).\n",
       "*   Used the `adk deploy cloud_run` command to automate the containerization and deployment process.\n",
       "*   Configured the deployed service to require authentication.\n",
       "*   Obtained the public URL for your Cloud Run service.\n",
       "*   Tested the live, deployed agent by sending authenticated HTTP requests using `curl` and obtaining an identity token.\n",
       "*   Recognized the importance of runtime service account permissions for cloud services like Vertex AI.\n",
       "\n",
       "Your agent is now running as a scalable, secure service in the cloud!\n",
       "\n",
       "This concludes the main tutorial path, covering building, testing, and deploying an ADK agent with various features.\n",
       "\n",
       "What would you like to focus on next?\n",
       "\n",
       "a)  **Clean Up:** Learn how to delete the deployed Cloud Run service to avoid ongoing costs.\n",
       "b)  **Review:** Go back over any previous stage if you have questions.\n",
       "c)  **Advanced Topics:** Briefly discuss `CustomAgent`s, persistent storage services, or other specific features."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## add to chat\n",
    "prompt = (\"Analyst: yes I am ready for the next step.\")\n",
    "response = chat.send_message(message=prompt)\n",
    "\n",
    "# self reflection step\n",
    "p = (\n",
    "  \"Before the analyst views this conduct a thorough review of your output. \"\n",
    "  \"Correct any errors or make improvements and return your output. \"\n",
    ")\n",
    "response = chat.send_message(message=p)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49c64dac-7d69-4925-8f18-5fa3cb964fab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's finalize the cleanup stage description.\n",
       "\n",
       "Okay, great. Before we wrap up, it's important to know how to remove the cloud resources we created during deployment. This prevents any potential ongoing costs for services you're no longer using.\n",
       "\n",
       "**Stage 13: Cleaning Up Cloud Resources**\n",
       "\n",
       "**Concept:** Deploying services to the cloud consumes resources (computing instances, network addresses, storage). Even if idle, these can sometimes incur small charges. It's a standard best practice, especially after tutorials or experiments, to delete resources you don't need anymore.\n",
       "\n",
       "In Stage 12, the `adk deploy cloud_run` command created two main things in your Google Cloud project:\n",
       "1.  A **Cloud Run Service:** This is the running instance of your agent application.\n",
       "2.  A **Container Image:** Stored in Google Artifact Registry, this is the packaged version of your agent code that Cloud Run uses.\n",
       "\n",
       "We'll use the `gcloud` command-line tool (which you used for authentication and project setup) to remove the Cloud Run service.\n",
       "\n",
       "**Implementation:**\n",
       "\n",
       "1.  **Confirm `gcloud` Configuration:** Ensure your terminal is still authenticated to Google Cloud (`gcloud auth login` if needed) and configured for the correct project (`gcloud config set project ap-alto-ml-1000`).\n",
       "2.  **Identify Service Name and Region:** Recall the `--service-name` (e.g., `my-first-adk-agent-service`) and `--region` (e.g., `us-central1`) you used during the `adk deploy` command.\n",
       "3.  **Delete the Cloud Run Service:** Execute the following `gcloud` command, replacing the service name and region if yours were different:\n",
       "\n",
       "    ```bash\n",
       "    # Ensure your terminal is authenticated and project is set to ap-alto-ml-1000\n",
       "\n",
       "    gcloud run services delete my-first-adk-agent-service \\\n",
       "        --region=us-central1 \\\n",
       "        --quiet\n",
       "        # Remove --quiet if you want to be prompted for confirmation (y/N)\n",
       "    ```\n",
       "    *   `my-first-adk-agent-service`: The name of the service to delete.\n",
       "    *   `--region=us-central1`: The location of the service.\n",
       "    *   `--quiet`: Skips the confirmation prompt. Omit this if you prefer to confirm manually.\n",
       "\n",
       "4.  **(Optional) Clean Up Artifact Registry Image:** The `adk deploy` command pushed a container image to Artifact Registry (usually in a repository named `cloud-run-source-deploy`). While storage costs for a single image are typically negligible, you *can* delete it if desired. However, managing container images and tags can be complex. For most tutorial cleanup purposes, **deleting the Cloud Run service is the most important step**. If you wish to delete the image, you would typically use `gcloud artifacts docker images list ...` to find the specific image digest (the unique `sha256:...` identifier) and then `gcloud artifacts docker images delete ...@[IMAGE_DIGEST]`. We'll skip the detailed commands here as simply deleting the service is usually sufficient after this tutorial.\n",
       "\n",
       "**Execution & Observation:**\n",
       "\n",
       "*   Running the `gcloud run services delete` command will show progress and output messages confirming that the service is being deleted.\n",
       "*   Once deleted, the `APP_URL` for your service will stop working (you'll get errors if you try to `curl` it).\n",
       "*   You can also verify the deletion by visiting the Cloud Run section in your Google Cloud Console.\n",
       "\n",
       "**Summary of Stage 13:**\n",
       "You have learned:\n",
       "*   The importance of cleaning up deployed cloud resources to manage costs.\n",
       "*   How to use the `gcloud run services delete` command to remove your deployed Cloud Run service.\n",
       "*   That container images are stored in Artifact Registry and can optionally be deleted (though often less critical than deleting the running service).\n",
       "\n",
       "This concludes our step-by-step tutorial on the Agent Development Kit!\n",
       "\n",
       "**Overall Review:**\n",
       "\n",
       "Congratulations! You started with just a Python environment and have successfully navigated through:\n",
       "\n",
       "1.  Creating a basic `LlmAgent`.\n",
       "2.  Adding capabilities with a custom `FunctionTool`.\n",
       "3.  Implementing short-term memory using Session State and `ToolContext`.\n",
       "4.  Intercepting LLM calls with `before_model_callback` for logging and modification.\n",
       "5.  Adding tool-specific validation using `before_tool_callback`.\n",
       "6.  Structuring a Multi-Agent System with delegation between a root agent and a specialist sub-agent.\n",
       "7.  Enforcing deterministic workflows using `SequentialAgent`.\n",
       "8.  Speeding up independent tasks using `ParallelAgent`.\n",
       "9.  Creating iterative processes using `LoopAgent` and escalation signals.\n",
       "10. Managing file-like data using Artifacts (`save_artifact`, `load_artifact`).\n",
       "11. Programmatically evaluating agent behavior using `AgentEvaluator` and `pytest`.\n",
       "12. Deploying your agent as a scalable, secure service on Google Cloud Run using `adk deploy`.\n",
       "13. Cleaning up the deployed cloud resources.\n",
       "\n",
       "You've gained practical experience with the essential components and patterns for building sophisticated applications with ADK.\n",
       "\n",
       "**What's Next?**\n",
       "\n",
       "From here, you can:\n",
       "\n",
       "*   **Practice:** Try modifying the agents, adding more tools, or combining workflow agents in different ways.\n",
       "*   **Review:** Revisit any stage that felt complex or unclear. The documentation provides more in-depth explanations.\n",
       "*   **Explore Persistent Storage:** Experiment with `DatabaseSessionService` or `GcsArtifactService` if you need data to persist between application runs.\n",
       "*   **Dive Deeper:** Look into `CustomAgent`s for non-LLM logic, advanced multi-agent communication patterns, or the specifics of the `MemoryService`.\n",
       "*   **Build Your Own!** Start designing and implementing your own agentic application using the skills you've learned.\n",
       "\n",
       "Do you have any final questions about the cleanup stage or any other part of the tutorial?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## add to chat\n",
    "prompt = (\"Analyst: yes I am ready for the next step.\")\n",
    "response = chat.send_message(message=prompt)\n",
    "\n",
    "# self reflection step\n",
    "p = (\n",
    "  \"Before the analyst views this conduct a thorough review of your output. \"\n",
    "  \"Correct any errors or make improvements and return your output. \"\n",
    ")\n",
    "response = chat.send_message(message=p)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1d1ee5e-d114-44fd-b659-23ba64024ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Excellent! We've now covered the entire planned tutorial path, from creating your very first simple agent all the way through adding tools, state, callbacks, workflows, artifacts, evaluation, deployment, and finally, cleanup.\n",
       "\n",
       "You've successfully built, tested, and deployed a functional agent, touching upon many of the core capabilities of the Agent Development Kit.\n",
       "\n",
       "**Recap of Stages Covered:**\n",
       "\n",
       "1.  Basic `Agent` Definition\n",
       "2.  Adding a `FunctionTool`\n",
       "3.  Using Session `State` with `ToolContext`\n",
       "4.  Intercepting LLM calls with `before_model_callback`\n",
       "5.  Guarding tool execution with `before_tool_callback`\n",
       "6.  Building a Multi-Agent Team with Delegation (`sub_agents`)\n",
       "7.  Deterministic flow with `SequentialAgent`\n",
       "8.  Concurrent execution with `ParallelAgent`\n",
       "9.  Iteration and conditional loops with `LoopAgent`\n",
       "10. Handling files/data with `Artifacts`\n",
       "11. Programmatic `Evaluation` using `pytest` and `AgentEvaluator`\n",
       "12. Deployment to `Cloud Run` using `adk deploy`\n",
       "13. Cleaning up deployed `Cloud Run` resources\n",
       "\n",
       "You now have a solid foundation for working with ADK.\n",
       "\n",
       "Since we've completed the structured tutorial, the \"next step\" is up to you! How would you like to proceed? We could:\n",
       "\n",
       "1.  **Review & Reinforce:** Go back over any of the stages (1-13) or specific concepts (like state vs. artifacts, or the difference between delegation and workflow agents) if anything was unclear or you'd like more examples.\n",
       "2.  **Discuss Next Steps & Advanced Topics:** Talk about how you might apply these concepts to build *your* specific agent. We could also briefly discuss more advanced ADK features, such as:\n",
       "    *   Persistent Storage (`DatabaseSessionService`, `GcsArtifactService`)\n",
       "    *   Long-Term Memory (`MemoryService`)\n",
       "    *   `CustomAgent`s (for non-LLM-based logic)\n",
       "    *   More complex Multi-Agent patterns.\n",
       "3.  **Q&A:** Address any specific questions you have about ADK, agent development in general, or anything we've covered.\n",
       "\n",
       "Let me know what would be most helpful for you at this point!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## add to chat\n",
    "prompt = (\"Analyst: yes I am ready for the next step.\")\n",
    "response = chat.send_message(message=prompt)\n",
    "\n",
    "# self reflection step\n",
    "p = (\n",
    "  \"Before the analyst views this conduct a thorough review of your output. \"\n",
    "  \"Correct any errors or make improvements and return your output. \"\n",
    ")\n",
    "response = chat.send_message(message=p)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06d10306-b340-4470-abcb-bb87ceae690e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's refine the explanation of Persistence.\n",
       "\n",
       "Okay, Analyst. We've successfully deployed the agent to Cloud Run, but there's a critical consideration for making it truly robust: **Persistence**.\n",
       "\n",
       "Throughout the tutorial, we relied on ADK's default `InMemorySessionService` and `InMemoryArtifactService`. These are excellent for getting started and local testing because they require zero setup. However, they have one significant drawback:\n",
       "\n",
       "*   **`InMemory` Limitation:** All session history, conversation state, and saved artifacts are stored only in the running application's memory. **If the application stops or restarts (which happens frequently in cloud environments like Cloud Run), all that data is lost.**\n",
       "\n",
       "For any agent intended for real use, where conversations might span multiple interactions or where generated files need to be kept, we need persistent storage.\n",
       "\n",
       "**Stage 14: Understanding Persistent Storage (Session & Artifact Services)**\n",
       "\n",
       "**Concept:** ADK is designed to work with different backend storage systems. It achieves this through swappable `SessionService` and `ArtifactService` implementations that save data durably, ensuring it survives application restarts and can potentially be shared across multiple running instances of your agent (crucial for scaling).\n",
       "\n",
       "**Why Use Persistent Storage?**\n",
       "\n",
       "*   **Conversation Continuity:** Users can pick up conversations later, even if the server restarted or they connect to a different instance. The agent retains the history and state.\n",
       "*   **Long-Term Data:** User-specific preferences (`user:` state) or files (`user:` artifacts) remain associated with the user across different sessions and times.\n",
       "*   **Scalability & Reliability:** Allows multiple instances of your deployed agent (e.g., scaled up on Cloud Run) to access the same, consistent session data. Protects against data loss from crashes or restarts.\n",
       "\n",
       "**ADK's Persistent Service Options (Examples based on Documentation):**\n",
       "\n",
       "1.  **`DatabaseSessionService`:**\n",
       "    *   **Stores:** Session metadata (ID, user, app), the list of `Events` (history), and the `state` dictionary (including `app:`, `user:`, and session scopes).\n",
       "    *   **Where:** A configured relational database (e.g., PostgreSQL, MySQL, Cloud Spanner via appropriate drivers, or even SQLite for simple local persistence).\n",
       "    *   **Setup:** Requires providing a database connection URL. ADK often uses libraries like SQLAlchemy, which might handle schema creation/migration. You'll need the relevant database driver installed (e.g., `psycopg2` for PostgreSQL).\n",
       "    *   **Use Case:** Suitable for deployments where you manage your own database infrastructure or use managed database services.\n",
       "\n",
       "2.  **`VertexAiSessionService`:**\n",
       "    *   **Stores:** Session metadata, event history, and state. Managed by Google Cloud.\n",
       "    *   **Where:** Google Cloud's scalable Vertex AI backend infrastructure.\n",
       "    *   **Setup:** Requires configuring your environment for Google Cloud (Project ID, Location, Credentials with Vertex AI permissions). The `app_name` used when interacting with this service should typically be the resource name of your deployed Vertex AI Agent Engine.\n",
       "    *   **Use Case:** Ideal for fully managed deployments on Google Cloud, especially when deploying *to* Vertex AI Agent Engine itself, leveraging its integrated session management.\n",
       "\n",
       "3.  **`GcsArtifactService`:**\n",
       "    *   **Stores:** Artifact data (the actual binary content of files like images, PDFs, etc.).\n",
       "    *   **Where:** A specified Google Cloud Storage (GCS) bucket.\n",
       "    *   **Setup:** Requires providing the GCS bucket name during instantiation. The agent's runtime environment (e.g., the Cloud Run service account) needs IAM permissions (like `roles/storage.objectAdmin`) to read and write objects in that bucket.\n",
       "    *   **Use Case:** The standard way to handle persistent file storage for ADK agents deployed on Google Cloud.\n",
       "\n",
       "**How to Use (Configuring the `Runner`):**\n",
       "\n",
       "The key step is to instantiate the desired persistent service(s) and provide them to the `Runner` when you initialize it in your application's entry point (e.g., your FastAPI `main.py` if deploying manually, or handled by `adk deploy` configurations).\n",
       "\n",
       "```python\n",
       "# Conceptual Example - Configuring Runner with Persistent Services\n",
       "\n",
       "# Necessary Imports\n",
       "from google.adk.sessions import DatabaseSessionService # Example\n",
       "from google.adk.artifacts import GcsArtifactService\n",
       "from google.adk.runners import Runner\n",
       "# Assume 'root_agent' is defined elsewhere\n",
       "\n",
       "# --- Configuration (Replace with your actual values) ---\n",
       "# Example DB URL (ensure driver like 'psycopg2' is installed if using PostgreSQL)\n",
       "DATABASE_CONNECTION_URL = \"postgresql+psycopg2://db_user:db_password@db_host:5432/adk_sessions_db\"\n",
       "GCS_ARTIFACT_BUCKET_NAME = \"your-gcs-bucket-for-adk-artifacts\" # Must exist in your GCP project\n",
       "PERSISTENT_APP_NAME = \"my_persistent_agent_app\" # Consistent name for the app\n",
       "\n",
       "# --- Instantiate Persistent Services ---\n",
       "try:\n",
       "    # Session Service for DB\n",
       "    persistent_session_service = DatabaseSessionService(db_url=DATABASE_CONNECTION_URL)\n",
       "    # Optional: Add logic here to ensure DB schema exists if not automatically handled\n",
       "    print(f\"DatabaseSessionService configured for: {DATABASE_CONNECTION_URL}\")\n",
       "\n",
       "    # Artifact Service for GCS\n",
       "    persistent_artifact_service = GcsArtifactService(bucket_name=GCS_ARTIFACT_BUCKET_NAME)\n",
       "    # Ensure runtime environment (e.g., Cloud Run service account) has GCS permissions\n",
       "    print(f\"GcsArtifactService configured for bucket: {GCS_ARTIFACT_BUCKET_NAME}\")\n",
       "\n",
       "    # --- Configure Runner with these Services ---\n",
       "    persistent_runner = Runner(\n",
       "        agent=root_agent,\n",
       "        app_name=PERSISTENT_APP_NAME, # Use the consistent application name\n",
       "        session_service=persistent_session_service,   # <<< Use persistent service\n",
       "        artifact_service=persistent_artifact_service, # <<< Use persistent service\n",
       "    )\n",
       "    print(\"Runner configured successfully with persistent Session and Artifact services.\")\n",
       "\n",
       "    # --- How it affects runtime ---\n",
       "    # Now, when this 'persistent_runner' handles requests:\n",
       "    # - session_service.create_session / get_session reads/writes from/to the database.\n",
       "    # - session_service.append_event saves events and applies state changes to the database.\n",
       "    # - context.save_artifact / load_artifact (called within tools/callbacks) will\n",
       "    #   interact with the specified GCS bucket via persistent_artifact_service.\n",
       "\n",
       "except ImportError as ie:\n",
       "     print(f\"Error configuring services: Missing library? (e.g., install 'psycopg2-binary' for PostgreSQL) Details: {ie}\")\n",
       "except Exception as e:\n",
       "    print(f\"Error configuring persistent services: {e}\")\n",
       "    print(\"Check connection strings, bucket names, cloud permissions, and required libraries.\")\n",
       "    persistent_runner = None # Prevent use if setup failed\n",
       "\n",
       "# --- Example Usage (Conceptual) ---\n",
       "# if persistent_runner:\n",
       "#    # Start your web server (e.g., uvicorn) or use runner directly\n",
       "#    # await persistent_runner.run_async(...)\n",
       "#    pass\n",
       "\n",
       "```\n",
       "\n",
       "**Key Changes with Persistent Services:**\n",
       "\n",
       "*   **Data Durability:** Session history, state (except keys prefixed with `temp:`), and artifacts saved via context methods *will* survive application restarts, crashes, or scaling events.\n",
       "*   **State Scopes Matter More:** Prefixes like `user:` and `app:` become truly meaningful, allowing data sharing across sessions or users as intended, managed by the persistent service.\n",
       "*   **Setup Complexity:** Requires configuring external resources (database, GCS bucket) and managing credentials/permissions correctly.\n",
       "\n",
       "**Summary of Stage 14:**\n",
       "You have now:\n",
       "*   Understood the critical difference between `InMemory` services (for testing) and persistent services (for real applications).\n",
       "*   Learned *why* persistence is necessary for conversation continuity, user data, scalability, and reliability.\n",
       "*   Become familiar with ADK's persistent service options described in the documentation: `DatabaseSessionService`, `VertexAiSessionService`, and `GcsArtifactService`.\n",
       "*   Seen conceptually how to instantiate these services and configure the `Runner` to use them.\n",
       "*   Recognized the implications for data durability and state scoping when using persistent backends.\n",
       "\n",
       "Thinking about persistence *before* or *during* deployment is crucial for building agents that function correctly and reliably in production environments.\n",
       "\n",
       "This concludes the core tutorial path based on the provided documentation! We've journeyed from a simple \"Hello, World\" agent to a multi-agent system with tools, state, callbacks, workflows, artifacts, evaluation, cloud deployment, and now, an understanding of persistence.\n",
       "\n",
       "What would be the most valuable next step for you?\n",
       "\n",
       "1.  **Review & Consolidate:** Revisit any stage (1-14) or concept.\n",
       "2.  **Discuss Your Use Case:** How can you apply these ADK features to the specific agent *you* want to build?\n",
       "3.  **Explore Specific Docs:** Point you towards documentation for features we only touched upon (e.g., `MemoryService`, specific tool wrappers, `CustomAgent`).\n",
       "4.  **End Session:** Conclude if you feel equipped with the foundational knowledge."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## add to chat\n",
    "prompt = (\"Analyst: yes I am ready for the next step.\")\n",
    "response = chat.send_message(message=prompt)\n",
    "\n",
    "# self reflection step\n",
    "p = (\n",
    "  \"Before the analyst views this conduct a thorough review of your output. \"\n",
    "  \"Correct any errors or make improvements and return your output. \"\n",
    ")\n",
    "response = chat.send_message(message=p)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4df936a3-03f3-4d72-b9fd-90b748c7554a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, Analyst! We've reached the end of the structured tutorial based on the core concepts presented in the ADK documentation.\n",
       "\n",
       "**Let's quickly recap the journey:**\n",
       "\n",
       "You started with the basics and successfully progressed through:\n",
       "\n",
       "*   **Agent Creation:** Defining simple `LlmAgent`s.\n",
       "*   **Tools:** Giving agents capabilities with `FunctionTool`.\n",
       "*   **State Management:** Enabling short-term memory within sessions using `ToolContext` and `session.state`.\n",
       "*   **Callbacks:** Intercepting and controlling execution flow (`before_model_callback`, `before_tool_callback`).\n",
       "*   **Multi-Agent Systems:** Building a team with delegation (`sub_agents`).\n",
       "*   **Workflow Agents:** Enforcing deterministic execution order (`SequentialAgent`, `ParallelAgent`, `LoopAgent`).\n",
       "*   **Artifacts:** Handling file-like data (`save_artifact`, `load_artifact`).\n",
       "*   **Evaluation:** Programmatically testing agent behavior (`AgentEvaluator`, `pytest`).\n",
       "*   **Deployment:** Running the agent on the cloud (`Cloud Run` via `adk deploy`).\n",
       "*   **Persistence:** Understanding the need for persistent storage (`DatabaseSessionService`, `GcsArtifactService`, etc.) beyond `InMemory` options.\n",
       "\n",
       "You now have a solid grasp of the fundamental building blocks and the development lifecycle within the Agent Development Kit.\n",
       "\n",
       "Since we've covered the core sequence, the \"next step\" is really about **what would be most valuable for *you* to focus on now**. How would you like to proceed? Here are some options:\n",
       "\n",
       "1.  **Review & Reinforce:** Would you like to revisit any of the stages (1-14) or concepts (e.g., the difference between state and artifacts, how callbacks control flow, the types of workflow agents)? We can go over specific examples again or clarify details.\n",
       "2.  **Discuss Your Specific Goals:** We could talk about the kind of agent *you* ultimately want to build. How might the ADK features we've covered apply to your use case? What challenges do you anticipate?\n",
       "3.  **Explore Advanced Topics (Overview):** I can provide a high-level overview of some features we didn't dive deep into, explaining *what* they are and *when* you might use them:\n",
       "    *   **`MemoryService`:** For long-term, cross-session memory search.\n",
       "    *   **`CustomAgent`:** For building agents with unique, non-LLM-driven logic.\n",
       "    *   **Other Tool Integrations:** Deeper look at OpenAPI/API Hub tools, LangChain/CrewAI wrappers, or specific Google Cloud tools.\n",
       "    *   **Streaming:** Building real-time voice/video agents.\n",
       "4.  **Documentation Deep Dive:** If you have a specific area of interest, I can point you to the most relevant sections in the ADK documentation we reviewed earlier.\n",
       "5.  **Conclude This Session:** If you feel comfortable with the foundation we've built and prefer to explore further on your own using the documentation and examples.\n",
       "\n",
       "Let me know what direction would be most helpful for you now!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## add to chat\n",
    "prompt = (\"Analyst: yes I am ready for the next step.\")\n",
    "response = chat.send_message(message=prompt)\n",
    "\n",
    "# self reflection step\n",
    "p = (\n",
    "  \"Before the analyst views this conduct a thorough review of your output. \"\n",
    "  \"Correct any errors or make improvements and return your output. \"\n",
    ")\n",
    "response = chat.send_message(message=p)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b48e789-9b09-4912-8861-30b0d801b21c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, great choices! Let's delve into those advanced topics, starting with `MemoryService`.\n",
       "\n",
       "**Advanced Topic 1: `MemoryService` - Long-Term, Searchable Knowledge**\n",
       "\n",
       "**Concept:** We've mastered `session.state` for short-term memory within a *single* conversation. But what happens when a user starts a *new* conversation tomorrow and asks, \"What was that project name we discussed last time?\" Or, what if the agent needs to consult a large database of product manuals or company policies that aren't part of the immediate chat? This is where **Memory** and the `MemoryService` come in.\n",
       "\n",
       "*   **Memory vs. Session State:**\n",
       "    *   `Session State`: Volatile (unless persisted via `SessionService`), tied to *one specific session*, acts like a **scratchpad** for the current interaction, accessed by **key**.\n",
       "    *   `Memory`: Designed for **long-term persistence**, potentially spanning *multiple sessions* for a user or holding shared knowledge, acts like a **searchable archive/library**, accessed by **query** (often semantic search).\n",
       "*   **Purpose:** To provide agents with a broader context than just the current conversation, enabling:\n",
       "    *   **Continuity:** Recalling user preferences, past decisions, or key facts mentioned in previous, separate conversations.\n",
       "    *   **Knowledge Retrieval:** Searching through ingested documents, FAQs, product specifications, or other relevant data sources to answer questions accurately.\n",
       "    *   **Personalization:** Tailoring responses based on a longer history of user interactions.\n",
       "*   **The `MemoryService` (`BaseMemoryService` Interface):** This is the component responsible for managing the long-term, searchable knowledge store. Its core functions are:\n",
       "    *   `add_session_to_memory(session)`: To **ingest** information. Takes data from a `Session` (often after it's completed) and processes/indexes relevant parts (like text from events) into the memory store. *How* it processes and indexes depends heavily on the specific implementation.\n",
       "    *   `search_memory(app_name, user_id, query)`: To **retrieve** information. Takes a natural language `query` and searches the memory store for the most relevant pieces of information associated with the `user_id` (and potentially `app_name`). It returns matching results, typically ranked by relevance.\n",
       "*   **Implementations (from Documentation):**\n",
       "    *   `InMemoryMemoryService`: Stores extracted information in the application's memory and performs simple **keyword matching** for search. **Not persistent** (data lost on restart). Useful only for basic local testing.\n",
       "    *   `VertexAiRagMemoryService`: Leverages Google Cloud's Vertex AI RAG service. Ingests data into a RAG Corpus and performs powerful **semantic search** (finding results based on meaning, not just keywords). **Persistent and scalable**. Requires GCP setup, a RAG Corpus, `pip install google-adk[vertexai]`, and proper authentication. Ideal for production on Google Cloud.\n",
       "*   **Typical Workflow:**\n",
       "    1.  **Configuration:** You instantiate a `MemoryService` (e.g., `VertexAiRagMemoryService`) and provide it to the `Runner` during setup.\n",
       "    2.  **Ingestion:** Your application logic determines when to enrich the memory, often by calling `memory_service.add_session_to_memory(completed_session)` after a conversation ends or at meaningful milestones.\n",
       "    3.  **Retrieval Need:** In a later session, the user asks something requiring past context (\"Remind me about Project Alpha details\").\n",
       "    4.  **Agent Uses Memory Tool:** The `LlmAgent`'s instructions guide it to use a specific tool designed for memory retrieval when needed (e.g., the built-in `load_memory` tool or a custom one like `recall_past_info` below). The LLM generates a query for the tool (e.g., `query=\"Project Alpha details from past discussions\"`).\n",
       "    5.  **Tool Calls Service:** The tool function receives the query and uses `tool_context.search_memory(query=...)`. This method, provided by the context object, interacts with the `MemoryService` instance configured in the `Runner`.\n",
       "    6.  **Service Searches:** The `MemoryService` searches its underlying store (using keyword or semantic search) and returns relevant results (e.g., `SearchMemoryResponse` containing `MemoryResult` objects with text snippets).\n",
       "    7.  **Tool Returns Results:** The tool packages the retrieved snippets into its dictionary return value.\n",
       "    8.  **Agent Synthesizes Answer:** The `LlmAgent` receives the results from the tool and uses this retrieved information, along with the current conversation context, to generate the final answer for the user.\n",
       "\n",
       "**Conceptual Code Example (Agent using a Memory Tool):**\n",
       "\n",
       "This focuses on how an agent and tool interact with the memory system via `ToolContext`. We assume a `MemoryService` is configured in the `Runner`.\n",
       "\n",
       "```python\n",
       "# Conceptual Code - Agent using a Memory Tool\n",
       "\n",
       "from google.adk.agents import Agent\n",
       "from google.adk.tools import FunctionTool, ToolContext\n",
       "from google.adk.memory import SearchMemoryResponse # Assuming this structure exists\n",
       "from typing import Dict, Any, List\n",
       "\n",
       "# --- Assume MemoryService is configured in Runner ---\n",
       "# runner = Runner(..., memory_service=my_memory_service_instance)\n",
       "# Assume data was previously added via memory_service.add_session_to_memory(...)\n",
       "\n",
       "# --- Define a Tool that uses MemoryService via ToolContext ---\n",
       "def recall_past_info(query: str, tool_context: ToolContext) -> dict:\n",
       "    \"\"\"\n",
       "    Searches the user's long-term memory archive for information relevant to the query.\n",
       "    Use this tool when the user explicitly asks about past interactions, preferences,\n",
       "    stored facts, or details from previous conversations (e.g., 'What did we discuss about X?',\n",
       "    'Remind me of my preference for Y', 'Find my notes on Z').\n",
       "\n",
       "    Args:\n",
       "        query (str): A natural language query describing the information to retrieve from memory.\n",
       "\n",
       "    Returns:\n",
       "        A dictionary containing the search status and results.\n",
       "        On success: {'status': 'found', 'results': ['Relevant snippet 1', 'Relevant snippet 2', ...]}\n",
       "        If not found: {'status': 'not_found', 'message': 'No relevant information found in memory archive.'}\n",
       "        On error: {'status': 'error', 'error_message': 'Details about the error.'}\n",
       "    \"\"\"\n",
       "    print(f\"--- Tool: recall_past_info searching memory for: '{query}' ---\")\n",
       "    try:\n",
       "        # tool_context provides access to the MemoryService configured in the Runner\n",
       "        # This triggers the search_memory method of the service instance.\n",
       "        search_response: SearchMemoryResponse = tool_context.search_memory(query=query)\n",
       "\n",
       "        # Process the response (structure might vary based on MemoryService implementation)\n",
       "        if search_response and search_response.results:\n",
       "            # Example: Extracting text snippets from results\n",
       "            # The actual structure of 'res' depends on the MemoryService implementation.\n",
       "            # For VertexAiRagMemoryService, results might be different.\n",
       "            # This is a simplified placeholder extraction logic.\n",
       "            extracted_snippets: List[str] = []\n",
       "            for res in search_response.results:\n",
       "                 # Adapt this based on the actual result object structure\n",
       "                 if hasattr(res, 'text') and res.text:\n",
       "                     extracted_snippets.append(res.text)\n",
       "                 elif hasattr(res, 'content') and res.content: # Another possible structure\n",
       "                     extracted_snippets.append(str(res.content))\n",
       "\n",
       "            if extracted_snippets:\n",
       "                print(f\"--- Tool: Found {len(extracted_snippets)} relevant snippet(s) in memory. ---\")\n",
       "                return {\"status\": \"found\", \"results\": extracted_snippets}\n",
       "            else:\n",
       "                 print(f\"--- Tool: Found results object, but no extractable text content. ---\")\n",
       "                 return {\"status\": \"not_found\", \"message\": \"Relevant information structure found, but no text content available.\"}\n",
       "        else:\n",
       "            print(f\"--- Tool: No relevant snippets found in memory. ---\")\n",
       "            return {\"status\": \"not_found\", \"message\": \"No relevant information found in your memory archive.\"}\n",
       "\n",
       "    except ValueError as e:\n",
       "         # This error often occurs if MemoryService wasn't configured in the Runner\n",
       "         print(f\"--- Tool ERROR: Failed to search memory: {e} (Is MemoryService configured in Runner?) ---\")\n",
       "         return {\"status\": \"error\", \"error_message\": f\"Configuration error accessing memory: {e}\"}\n",
       "    except Exception as e:\n",
       "        # Catch other potential errors during the search (e.g., network issues with cloud service)\n",
       "        print(f\"--- Tool ERROR: Unexpected error searching memory: {e} ---\")\n",
       "        return {\"status\": \"error\", \"error_message\": f\"Unexpected error during memory search: {e}\"}\n",
       "\n",
       "# Wrap the function into an ADK Tool\n",
       "memory_tool = FunctionTool(func=recall_past_info)\n",
       "\n",
       "# --- Define an Agent that uses the Memory Tool ---\n",
       "memory_enabled_agent = Agent(\n",
       "    name=\"knowledgeable_assistant\",\n",
       "    model=\"gemini-2.0-flash-001\", # Or another suitable model\n",
       "    instruction=\"You are an assistant with access to a long-term memory archive about the user's past interactions and preferences. \"\n",
       "                \"Answer questions directly if you know the answer. \"\n",
       "                \"However, if the user asks to recall specific details from the past, previous discussions, \"\n",
       "                \"stored preferences, or information they previously provided (e.g., 'What did I say about X?', 'Remind me of Y', 'Find my notes on Z'), \"\n",
       "                \"you MUST use the 'recall_past_info' tool to search the memory archive. \"\n",
       "                \"Synthesize the results from the tool into your answer.\",\n",
       "    tools=[memory_tool], # Provide the memory access tool\n",
       ")\n",
       "\n",
       "# --- Note on Running ---\n",
       "# To run this agent effectively:\n",
       "# 1. An appropriate MemoryService instance (e.g., InMemoryMemoryService or VertexAiRagMemoryService)\n",
       "#    must be created and passed to the Runner: `Runner(..., memory_service=...)`.\n",
       "# 2. Data must have been previously ingested into that MemoryService using\n",
       "#    `memory_service.add_session_to_memory(...)`.\n",
       "# 3. Then, running the agent with a query like \"What was mentioned about Project Alpha?\"\n",
       "#    should trigger the 'recall_past_info' tool.\n",
       "\n",
       "```\n",
       "\n",
       "**Key Takeaway for `MemoryService`:** It provides a **searchable** (often semantically), potentially **persistent**, **cross-session** knowledge layer. Agents access it indirectly via **Tools** that utilize the `tool_context.search_memory` method, which in turn calls the `MemoryService` instance configured in the `Runner`. This complements the short-term, key-value nature of `session.state`.\n",
       "\n",
       "Does this explanation of `MemoryService` and how agents interact with it make sense? Are you ready to move on to `CustomAgent`?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## add to chat\n",
    "prompt = (\"Analyst: Lets step through the advanced topics: MemoryService and then CustomAgent\")\n",
    "response = chat.send_message(message=prompt)\n",
    "\n",
    "# self reflection step\n",
    "p = (\n",
    "  \"Before the analyst views this conduct a thorough review of your output. \"\n",
    "  \"Correct any errors or make improvements and return your output. \"\n",
    ")\n",
    "response = chat.send_message(message=p)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32b9850a-032f-4c3c-9bcd-91f7770e35db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, let's refine the `CustomAgent` explanation for the analyst.\n",
       "\n",
       "Okay, let's tackle **`CustomAgent`**. This is an advanced topic for situations where the predefined agent types (`LlmAgent`, `SequentialAgent`, `ParallelAgent`, `LoopAgent`) don't provide the exact control flow you need. Use `CustomAgent` when you want to orchestrate other agents or perform actions using **your own specific Python logic**.\n",
       "\n",
       "**Advanced Topic 2: `CustomAgent` - Defining Your Own Execution Logic**\n",
       "\n",
       "**Concept:** We've primarily used:\n",
       "\n",
       "*   `LlmAgent`: Uses an LLM for flexible, dynamic reasoning and decision-making (including tool use and delegation). Its flow is non-deterministic.\n",
       "*   `WorkflowAgent`s (`Sequential`, `Parallel`, `Loop`): Execute sub-agents according to fixed, predictable patterns. They provide deterministic flow control *without* using an LLM for the orchestration itself.\n",
       "\n",
       "You need a `CustomAgent` when your desired orchestration logic involves:\n",
       "\n",
       "*   **Complex Conditional Branching:** Running different sub-agents or sequences based on intricate conditions evaluated in Python code (e.g., checking multiple state variables, external factors).\n",
       "*   **Custom Retry or Error Handling Logic:** Implementing sophisticated retry mechanisms for sub-agent failures beyond simple looping.\n",
       "*   **Hybrid Logic:** Combining deterministic steps with calls to external systems, databases, or custom computations *directly within the orchestration flow* itself, rather than solely within tools called by an `LlmAgent`.\n",
       "*   **Unique Workflow Patterns:** Creating orchestration structures that don't map cleanly onto simple sequential, parallel, or loop constructs.\n",
       "\n",
       "**How it works:**\n",
       "\n",
       "1.  **Inherit from `BaseAgent`:** Your custom orchestrator must be a Python class that inherits directly from `google.adk.agents.BaseAgent`.\n",
       "2.  **Implement `_run_async_impl`:** This is the heart of your custom agent. You **must** override the asynchronous method:\n",
       "    ```python\n",
       "    async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:\n",
       "        # Your custom orchestration logic goes here\n",
       "        pass\n",
       "    ```\n",
       "    *   **`async def`:** It must be an asynchronous generator function.\n",
       "    *   **`ctx: InvocationContext`:** It receives the full `InvocationContext`, providing access to `ctx.session` (including `.state` and `.events`), `ctx.agent` (this custom agent instance), `ctx.invocation_id`, configured services (`artifact_service`, `memory_service`), etc.\n",
       "    *   **`-> AsyncGenerator[Event, None]`:** It **must** `yield` `Event` objects. This is crucial for:\n",
       "        *   Passing events generated by any sub-agents it calls up to the `Runner`.\n",
       "        *   Signaling its own state changes or results via custom `Event`s.\n",
       "        *   Cooperating with the ADK `Runner`'s event loop (pausing and resuming correctly).\n",
       "3.  **Define Custom Logic within `_run_async_impl`:** Inside this method, you write standard Python `asyncio` code:\n",
       "    *   **Store and Call Sub-Agents:** If your custom agent manages other agents, pass them during `__init__` and store them as instance attributes (e.g., `self.checker_agent`). Call their execution methods (usually `sub_agent.run_async(ctx)`) and properly handle their events using `async for`:\n",
       "        ```python\n",
       "        print(f\"--- {self.name}: Calling {self.checker_agent.name} ---\")\n",
       "        async for event in self.checker_agent.run_async(ctx):\n",
       "            # Process or log the event from the sub-agent if needed\n",
       "            print(f\"  Yielding event from {event.author}...\")\n",
       "            yield event # <<< Crucial: Yield sub-agent events up to the Runner\n",
       "        # Execution resumes here after checker_agent finishes AND its last event is processed by Runner\n",
       "        ```\n",
       "    *   **Access and Use State:** Read values from `ctx.session.state` to make decisions. You can *write* to state (e.g., `ctx.session.state['my_flag'] = True`), but remember the change is only reliably committed *after* an `Event` containing the corresponding `state_delta` (which you might need to yield yourself or which might be part of a sub-agent's event) is processed by the `Runner`.\n",
       "    *   **Implement Control Flow:** Use Python's `if`/`elif`/`else`, `for`/`while` loops, `try`/`except` blocks, etc., to build your specific workflow involving sub-agent calls or other actions.\n",
       "    *   **Yield Custom Events:** Your `CustomAgent` can `yield` its own `Event` objects (e.g., `yield Event(author=self.name, content=..., actions=...)`) to report status, intermediate results, or explicitly signal state changes.\n",
       "\n",
       "**Implementation Example (Conditional Workflow):**\n",
       "\n",
       "Let's create a custom agent (`ConditionalWorkflowAgent`) that:\n",
       "1.  Runs a sub-agent (`task_a`) which sets a specific state key (`task_a_outcome`).\n",
       "2.  Reads the value of `task_a_outcome` from the state *after* `task_a` completes.\n",
       "3.  Based on that value, it conditionally runs *either* `task_b` (if outcome was 'success') *or* `task_c` (otherwise).\n",
       "\n",
       "```python\n",
       "# filename: my_first_agent/agent.py (Updated for Custom Agent)\n",
       "\n",
       "from google.adk.agents import Agent, BaseAgent, InvocationContext # <<< BaseAgent, InvocationContext\n",
       "from google.adk.events import Event, EventActions\n",
       "from google.genai import types\n",
       "import asyncio\n",
       "from typing import AsyncGenerator, List, Optional # <<< AsyncGenerator\n",
       "\n",
       "# --- Define Simple Sub-Agents ---\n",
       "# These agents will be orchestrated by our CustomAgent.\n",
       "# Task A sets a state key via output_key.\n",
       "agent_task_a = Agent(\n",
       "    name=\"TaskA_SetOutcome\",\n",
       "    model=\"gemini-2.0-flash-001\",\n",
       "    instruction=\"Set the state key 'task_a_outcome' to the value 'success'. Confirm this action.\",\n",
       "    # output_key automatically creates state_delta={'task_a_outcome': 'success'}\n",
       "    # in the agent's final event.\n",
       "    output_key=\"task_a_outcome\",\n",
       ")\n",
       "\n",
       "# Task B runs if Task A succeeded.\n",
       "agent_task_b = Agent(\n",
       "    name=\"TaskB_SuccessPath\",\n",
       "    model=\"gemini-2.0-flash-001\",\n",
       "    instruction=\"Confirm that you are Task B, running because the previous step succeeded.\",\n",
       "    output_key=\"final_result\" # Overwrites state['final_result']\n",
       ")\n",
       "\n",
       "# Task C runs if Task A did not succeed.\n",
       "agent_task_c = Agent(\n",
       "    name=\"TaskC_FailurePath\",\n",
       "    model=\"gemini-2.0-flash-001\",\n",
       "    instruction=\"Confirm that you are Task C, running because the previous step did NOT result in 'success'.\",\n",
       "    output_key=\"final_result\" # Overwrites state['final_result']\n",
       ")\n",
       "\n",
       "\n",
       "# --- Define the Custom Agent ---\n",
       "class ConditionalWorkflowAgent(BaseAgent):\n",
       "    \"\"\"\n",
       "    A Custom Agent that runs Task A, then runs Task B or Task C\n",
       "    based on the 'task_a_outcome' state set by Task A.\n",
       "    \"\"\"\n",
       "    # Define attributes for sub-agents (helps with type checking and clarity)\n",
       "    task_a: Agent\n",
       "    task_b: Agent\n",
       "    task_c: Agent\n",
       "\n",
       "    # Pydantic configuration to allow Agent objects as attributes\n",
       "    model_config = {\"arbitrary_types_allowed\": True}\n",
       "\n",
       "    def __init__(self, name: str, task_a: Agent, task_b: Agent, task_c: Agent):\n",
       "        \"\"\"Initializes the custom agent, storing sub-agents.\"\"\"\n",
       "        # List the agents this custom agent directly orchestrates\n",
       "        direct_sub_agents = [task_a, task_b, task_c]\n",
       "\n",
       "        # Call super().__init__ FIRST.\n",
       "        # Pass keyword arguments for Pydantic validation and assignment (self.task_a = task_a).\n",
       "        # Pass the list of sub-agents to the 'sub_agents' parameter for framework hierarchy.\n",
       "        super().__init__(\n",
       "            name=name,\n",
       "            task_a=task_a,\n",
       "            task_b=task_b,\n",
       "            task_c=task_c,\n",
       "            sub_agents=direct_sub_agents\n",
       "        )\n",
       "        print(f\"Custom Agent '{self.name}' initialized.\")\n",
       "        print(f\"  Orchestrates: {[sa.name for sa in self.sub_agents]}\")\n",
       "\n",
       "    # <<< Override the core execution method >>>\n",
       "    async def _run_async_impl(\n",
       "        self, ctx: InvocationContext\n",
       "    ) -> AsyncGenerator[Event, None]:\n",
       "        \"\"\"Implements the custom conditional workflow logic.\"\"\"\n",
       "        print(f\"\\n--- Custom Agent '{self.name}' Starting (Invocation ID: {ctx.invocation_id}) ---\")\n",
       "\n",
       "        # === Step 1: Always run Task A ===\n",
       "        print(f\"--- {self.name}: Running sub-agent '{self.task_a.name}'... ---\")\n",
       "        # Use 'async for' to properly yield all events from the sub-agent's run\n",
       "        async for event in self.task_a.run_async(ctx):\n",
       "            print(f\"  Yielding event from '{event.author}' (Final: {event.is_final_response()})\")\n",
       "            yield event\n",
       "        # ---- Task A finished execution ----\n",
       "        # The Runner processed Task A's final event, including committing its state_delta.\n",
       "\n",
       "        # === Step 2: Read State set by Task A ===\n",
       "        # Access the session state via the InvocationContext 'ctx'\n",
       "        # Use .get() for safe access in case the key wasn't set\n",
       "        outcome = ctx.session.state.get(\"task_a_outcome\", \"unknown\")\n",
       "        print(f\"--- {self.name}: Read state 'task_a_outcome' = '{outcome}' ---\")\n",
       "\n",
       "        # === Step 3: Conditional Execution based on State ===\n",
       "        chosen_task: Optional[Agent] = None # Variable to hold the next task\n",
       "        if outcome == \"success\":\n",
       "            print(f\"--- {self.name}: Condition 'success' met. Choosing '{self.task_b.name}'. ---\")\n",
       "            chosen_task = self.task_b\n",
       "        else:\n",
       "            print(f\"--- {self.name}: Condition NOT 'success' ('{outcome}'). Choosing '{self.task_c.name}'. ---\")\n",
       "            chosen_task = self.task_c\n",
       "\n",
       "        # === Step 4: Execute the chosen task ===\n",
       "        if chosen_task:\n",
       "            print(f\"--- {self.name}: Running chosen sub-agent '{chosen_task.name}'... ---\")\n",
       "            async for event in chosen_task.run_async(ctx):\n",
       "                print(f\"  Yielding event from '{event.author}' (Final: {event.is_final_response()})\")\n",
       "                yield event\n",
       "            # --- Chosen task (B or C) finished execution ---\n",
       "        else:\n",
       "             # Should not happen in this logic, but good practice\n",
       "             print(f\"--- {self.name}: No task chosen based on outcome '{outcome}'. ---\")\n",
       "\n",
       "        print(f\"--- Custom Agent '{self.name}' Finished ---\")\n",
       "        # Optionally yield a final status event from the custom agent itself\n",
       "        yield Event(author=self.name, content=types.Content(parts=[types.Part(text=\"Conditional workflow complete.\")]))\n",
       "\n",
       "\n",
       "# --- Instantiate the Custom Agent as the Root Agent ---\n",
       "root_agent = ConditionalWorkflowAgent(\n",
       "    name=\"my_conditional_workflow\",\n",
       "    task_a=agent_task_a,\n",
       "    task_b=agent_task_b,\n",
       "    task_c=agent_task_c,\n",
       ")\n",
       "\n",
       "# --- Running this Agent ---\n",
       "# The `adk run my_first_agent` command will now execute this CustomAgent.\n",
       "# You still need the supporting code structure (Runner, SessionService)\n",
       "# if running programmatically, like in the commented-out example in the previous response.\n",
       "# `adk run` handles that setup implicitly.\n",
       "\n",
       "print(f\"\\nRoot agent is now '{root_agent.name}' (Custom Agent).\")\n",
       "\n",
       "```\n",
       "\n",
       "**Running and Observing:**\n",
       "\n",
       "1.  Go back to your terminal (in `adk_tutorial`), activate `myenv`.\n",
       "2.  Run the agent:\n",
       "\n",
       "```bash\n",
       "adk run my_first_agent\n",
       "```\n",
       "\n",
       "Send any prompt to start the custom workflow, e.g.:\n",
       "\n",
       "*   `Start`\n",
       "\n",
       "**Expected Output & Observation:**\n",
       "\n",
       "1.  The `my_conditional_workflow` (`CustomAgent`) starts.\n",
       "2.  Log: `--- my_conditional_workflow: Running sub-agent 'TaskA_SetOutcome'... ---`\n",
       "3.  `TaskA_SetOutcome` runs. It uses its LLM to generate the confirmation and its `output_key` ensures its final event includes `state_delta={'task_a_outcome': 'success'}`. You'll see events yielded from it.\n",
       "4.  The `CustomAgent` resumes *after* Task A's final event is processed by the Runner (committing the state).\n",
       "5.  Log: `--- my_conditional_workflow: Read state 'task_a_outcome' = 'success' ---`\n",
       "6.  Log: `--- my_conditional_workflow: Condition 'success' met. Choosing 'TaskB_SuccessPath'. ---`\n",
       "7.  Log: `--- my_conditional_workflow: Running chosen sub-agent 'TaskB_SuccessPath'... ---`\n",
       "8.  `TaskB_SuccessPath` runs, uses its LLM, and yields its events (including its final response confirming it's Task B).\n",
       "9.  The `CustomAgent` resumes after Task B finishes.\n",
       "10. Log: `--- Custom Agent 'my_conditional_workflow' Finished ---`\n",
       "11. The `CustomAgent` yields its final completion event.\n",
       "12. The final response displayed by `adk run` will be from the last agent in the executed path (Task B in this case).\n",
       "\n",
       "If you were to modify `agent_task_a`'s instruction to set the outcome differently (e.g., \"Set the state key 'task_a_outcome' to 'pending'\"), rerunning the workflow would cause the logs to show Task C being chosen and executed instead of Task B. This confirms the custom conditional logic is working deterministically based on the state set by the first step.\n",
       "\n",
       "**Key Takeaways for `CustomAgent`:**\n",
       "\n",
       "*   **Use Case:** Needed for complex, deterministic orchestration logic that goes beyond standard `WorkflowAgent` patterns.\n",
       "*   **Inheritance:** Must inherit from `BaseAgent`.\n",
       "*   **Core Method:** You **must** implement `async def _run_async_impl(self, ctx: InvocationContext)`.\n",
       "*   **Sub-Agent Calls:** Use `async for event in sub_agent.run_async(ctx): yield event` to correctly run sub-agents and propagate their events.\n",
       "*   **State Interaction:** Use `ctx.session.state` to read state for making decisions. Be mindful that state writes are committed by the `Runner` *after* an event with the `state_delta` is yielded.\n",
       "*   **`yield Event`:** Essential for pausing execution, allowing the `Runner` to process events (including state/artifact changes), and communicating results or status.\n",
       "\n",
       "`CustomAgent` offers the highest degree of control over agent execution flow but requires careful management of the asynchronous `asyncio` model and the ADK event lifecycle.\n",
       "\n",
       "We've now explored all the major agent types (`LlmAgent`, `SequentialAgent`, `ParallelAgent`, `LoopAgent`, `CustomAgent`) along with tools, state, callbacks, artifacts, evaluation, deployment, and persistence! This provides a very comprehensive overview of the ADK framework based on the documentation.\n",
       "\n",
       "What would be the most helpful final step for you?\n",
       "\n",
       "1.  **Quick Recap Quiz:** A few questions to solidify understanding of all concepts.\n",
       "2.  **Discuss Your Project:** Brainstorm applying these features to your specific needs.\n",
       "3.  **Documentation Pointers:** Highlight specific documentation pages for deeper dives.\n",
       "4.  **Conclude:** End the tutorial session."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## add to chat\n",
    "prompt = (\"Analyst: yes I am ready for CustomAgent.\")\n",
    "response = chat.send_message(message=prompt)\n",
    "\n",
    "# self reflection step\n",
    "p = (\n",
    "  \"Before the analyst views this conduct a thorough review of your output. \"\n",
    "  \"Correct any errors or make improvements and return your output. \"\n",
    ")\n",
    "response = chat.send_message(message=p)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989556bd-53df-4910-93d1-9c13cc4d292a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
