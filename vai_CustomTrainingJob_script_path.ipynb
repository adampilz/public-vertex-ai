{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1539c25-698b-4213-a67c-dc9cf76d0442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c4667-cf99-47a7-8096-d0de0c7b2e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#\n",
    "#       aiplatform.CustomTrainingJob -> script_path\n",
    "#\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa12b4-189d-470b-9def-3b3d1befc326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#\n",
    "# define the training script\n",
    "#\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d2d9ef4-5787-43e5-86d5-59116db92c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile training_script.py\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Sample Decision Tree Classifier\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "# parse args\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--bucket_name', dest='bucket_name', default=\"\", type=str, help='The GCS bucket to store model artifacts -> w/o gs://')\n",
    "parser.add_argument('--max_depth', dest='max_depth', default=10, type=int, help='The maximum depth of the tree')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# load the iris datasets\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "# fit a CART model to the data\n",
    "model = DecisionTreeClassifier(max_depth = args.max_depth)\n",
    "model.fit(dataset.data, dataset.target)\n",
    "print(model)\n",
    "\n",
    "# make predictions\n",
    "expected = dataset.target\n",
    "predicted = model.predict(dataset.data)\n",
    "\n",
    "# summarize the fit of the model\n",
    "classification_report = metrics.classification_report(expected, predicted)\n",
    "confusion_matrix = metrics.confusion_matrix(expected, predicted)\n",
    "\n",
    "# save the model to disk\n",
    "model_filename = \"model.pkl\"\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "# Upload the saved model file to GCS\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(args.bucket_name)\n",
    "model_directory = os.environ[\"AIP_MODEL_DIR\"]\n",
    "storage_path = os.path.join(model_directory, model_filename)\n",
    "blob = storage.blob.Blob.from_string(storage_path, client=storage_client)\n",
    "blob.upload_from_filename(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5337cc1a-5363-4b80-b2fb-ef715678b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#\n",
    "# kick off the custom training job\n",
    "#\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c85eb3e-a729-4a04-b474-084cb0c97a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd2e0c5e-379f-419b-b508-aee8601ac572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "P = ! gcloud config list --format 'value(core.project)'\n",
    "PROJECT_ID = P[0]\n",
    "REGION = \"us-central1\"\n",
    "BUCKET_NAME = f\"bkt-{PROJECT_ID}-vpipelines\"\n",
    "BUCKET_PATH = f\"gs://{BUCKET_NAME}\"\n",
    "PIPELINE_ROOT = f\"{BUCKET_PATH}/pipeline_root\"\n",
    "PIPELINE_DATA = f\"{BUCKET_PATH}/data\"\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77613083-3655-42d6-94f7-d409c586dcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_VERSION  = \"scikit-learn-cpu.0-23\"\n",
    "DEPLOY_VERSION = \"sklearn-cpu.0-23\"\n",
    "\n",
    "TRAIN_IMAGE = \"us-docker.pkg.dev/vertex-ai/training/{}:latest\".format(TRAIN_VERSION)\n",
    "DEPLOY_IMAGE = \"us-docker.pkg.dev/vertex-ai/prediction/{}:latest\".format(DEPLOY_VERSION)\n",
    "\n",
    "JOB_NAME = \"vai_CustomTrainingJob\"\n",
    "\n",
    "MAX_DEPTH = 20\n",
    "CMDARGS = [  f\"--bucket_name={BUCKET_NAME}\"\n",
    "           , f\"--max_depth={str(MAX_DEPTH)}\"\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6cb57e-7545-406e-9624-072b162d8b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training script copied to:\n",
      "gs://bkt-ap-alto-ml-1000-vpipelines/aiplatform-2022-12-19-23:47:59.948-aiplatform_custom_trainer_script-0.1.tar.gz.\n",
      "Training Output directory:\n",
      "gs://bkt-ap-alto-ml-1000-vpipelines/aiplatform-custom-training-2022-12-19-23:48:00.110 \n",
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/2596916859873787904?project=720376660491\n",
      "CustomTrainingJob projects/720376660491/locations/us-central1/trainingPipelines/2596916859873787904 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "View backing custom job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/2906565722534576128?project=720376660491\n",
      "CustomTrainingJob projects/720376660491/locations/us-central1/trainingPipelines/2596916859873787904 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomTrainingJob projects/720376660491/locations/us-central1/trainingPipelines/2596916859873787904 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_PATH)\n",
    "\n",
    "job = aiplatform.CustomTrainingJob(\n",
    "    display_name = JOB_NAME\n",
    "    , script_path = \"training_script.py\"\n",
    "    , container_uri = TRAIN_IMAGE\n",
    "    #, requirements = [\"tensorflow_datasets\"]\n",
    "    , model_serving_container_image_uri = DEPLOY_IMAGE\n",
    ")\n",
    "\n",
    "MODEL_DISPLAY_NAME = \"vai_model_registry_name\"\n",
    "\n",
    "# Start the training\n",
    "model = job.run(\n",
    "    model_display_name = MODEL_DISPLAY_NAME\n",
    "    , args = CMDARGS\n",
    "    , replica_count = 1\n",
    "    , service_account = f\"sa-vertex-pipelines@{PROJECT_ID}.iam.gserviceaccount.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fcc7fd-1196-4441-ae42-deb6efeeec31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "local-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
