{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1539c25-698b-4213-a67c-dc9cf76d0442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c4667-cf99-47a7-8096-d0de0c7b2e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#\n",
    "#       aiplatform.CustomJob.from_local_script\n",
    "#\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b70c9de-21cd-478f-bf34-8af8c490c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# google\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858e8c8f-e71c-42d9-96fc-19540b120bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "P = ! gcloud config list --format 'value(core.project)'\n",
    "PROJECT_ID = P[0]\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "SERVICE_ACCOUNT = f\"sa-vertex-pipelines@{PROJECT_ID}.iam.gserviceaccount.com\"\n",
    "NETWORK = \"vpc-adam-default\"\n",
    "\n",
    "USE_CASE = \"custom-training\"\n",
    "ML_FRAMEWORK = \"scikit\"\n",
    "MODEL_TYPE = \"binclass\"\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "# GCS inputs\n",
    "GCS_BUCKET_NAME = f\"bkt-{REGION}-{USE_CASE}\"\n",
    "GCS_BUCKET_PATH = f\"gs://{GCS_BUCKET_NAME}\"\n",
    "GCS_BUCKET_PATH_DATA = f\"{GCS_BUCKET_PATH}/data\"\n",
    "GCS_BUCKET_PATH_CONFIGS = f\"{GCS_BUCKET_PATH}/configs\"\n",
    "GCS_BUCKET_PATH_TMP = f\"{GCS_BUCKET_PATH}/tmp\"\n",
    "GCS_BUCKET_PATH_STAGING = f\"{GCS_BUCKET_PATH}/staging\"\n",
    "\n",
    "TRAIN_DS = \"tab_class_10inps_1krows_tes_3498.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa12b4-189d-470b-9def-3b3d1befc326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#\n",
    "# define the training script\n",
    "#\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13793cc3-2e78-4609-b2ab-0590f07766bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile training_script.py\n",
    "\n",
    "import argparse, os, pickle\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from google.cloud import storage\n",
    "\n",
    "# parse args\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--bucket_name', dest='bucket_name', default=\"\", type=str, help='The GCS bucket to store model artifacts -> w/o gs://')\n",
    "parser.add_argument('--train_ds', dest='train_ds', default=\"\", type=str, help='file name of the training data')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# clients\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# download data from GCS\n",
    "data_directory = f\"gs://{args.bucket_name}/{args.train_ds}\"\n",
    "blob = storage.blob.Blob.from_string(data_directory, client=storage_client)\n",
    "blob.download_to_filename(args.train_ds)\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv(args.train_ds)\n",
    "labels = df.pop(\"label\").tolist()\n",
    "data = df.values.tolist()\n",
    "\n",
    "# fit the model\n",
    "skmodel = GradientBoostingClassifier(n_estimators = 100, max_depth = 10, min_samples_split = 100, min_samples_leaf = 100)\n",
    "skmodel.fit(data, labels)\n",
    "\n",
    "# save model\n",
    "model_filename = \"model.pkl\"\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    pickle.dump(skmodel, model_file)\n",
    "\n",
    "# Upload the saved model file to GCS\n",
    "model_directory = os.environ[\"AIP_MODEL_DIR\"]\n",
    "storage_path = os.path.join(model_directory, model_filename)\n",
    "blob = storage.blob.Blob.from_string(storage_path, client=storage_client)\n",
    "blob.upload_from_filename(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337cc1a-5363-4b80-b2fb-ef715678b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#\n",
    "# kick off the custom training job\n",
    "#\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c85eb3e-a729-4a04-b474-084cb0c97a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cecb078-ecae-4ea0-a2ab-03e5f1b1a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "job = aiplatform.CustomJob.from_local_script(\n",
    "    display_name = f\"CustomJob_fromLocalScript_{TIMESTAMP}\"\n",
    "    , project = PROJECT_ID\n",
    "    , location = REGION\n",
    "    , staging_bucket = GCS_BUCKET_PATH\n",
    "    , script_path = \"training_script.py\"\n",
    "    , container_uri = \"us-docker.pkg.dev/vertex-ai/training/scikit-learn-cpu.0-23:latest\"\n",
    "    , requirements = [\"gcsfs\"]\n",
    "    , replica_count = 1\n",
    "    , machine_type = \"n1-standard-4\"\n",
    "    , accelerator_count = 0\n",
    "    , args = [f\"--bucket_name={GCS_BUCKET_NAME}\", f\"--train_ds={TRAIN_DS}\"]\n",
    "    , environment_variables = { 'MY_KEY': 'MY_VALUE' }\n",
    "    , labels={'my_key': 'my_value'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e48c199-10c7-48c2-ad4e-f423dfb5d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.run(service_account = f\"sa-vertex-pipelines@{PROJECT_ID}.iam.gserviceaccount.com\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m102"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
